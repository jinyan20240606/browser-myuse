import asyncio  # å¼‚æ­¥ I/O æ”¯æŒï¼Œç”¨äºåç¨‹å’Œ async/await
import gc  # åƒåœ¾å›æ”¶æ¨¡å—ï¼Œç”¨äºå¼ºåˆ¶å›æ”¶å¯¹è±¡
import inspect  # è¿è¡Œæ—¶æ£€æŸ¥å·¥å…·ï¼Œç”¨äºåˆ¤æ–­å‡½æ•°æ˜¯å¦ä¸ºåç¨‹ç­‰
import json  # JSON ç¼–è§£ç 
import logging  # æ—¥å¿—è®°å½•
import re  # æ­£åˆ™è¡¨è¾¾å¼å¤„ç†
import tempfile  # ä¸´æ—¶æ–‡ä»¶/ç›®å½•æ“ä½œ
import time  # æ—¶é—´ç›¸å…³å‡½æ•°ï¼ˆæ—¶é—´æˆ³ã€ç¡çœ ç­‰ï¼‰
from collections.abc import Awaitable, Callable  # ç±»å‹æç¤ºï¼šå¯ç­‰å¾…å¯¹è±¡å’Œå¯è°ƒç”¨å¯¹è±¡
from pathlib import Path  # è·¯å¾„æ“ä½œçš„é¢å‘å¯¹è±¡æ¥å£
from typing import TYPE_CHECKING, Any, Generic, Literal, TypeVar, cast  # ç±»å‹æç¤ºå·¥å…·
from urllib.parse import urlparse  # URL è§£æ

if TYPE_CHECKING:
	# é˜²æ­¢å¾ªç¯å¯¼å…¥ï¼Œä»…åœ¨ç±»å‹æ£€æŸ¥æ—¶å¯¼å…¥ Skill ç±»å‹
	from browser_use.skills.views import Skill

from dotenv import load_dotenv  # åŠ è½½ .env ç¯å¢ƒå˜é‡æ–‡ä»¶

from browser_use.agent.cloud_events import (
	CreateAgentOutputFileEvent,
	CreateAgentSessionEvent,
	CreateAgentStepEvent,
	CreateAgentTaskEvent,
	UpdateAgentTaskEvent,
)  # å¯¼å…¥ä»£ç†ç›¸å…³çš„äº‘äº‹ä»¶ç±»ï¼Œç”¨äºäº‹ä»¶åˆ†å‘å’Œè®°å½•
from browser_use.agent.message_manager.utils import save_conversation  # ä¿å­˜å¯¹è¯åˆ°æ–‡ä»¶çš„å·¥å…·
from browser_use.llm.base import BaseChatModel  # æŠ½è±¡çš„èŠå¤©æ¨¡å‹åŸºç±»ç±»å‹
from browser_use.llm.exceptions import ModelProviderError, ModelRateLimitError  # LLM å¼‚å¸¸ç±»å‹
from browser_use.llm.messages import BaseMessage, ContentPartImageParam, ContentPartTextParam, UserMessage  # LLM æ¶ˆæ¯ç±»å‹
from browser_use.tokens.service import TokenCost  # ä»¤ç‰Œ/è´¹ç”¨ç»Ÿè®¡æœåŠ¡

load_dotenv()  # ä» .env æ–‡ä»¶åŠ è½½ç¯å¢ƒå˜é‡ï¼ˆä¾‹å¦‚ API keysï¼‰

from bubus import EventBus  # äº‹ä»¶æ€»çº¿å®ç°ï¼Œç”¨äºè¿›ç¨‹å†…äº‹ä»¶åˆ†å‘
from pydantic import BaseModel, ValidationError  # Pydantic ç”¨äºæ¨¡å‹éªŒè¯ä¸é”™è¯¯ç±»å‹
from uuid_extensions import uuid7str  # ç”Ÿæˆå¯æ’åº/çŸ­çš„ UUID å­—ç¬¦ä¸²

from browser_use import Browser, BrowserProfile, BrowserSession  # æµè§ˆå™¨ç›¸å…³ç±»ï¼ˆä¼šè¯ã€é…ç½®ï¼‰
from browser_use.agent.judge import construct_judge_messages  # æ„é€ ç”¨äº Judge çš„æ¶ˆæ¯å·¥å…·

# å»¶è¿Ÿå¯¼å…¥ gif ä»¥é¿å…å¯åŠ¨æ—¶å¼•å…¥è¿‡å¤šä¾èµ–
# from browser_use.agent.gif import create_history_gif
from browser_use.agent.message_manager.service import (
	MessageManager,
)  # æ¶ˆæ¯ç®¡ç†å™¨æœåŠ¡ï¼Œè´Ÿè´£æ„å»ºå‘é€ç»™ LLM çš„æ¶ˆæ¯ä¸Šä¸‹æ–‡
from browser_use.agent.prompts import SystemPrompt  # ç³»ç»Ÿæç¤ºæ„é€ å™¨
from browser_use.agent.views import (
	ActionResult,
	AgentError,
	AgentHistory,
	AgentHistoryList,
	AgentOutput,
	AgentSettings,
	AgentState,
	AgentStepInfo,
	AgentStructuredOutput,
	BrowserStateHistory,
	DetectedVariable,
	JudgementResult,
	StepMetadata,
)  # ä»£ç†ç›¸å…³çš„è§†å›¾/æ•°æ®æ¨¡å‹å¯¼å…¥ï¼ˆå†å²ã€è¾“å‡ºã€è®¾ç½®ç­‰ï¼‰
from browser_use.browser.session import DEFAULT_BROWSER_PROFILE  # é»˜è®¤æµè§ˆå™¨é…ç½®
from browser_use.browser.views import BrowserStateSummary  # æµè§ˆå™¨çŠ¶æ€æ‘˜è¦æ¨¡å‹
from browser_use.config import CONFIG  # å…¨å±€é…ç½®
from browser_use.dom.views import DOMInteractedElement, MatchLevel  # DOM äº¤äº’å…ƒç´ è¡¨ç¤ºå’ŒåŒ¹é…å±‚çº§æšä¸¾
from browser_use.filesystem.file_system import FileSystem  # æ–‡ä»¶ç³»ç»ŸæŠ½è±¡ï¼Œç”¨äºæŒä¹…åŒ–æå–å†…å®¹ç­‰
from browser_use.observability import observe, observe_debug  # è§‚å¯Ÿ/åŸ‹ç‚¹è£…é¥°å™¨
from browser_use.telemetry.service import ProductTelemetry  # äº§å“é¥æµ‹æœåŠ¡
from browser_use.telemetry.views import AgentTelemetryEvent  # é¥æµ‹äº‹ä»¶æ¨¡å‹
from browser_use.tools.registry.views import ActionModel  # åŠ¨æ€åŠ¨ä½œæ¨¡å‹ç±»å‹
from browser_use.tools.service import Tools  # å·¥å…·æ³¨å†Œä¸æ‰§è¡ŒæœåŠ¡
from browser_use.utils import (
	URL_PATTERN,
	_log_pretty_path,
	check_latest_browser_use_version,
	get_browser_use_version,
	time_execution_async,
	time_execution_sync,
)  # è‹¥å¹²å·¥å…·å‡½æ•°ä¸å¸¸é‡ï¼ˆURL æ­£åˆ™ã€ç‰ˆæœ¬æ£€æŸ¥ã€è®¡æ—¶è£…é¥°å™¨ç­‰ï¼‰

logger = logging.getLogger(__name__)  # è·å–æ¨¡å—çº§ loggerï¼Œç”¨äºè®°å½•æ¨¡å—å†…éƒ¨æ—¥å¿—


def log_response(response: AgentOutput, registry=None, logger=None) -> None:
	"""Utility function to log the model's response."""

	# Use module logger if no logger provided
	if logger is None:
		logger = logging.getLogger(__name__)

	# Only log thinking if it's present
	if response.current_state.thinking:
		logger.debug(f'ğŸ’¡ Thinking:\n{response.current_state.thinking}')

	# Only log evaluation if it's not empty
	eval_goal = response.current_state.evaluation_previous_goal
	if eval_goal:
		if 'success' in eval_goal.lower():
			emoji = 'ğŸ‘'
			# Green color for success
			logger.info(f'  \033[32m{emoji} Eval: {eval_goal}\033[0m')
		elif 'failure' in eval_goal.lower():
			emoji = 'âš ï¸'
			# Red color for failure
			logger.info(f'  \033[31m{emoji} Eval: {eval_goal}\033[0m')
		else:
			emoji = 'â”'
			# No color for unknown/neutral
			logger.info(f'  {emoji} Eval: {eval_goal}')

	# Always log memory if present
	if response.current_state.memory:
		logger.info(f'  ğŸ§  Memory: {response.current_state.memory}')

	# Only log next goal if it's not empty
	next_goal = response.current_state.next_goal
	if next_goal:
		# Blue color for next goal
		logger.info(f'  \033[34mğŸ¯ Next goal: {next_goal}\033[0m')

# Contextï¼šæ˜¯ä½ ç»™è¿™ä¸ªç±»å‹å˜é‡èµ·çš„åå­—ï¼ˆé€šå¸¸å¤§å†™ï¼Œå’Œå˜é‡åä¸€è‡´ï¼Œä¾¿äºè¯†
Context = TypeVar('Context')


AgentHookFunc = Callable[['Agent'], Awaitable[None]]


class Agent(Generic[Context, AgentStructuredOutput]):
	"""
	Agent ç±» - æµè§ˆå™¨è‡ªåŠ¨åŒ–ä»£ç†çš„æ ¸å¿ƒç±»
	
	è¿™æ˜¯ä¸€ä¸ªæ³›å‹ç±»ï¼Œæ¥å—ä¸¤ä¸ªç±»å‹å‚æ•°ï¼š
	- Context: ä¸Šä¸‹æ–‡ç±»å‹ï¼Œç”¨äºä¼ é€’è‡ªå®šä¹‰æ•°æ®
	- AgentStructuredOutput: ç»“æ„åŒ–è¾“å‡ºç±»å‹ï¼Œå®šä¹‰ Agent è¿”å›çš„æ•°æ®æ ¼å¼
	
	Agent é€šè¿‡ LLM å†³ç­–ï¼Œè‡ªåŠ¨æ‰§è¡Œæµè§ˆå™¨æ“ä½œæ¥å®Œæˆç”¨æˆ·æŒ‡å®šçš„ä»»åŠ¡
	"""
	# ç»™å‡½æ•° / æ–¹æ³•æ·»åŠ  â€œæ‰§è¡Œæ—¶é—´ç»Ÿè®¡â€ çš„åŠŸèƒ½ï¼Œä¸”ä¼ å…¥äº† '--init' ä½œä¸ºæ ‡è¯†å‚æ•° 
	@time_execution_sync('--init')
	def __init__(
		self,
		task: str,  # ç”¨æˆ·ä»»åŠ¡æè¿°
		llm: BaseChatModel | None = None,  # è¯­è¨€æ¨¡å‹ï¼Œç”¨äºå†³ç­–
		# Optional parameters - å¯é€‰å‚æ•°
		browser_profile: BrowserProfile | None = None,  # æµè§ˆå™¨é…ç½®æ–‡ä»¶
		browser_session: BrowserSession | None = None,  # æµè§ˆå™¨ä¼šè¯
		browser: Browser | None = None,  # browser_session çš„åˆ«åï¼ˆæ¨èä½¿ç”¨ï¼‰
		tools: Tools[Context] | None = None,  # å·¥å…·æ³¨å†Œè¡¨
		controller: Tools[Context] | None = None,  # tools çš„åˆ«åï¼ˆå·²åºŸå¼ƒï¼‰
		# Skills integration
		skill_ids: list[str | Literal['*']] | None = None,
		skills: list[str | Literal['*']] | None = None,  # Alias for skill_ids
		skill_service: Any | None = None,
		# Initial agent run parameters
		sensitive_data: dict[str, str | dict[str, str]] | None = None,
		initial_actions: list[dict[str, dict[str, Any]]] | None = None,
		# Cloud Callbacks
		register_new_step_callback: (
			Callable[['BrowserStateSummary', 'AgentOutput', int], None]  # Sync callback
			| Callable[['BrowserStateSummary', 'AgentOutput', int], Awaitable[None]]  # Async callback
			| None
		) = None,
		register_done_callback: (
			Callable[['AgentHistoryList'], Awaitable[None]]  # Async Callback
			| Callable[['AgentHistoryList'], None]  # Sync Callback
			| None
		) = None,
		register_external_agent_status_raise_error_callback: Callable[[], Awaitable[bool]] | None = None,
		register_should_stop_callback: Callable[[], Awaitable[bool]] | None = None,
		# Agent settings
		output_model_schema: type[AgentStructuredOutput] | None = None,
		use_vision: bool | Literal['auto'] = True,
		save_conversation_path: str | Path | None = None,
		save_conversation_path_encoding: str | None = 'utf-8',
		max_failures: int = 3,
		override_system_message: str | None = None,
		extend_system_message: str | None = None,
		generate_gif: bool | str = False,
		available_file_paths: list[str] | None = None,
		include_attributes: list[str] | None = None,
		max_actions_per_step: int = 3,
		use_thinking: bool = True,
		flash_mode: bool = False,
		demo_mode: bool | None = None,
		max_history_items: int | None = None,
		page_extraction_llm: BaseChatModel | None = None,
		fallback_llm: BaseChatModel | None = None,
		use_judge: bool = True,
		ground_truth: str | None = None,
		judge_llm: BaseChatModel | None = None,
		injected_agent_state: AgentState | None = None,
		source: str | None = None,
		file_system_path: str | None = None,
		task_id: str | None = None,
		calculate_cost: bool = False,
		display_files_in_done_text: bool = True,
		include_tool_call_examples: bool = False,
		vision_detail_level: Literal['auto', 'low', 'high'] = 'auto',
		llm_timeout: int | None = None,
		step_timeout: int = 120,
		directly_open_url: bool = True,
		include_recent_events: bool = False,
		# å¼€å…³å‚æ•°ï¼šæ˜¯å¦é‡‡æ ·é¡µé¢å›¾ç‰‡ï¼ˆè§†è§‰æ¨¡å¼ä¸‹å‡å°‘å›¾ç‰‡æ•°é‡ï¼ŒèŠ‚çœ Tokenï¼‰
		sample_images: list[ContentPartTextParam | ContentPartImageParam] | None = None,
		final_response_after_failure: bool = True,
		llm_screenshot_size: tuple[int, int] | None = None,
		_url_shortening_limit: int = 25,
		**kwargs,
	):
		# éªŒè¯ llm_screenshot_size å¤§å°
		if llm_screenshot_size is not None:
			if not isinstance(llm_screenshot_size, tuple) or len(llm_screenshot_size) != 2:
				raise ValueError('llm_screenshot_size must be a tuple of (width, height)')
			width, height = llm_screenshot_size
			if not isinstance(width, int) or not isinstance(height, int):
				raise ValueError('llm_screenshot_size dimensions must be integers')
			if width < 100 or height < 100:
				raise ValueError('llm_screenshot_size dimensions must be at least 100 pixels')
			self.logger.info(f'ğŸ–¼ï¸  LLM screenshot resizing enabled: {width}x{height}')
		if llm is None:
			default_llm_name = CONFIG.DEFAULT_LLM
			if default_llm_name:
				from browser_use.llm.models import get_llm_by_name

				llm = get_llm_by_name(default_llm_name)
			else:
				# No default LLM specified, use the original default
				from browser_use import ChatBrowserUse

				llm = ChatBrowserUse()

		# å¦‚æœæ˜¯ ChatBrowserUse åˆ™è®¾ç½®å¿«é€Ÿæ¨¡å¼ï¼š set flashmode = True if llm is ChatBrowserUse
		if llm.provider == 'browser-use':
			flash_mode = True
			# è¯¥æ¨¡å¼é€šå¸¸æ˜¯ browser-use ä¼˜åŒ–çš„ â€œå¿«é€Ÿå“åº”æ¨¡å¼â€â€”â€” æ¯”å¦‚ç¼“å­˜å¸¸ç”¨æŒ‡ä»¤ã€ç²¾ç®€ä¸Šä¸‹æ–‡ã€æå‡ LLM å†³ç­–é€Ÿåº¦ï¼Œé€‚é…æµè§ˆå™¨è‡ªåŠ¨åŒ–çš„ä½å»¶è¿Ÿéœ€æ±‚

		# å½“æœªæŒ‡å®š LLM æˆªå›¾å°ºå¯¸æ—¶ï¼Œé’ˆå¯¹ Claude Sonnet æ¨¡å‹è‡ªåŠ¨é…ç½®ä¸“å±çš„æˆªå›¾å°ºå¯¸ï¼šAuto-configure llm_screenshot_size for Claude Sonnet models
		if llm_screenshot_size is None:
			model_name = getattr(llm, 'model', '')
			if isinstance(model_name, str) and model_name.startswith('claude-sonnet'):
				llm_screenshot_size = (1400, 850)
				logger.info('ğŸ–¼ï¸  Auto-configured LLM screenshot size for Claude Sonnet: 1400x850')
		# è®¾ç½®é¡µé¢æå– LLM å’Œ åˆ¤æ–­è¯„ä¼° LLM
		if page_extraction_llm is None:
			page_extraction_llm = llm
		if judge_llm is None:
			judge_llm = llm
		# åˆå§‹åŒ–å¯ç”¨æ–‡ä»¶è·¯å¾„
		if available_file_paths is None:
			available_file_paths = []

		# Set timeout based on model name if not explicitly provided
		if llm_timeout is None:

			def _get_model_timeout(llm_model: BaseChatModel) -> int:
				"""Determine timeout based on model name"""
				model_name = getattr(llm_model, 'model', '').lower()
				if 'gemini' in model_name:
					if '3-pro' in model_name:
						return 90
					return 45
				elif 'groq' in model_name:
					return 30
				elif 'o3' in model_name or 'claude' in model_name or 'sonnet' in model_name or 'deepseek' in model_name:
					return 90
				else:
					return 60  # Default timeout

			llm_timeout = _get_model_timeout(llm)

		# åˆ›å»ºä»»åŠ¡ ID å’Œ ä¼šè¯ID
		self.id = task_id or uuid7str()
		self.task_id: str = self.id
		self.session_id: str = uuid7str()
		# åˆ›å»ºæµè§ˆå™¨ç®¡ç†çš„é…ç½®å‚æ•°
		base_profile = browser_profile or DEFAULT_BROWSER_PROFILE
		if base_profile is DEFAULT_BROWSER_PROFILE:
			base_profile = base_profile.model_copy()
		if demo_mode is not None and base_profile.demo_mode != demo_mode:
			base_profile = base_profile.model_copy(update={'demo_mode': demo_mode})
		browser_profile = base_profile

		# Handle browser vs browser_session parameter (browser takes precedence)
		if browser and browser_session:
			raise ValueError('Cannot specify both "browser" and "browser_session" parameters. Use "browser" for the cleaner API.')
		browser_session = browser or browser_session

		if browser_session is not None and demo_mode is not None and browser_session.browser_profile.demo_mode != demo_mode:
			browser_session.browser_profile = browser_session.browser_profile.model_copy(update={'demo_mode': demo_mode})

		self.browser_session = browser_session or BrowserSession(
			browser_profile=browser_profile,
			id=uuid7str()[:-4] + self.id[-4:],  # re-use the same 4-char suffix so they show up together in logs
		)

		self._demo_mode_enabled: bool = bool(self.browser_profile.demo_mode) if self.browser_session else False
		if self._demo_mode_enabled and getattr(self.browser_profile, 'headless', False):
			self.logger.warning(
				'Demo mode is enabled but the browser is headless=True; set headless=False to view the in-browser panel.'
			)

		# Initialize available file paths as direct attribute
		self.available_file_paths = available_file_paths

		# è®¾ç½®é»˜è®¤Toolsï¼šSet up tools first (needed to detect output_model_schema)
		if tools is not None:
			self.tools = tools
		elif controller is not None:
			self.tools = controller
		else:
			# å½“ LLM çš„è§†è§‰æ¨¡å¼ï¼ˆuse_visionï¼‰ä¸æ˜¯ â€œè‡ªåŠ¨â€ æ¨¡å¼æ—¶ï¼Œä» Agent çš„å·¥å…·é›†ä¸­ç§»é™¤æˆªå›¾å·¥å…·ï¼ˆé¿å… Agent è°ƒç”¨æˆªå›¾ä½† LLM æ— æ³•è§£æè§†è§‰å†…å®¹ï¼‰ï¼›å¦‚æœæ˜¯è‡ªåŠ¨æ¨¡å¼ï¼Œåˆ™ä¿ç•™æˆªå›¾å·¥å…·ï¼ˆè®© Agent è‡ªä¸»å†³å®šæ˜¯å¦æˆªå›¾ï¼‰
			# Exclude screenshot tool when use_vision is not auto
			exclude_actions = ['screenshot'] if use_vision != 'auto' else []
			# display_files_in_done_textï¼šAgent å®Œæˆä»»åŠ¡åï¼Œæ˜¯å¦åœ¨æœ€ç»ˆçš„ç»“æœæ–‡æœ¬ä¸­æ˜¾ç¤ºç›¸å…³æ–‡ä»¶è·¯å¾„
			self.tools = Tools(exclude_actions=exclude_actions, display_files_in_done_text=display_files_in_done_text)

		# Enforce screenshot exclusion when use_vision != 'auto', even if user passed custom tools
		if use_vision != 'auto':
			self.tools.exclude_action('screenshot')

		# è‡ªåŠ¨æ£€æµ‹ LLM æ¨¡å‹æ˜¯å¦æ”¯æŒåæ ‡ç‚¹å‡»ï¼Œè‹¥æ”¯æŒåˆ™å¼€å¯å·¥å…·é›†çš„åæ ‡ç‚¹å‡»åŠŸèƒ½ Enable coordinate clicking for models that support it
		# ä¸€äº›é«˜çº§å¤§æ¨¡å‹ï¼Œèƒ½ç›´æ¥è¾“å‡ºç›®æ ‡å…ƒç´ çš„åæ ‡ä½ç½®ï¼Œå¦‚ï¼šClaude Sonnet 4
		model_name = getattr(llm, 'model', '').lower()
		supports_coordinate_clicking = any(
			pattern in model_name for pattern in ['claude-sonnet-4', 'claude-opus-4', 'gemini-3-pro', 'browser-use/']
		)
		if supports_coordinate_clicking:
			self.tools.set_coordinate_clicking(True)

		# è§£å†³ skills å’Œ skill_ids ä¸¤ä¸ªå‚æ•°çš„å†²çªé—®é¢˜ï¼Œä¸”è®© skills å‚æ•°æ‹¥æœ‰æ›´é«˜ä¼˜å…ˆçº§ ---- Handle skills vs skill_ids parameter (skills takes precedence)
		if skills and skill_ids:
			raise ValueError('Cannot specify both "skills" and "skill_ids" parameters. Use "skills" for the cleaner API.')
		skill_ids = skills or skill_ids

		# SkillæœåŠ¡é›†æˆï¼šä¼˜å…ˆä½¿ç”¨å¤–éƒ¨æ³¨å…¥çš„ skill_service å®ä¾‹ï¼Œè‹¥æœªæ³¨å…¥åˆ™åŸºäº skill_ids è‡ªè¡Œåˆ›å»º SkillService å®ä¾‹ -- Skills integration - use injected service or create from skill_ids
		self.skill_service = None
		self._skills_registered = False
		if skill_service is not None:
			self.skill_service = skill_service
		elif skill_ids:
			from browser_use.skills import SkillService

			self.skill_service = SkillService(skill_ids=skill_ids)

		# ç»Ÿä¸€ Agent å’Œ Tools å±‚çš„ç»“æ„åŒ–è¾“å‡ºæ¨¡å‹ï¼Œä¼˜å…ˆä½¿ç”¨ Agent æ˜¾å¼æŒ‡å®šçš„æ¨¡å‹ï¼Œè‹¥æ— åˆ™å¤ç”¨ Tools å±‚çš„æ¨¡å‹ï¼ŒåŒæ—¶å¤„ç†æ¨¡å‹ä¸ä¸€è‡´çš„è­¦å‘Š------Structured output - use explicit param or detect from tools
		tools_output_model = self.tools.get_output_model()
		if output_model_schema is not None and tools_output_model is not None:
			# Both provided - warn if they differ
			if output_model_schema is not tools_output_model:
				logger.warning(
					f'output_model_schema ({output_model_schema.__name__}) differs from Tools output_model '
					f'({tools_output_model.__name__}). Using Agent output_model_schema.'
				)
		elif output_model_schema is None and tools_output_model is not None:
			# Only tools has it - use that (cast is safe: both are BaseModel subclasses)
			output_model_schema = cast(type[AgentStructuredOutput], tools_output_model)
		self.output_model_schema = output_model_schema
		if self.output_model_schema is not None:
			self.tools.use_structured_output_action(self.output_model_schema)

		# Core components - task enhancement now has access to output_model_schema from tools
		# å¢å¼ºä»»åŠ¡åŒ…è£…å™¨ï¼šä¼ å…¥ taskï¼ˆåŸå§‹ä»»åŠ¡ï¼‰å’Œ output_model_schemaï¼ˆå‰æ–‡ç»Ÿä¸€çš„ç»“æ„åŒ–è¾“å‡ºæ¨¡å‹ï¼‰ï¼Œä¿è¯å¢å¼ºé€»è¾‘ä¸€å®šèƒ½è·å–åˆ°æ ¼å¼çº¦æŸçš„ä¾æ®
		self.task = self._enhance_task_with_schema(task, output_model_schema)
		self.llm = llm
		self.judge_llm = judge_llm

		# å…œåº• LLMï¼ˆFallback LLMï¼‰é…ç½® ---- Fallback LLM configuration
		# å½“ä¸» LLMï¼ˆself._original_llmï¼‰ å‡ºç°æ•…éšœï¼ˆè¶…æ—¶ã€æŠ¥é”™ã€è¿”å›æ ¼å¼å¼‚å¸¸ï¼‰æ—¶ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ° self._fallback_llm ç»§ç»­æ‰§è¡Œä»»åŠ¡
		self._fallback_llm: BaseChatModel | None = fallback_llm
		self._using_fallback_llm: bool = False
		self._original_llm: BaseChatModel = llm  # Store original for reference
		self.directly_open_url = directly_open_url
		self.include_recent_events = include_recent_events
		self._url_shortening_limit = _url_shortening_limit

		self.sensitive_data = sensitive_data

		self.sample_images = sample_images

		self.settings = AgentSettings(
			use_vision=use_vision,
			vision_detail_level=vision_detail_level,
			save_conversation_path=save_conversation_path,
			save_conversation_path_encoding=save_conversation_path_encoding,
			max_failures=max_failures,
			override_system_message=override_system_message,
			extend_system_message=extend_system_message,
			generate_gif=generate_gif,
			include_attributes=include_attributes,
			max_actions_per_step=max_actions_per_step,
			use_thinking=use_thinking,
			flash_mode=flash_mode,
			max_history_items=max_history_items,
			page_extraction_llm=page_extraction_llm,
			calculate_cost=calculate_cost,
			include_tool_call_examples=include_tool_call_examples,
			llm_timeout=llm_timeout,
			step_timeout=step_timeout,
			final_response_after_failure=final_response_after_failure,
			use_judge=use_judge,
			ground_truth=ground_truth,
		)

		# Token cost service
		self.token_cost_service = TokenCost(include_cost=calculate_cost)
		self.token_cost_service.register_llm(llm)
		self.token_cost_service.register_llm(page_extraction_llm)
		self.token_cost_service.register_llm(judge_llm)

		# ä¼˜å…ˆä½¿ç”¨å¤–éƒ¨æ³¨å…¥çš„ Agent çŠ¶æ€ï¼ˆä¿è¯çŠ¶æ€å¤ç”¨ / æ¢å¤ï¼‰ï¼Œå¦åˆ™åˆå§‹åŒ–å…¨æ–°çŠ¶æ€ï¼›
		# åŒæ—¶åˆ›å»ºç©ºçš„ Agent äº¤äº’å†å²åˆ—è¡¨ï¼Œç”¨äºè®°å½•å¯¹è¯ã€æ“ä½œã€æˆæœ¬ç­‰ä¿¡æ¯
		# Initialize state
		self.state = injected_agent_state or AgentState()

		# Initialize history
		self.history = AgentHistoryList(history=[], usage=None)

		# Initialize agent directory
		import time

		timestamp = int(time.time())
		base_tmp = Path(tempfile.gettempdir())
		self.agent_directory = base_tmp / f'browser_use_agent_{self.id}_{timestamp}'

		# Initialize file system and screenshot service
		# ä¸ºæ¯ä¸ª Agent å®ä¾‹åˆ›å»ºå”¯ä¸€çš„ä¸´æ—¶ç›®å½•ï¼ˆåŸºäºç³»ç»Ÿä¸´æ—¶ç›®å½• + Agent ID + æ—¶é—´æˆ³ï¼‰ï¼Œç”¨äºå­˜å‚¨è¯¥ Agent è¿è¡Œè¿‡ç¨‹ä¸­äº§ç”Ÿçš„ä¸´æ—¶æ–‡ä»¶ï¼ˆæˆªå›¾ã€å½•å±ã€å¯¹è¯è®°å½•ç­‰ï¼‰â€
		self._set_file_system(file_system_path)
		# ä½¿ç”¨Agentçš„ä¸´æ—¶ç›®å½•åˆå§‹åŒ–æˆªå›¾æœåŠ¡
		self._set_screenshot_service()

		# è®¾ç½®Actionæ­¥éª¤æ‰§è¡Œçš„æ¨¡å‹-è¿›è¡Œåˆå§‹åŒ–ï¼šAction setup
		self._setup_action_models()
		# è®°å½• Agent çš„ç‰ˆæœ¬ä¿¡æ¯å’Œæ¥æºæ ‡è¯†ï¼ˆç”¨äºæº¯æºã€å…¼å®¹æ€§é€‚é…ï¼‰
		self._set_browser_use_version_and_source(source)

		initial_url = None

		# only load url if no initial actions are provided
		# å½“æ»¡è¶³ç‰¹å®šæ¡ä»¶ï¼ˆå¼€å¯ç›´æ¥æ‰“å¼€ URLã€æ— åç»­ä»»åŠ¡ã€æ— åˆå§‹åŠ¨ä½œï¼‰æ—¶
		if self.directly_open_url and not self.state.follow_up_task and not initial_actions:
			initial_url = self._extract_start_url(self.task)
			if initial_url:
				self.logger.info(f'ğŸ”— Found URL in task: {initial_url}, adding as initial action...')
				initial_actions = [{'navigate': {'url': initial_url, 'new_tab': False}}]

		self.initial_url = initial_url
		# ä»ä»»åŠ¡ä¸­æå–èµ·å§‹ URL å¹¶ç”Ÿæˆå¯¹åº”çš„å¯¼èˆªåŠ¨ä½œï¼Œä¹‹åå¤„ç†åˆå§‹åŠ¨ä½œæ ¼å¼å¹¶éªŒè¯ LLMï¼ˆå¤§è¯­è¨€æ¨¡å‹ï¼‰çš„è¿æ¥çŠ¶æ€
		self.initial_actions = self._convert_initial_actions(initial_actions) if initial_actions else None
		# éªŒè¯APIkeyçš„æœ‰æ•ˆæ€§Verify we can connect to the model
		self._verify_and_setup_llm()

		# TODO: move this logic to the LLMs
		# Handle users trying to use use_vision=True with DeepSeek models
		# é’ˆå¯¹ DeepSeek æ¨¡å‹çš„å…¼å®¹æ€§å¤„ç†é€»è¾‘ï¼Œæ ¸å¿ƒä½œç”¨æ˜¯ï¼šå½“æ£€æµ‹åˆ°å½“å‰ä½¿ç”¨çš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ˜¯ DeepSeek ç³»åˆ—æ—¶ï¼Œè‡ªåŠ¨å…³é—­è§†è§‰åŠŸèƒ½ï¼ˆuse_visionï¼‰ï¼Œå¹¶ç»™å‡ºè­¦å‘Šæ—¥å¿—ï¼ŒåŒæ—¶å¤‡æ³¨äº†åç»­éœ€è¦å°†è¿™ä¸ªé€»è¾‘è¿ç§»åˆ° LLM ç›¸å…³æ¨¡å—ä¸­
		if 'deepseek' in self.llm.model.lower():
			self.logger.warning('âš ï¸ DeepSeek models do not support use_vision=True yet. Setting use_vision=False for now...')
			self.settings.use_vision = False

		# Handle users trying to use use_vision=True with XAI models that don't support it
		# grok-3 variants and grok-code don't support vision; grok-2 and grok-4 do
		# é’ˆå¯¹ XAI ç³»åˆ—æ¨¡å‹åšè§†è§‰åŠŸèƒ½ï¼ˆuse_visionï¼‰çš„å…¼å®¹æ€§å¤„ç† â€”â€” æ˜ç¡®åŒºåˆ†å“ªäº› XAI æ¨¡å‹æ”¯æŒè§†è§‰ã€å“ªäº›ä¸æ”¯æŒï¼ˆgrok-3 å˜ä½“å’Œ grok-code ä¸æ”¯æŒï¼Œgrok-2 å’Œ grok-4 æ”¯æŒï¼‰ï¼Œä»è€Œé¿å…ç”¨æˆ·é”™è¯¯å¼€å¯ä¸æ”¯æŒçš„è§†è§‰åŠŸèƒ½å¯¼è‡´ç¨‹åºå¼‚å¸¸
		model_lower = self.llm.model.lower()
		if 'grok-3' in model_lower or 'grok-code' in model_lower:
			self.logger.warning('âš ï¸ This XAI model does not support use_vision=True yet. Setting use_vision=False for now...')
			self.settings.use_vision = False

		logger.debug(
			f'{" +vision" if self.settings.use_vision else ""}'
			f' extraction_model={self.settings.page_extraction_llm.model if self.settings.page_extraction_llm else "Unknown"}'
			f'{" +file_system" if self.file_system else ""}'
		)

		# Store llm_screenshot_size in browser_session so tools can access it
		self.browser_session.llm_screenshot_size = llm_screenshot_size

		# ä¸€æ˜¯æ£€æµ‹å½“å‰ä½¿ç”¨çš„ LLM æ˜¯å¦æ˜¯ Anthropic ç³»åˆ—æ¨¡å‹çš„å®ä¾‹ï¼Œ
		# äºŒæ˜¯æ£€æµ‹æ¨¡å‹æ˜¯å¦ä¸º browser-use å¾®è°ƒç‰ˆæœ¬ï¼ˆè¿™ç±»æ¨¡å‹ä½¿ç”¨ç®€åŒ–çš„æç¤ºè¯æ ¼å¼ï¼‰ï¼Œä¸ºåç»­é€‚é…ä¸åŒæ¨¡å‹çš„æç¤ºè¯é€»è¾‘åšå‡†å¤‡
		# Check if LLM is ChatAnthropic instance
		from browser_use.llm.anthropic.chat import ChatAnthropic

		is_anthropic = isinstance(self.llm, ChatAnthropic)

		# Check if model is a browser-use fine-tuned model (uses simplified prompts)
		is_browser_use_model = 'browser-use/' in self.llm.model.lower()

		# Initialize message manager with state
		# åŒ…å«æ‰€æœ‰åŠ¨ä½œçš„åˆå§‹ç³»ç»Ÿæç¤º â€”â€” ä¼šåœ¨æ¯ä¸ªæ­¥éª¤ä¸­æ›´æ–°â€ï¼Œæ˜ç¡®äº† MessageManager çš„åˆå§‹åŒ–ç›®çš„å’Œç³»ç»Ÿæç¤ºçš„åŠ¨æ€ç‰¹æ€§
		# åˆå§‹åŒ–ä¸€ä¸ª MessageManagerï¼ˆæ¶ˆæ¯ç®¡ç†å™¨ï¼‰å®ä¾‹ï¼Œå®ƒä¼šæ•´åˆä»»åŠ¡ã€ç³»ç»Ÿæç¤ºã€é…ç½®é¡¹ã€çŠ¶æ€ç­‰æ ¸å¿ƒä¿¡æ¯ï¼Œä¸ºåç»­æ™ºèƒ½ä½“å’Œå¤§è¯­è¨€æ¨¡å‹çš„äº¤äº’ï¼ˆå¦‚ç”Ÿæˆæç¤ºè¯ã€ç®¡ç†å¯¹è¯å†å²ï¼‰æä¾›ç»Ÿä¸€çš„æ¶ˆæ¯ç®¡ç†èƒ½åŠ›
		self._message_manager = MessageManager(
			# ä»»åŠ¡æè¿°
			task=self.task,
			# è°ƒç”¨ get_system_message() æ–¹æ³•ï¼Œç”Ÿæˆæœ€ç»ˆçš„ç³»ç»Ÿæç¤ºè¯å­—ç¬¦ä¸²ï¼Œä¼ å…¥ MessageManager
			system_message=SystemPrompt(
				# æ¯ä¸€æ­¥å…è®¸æ‰§è¡Œçš„æœ€å¤§åŠ¨ä½œæ•°ï¼ˆæ§åˆ¶æ™ºèƒ½ä½“å•æ¬¡è¾“å‡ºçš„åŠ¨ä½œæ•°é‡ï¼‰ï¼›
				max_actions_per_step=self.settings.max_actions_per_step,
				# åˆ†åˆ«ç”¨äº â€œè¦†ç›–é»˜è®¤ç³»ç»Ÿæç¤ºâ€ å’Œ â€œæ‰©å±•é»˜è®¤ç³»ç»Ÿæç¤ºâ€ï¼ˆçµæ´»å®šåˆ¶æç¤ºè¯ï¼‰
				override_system_message=override_system_message,
				extend_system_message=extend_system_message,
				# å…³è”ä¹‹å‰çš„è¿è¡Œæ¨¡å¼ï¼ˆæ€è€ƒæ¨¡å¼ / å¿«é€Ÿæ¨¡å¼ï¼‰ï¼Œé€‚é…æç¤ºè¯æ ¼å¼ï¼›
				use_thinking=self.settings.use_thinking,
				flash_mode=self.settings.flash_mode,
				# å…³è”ä¹‹å‰è¯†åˆ«çš„æ¨¡å‹ç‰¹å¾ï¼Œç”Ÿæˆé€‚é… Anthropic æ¨¡å‹ / æµè§ˆå™¨å¾®è°ƒæ¨¡å‹çš„æç¤ºè¯ï¼›
				is_anthropic=is_anthropic,
				is_browser_use_model=is_browser_use_model,
			).get_system_message(),
			# ä¼ å…¥æ–‡ä»¶ç³»ç»Ÿå®ä¾‹ï¼šå…è®¸æ¶ˆæ¯ç®¡ç†å™¨è®¿é—® / æ“ä½œæ–‡ä»¶ï¼ˆå¦‚è¯»å–æœ¬åœ°æ–‡ä»¶ã€ä¿å­˜äº¤äº’æ—¥å¿—ï¼‰
			file_system=self.file_system,
			# ä¼ å…¥å†å²çŠ¶æ€ï¼šæ¢å¤æ¶ˆæ¯ç®¡ç†å™¨çš„å†å²çŠ¶æ€ï¼ˆå¦‚ä¹‹å‰çš„å¯¹è¯å†å²ã€å·²æ‰§è¡ŒåŠ¨ä½œï¼‰ï¼Œä¿è¯çŠ¶æ€çš„è¿ç»­æ€§ï¼ˆæ¯”å¦‚æ™ºèƒ½ä½“é‡å¯åèƒ½æ¥ç»­ä¹‹å‰çš„äº¤äº’ï¼‰
			state=self.state.message_manager_state,
			# ä¼ å…¥æ€è€ƒæ¨¡å¼é…ç½®ï¼šæ§åˆ¶æ¶ˆæ¯ç®¡ç†å™¨æ˜¯å¦åœ¨å¯¹è¯å†å²ä¸­ä¿ç•™ â€œæ€è€ƒè¿‡ç¨‹â€ï¼ˆå¼€å¯åä¼šè®°å½•æ™ºèƒ½ä½“çš„æ¨ç†é€»è¾‘ï¼‰ã€‚
			use_thinking=self.settings.use_thinking,
			# Settings that were previously in MessageManagerSettings
			# æ˜¯å¦åœ¨æç¤ºè¯ä¸­åŒ…å«æ™ºèƒ½ä½“ / ä»»åŠ¡çš„å±æ€§ä¿¡æ¯ï¼›
			include_attributes=self.settings.include_attributes,
			# æ•æ„Ÿæ•°æ®ï¼ˆç”¨äºæç¤ºè¯ä¸­è„±æ•æˆ–è¿‡æ»¤ï¼‰
			sensitive_data=sensitive_data,
			# å¯¹è¯å†å²çš„æœ€å¤§ä¿å­˜æ¡æ•°ï¼ˆé¿å…å†å²è¿‡é•¿å¯¼è‡´æç¤ºè¯è¶…é™ï¼‰ï¼›
			max_history_items=self.settings.max_history_items,
			# è§†è§‰åŠŸèƒ½çš„ç»†èŠ‚çº§åˆ«ï¼ˆæ§åˆ¶æˆªå›¾ / å›¾ç‰‡çš„æè¿°ç²’åº¦ï¼‰ï¼›
			vision_detail_level=self.settings.vision_detail_level,
			# æ˜¯å¦åœ¨æç¤ºè¯ä¸­åŒ…å«å·¥å…·è°ƒç”¨ç¤ºä¾‹ï¼ˆå¸®åŠ©æ¨¡å‹æ­£ç¡®è°ƒç”¨å·¥å…·ï¼‰ï¼›
			include_tool_call_examples=self.settings.include_tool_call_examples,
			# æ˜¯å¦åŒ…å«è¿‘æœŸäº‹ä»¶ï¼ˆå¦‚æœ€è¿‘æ‰§è¡Œçš„åŠ¨ä½œã€é¡µé¢å˜åŒ–ï¼‰ï¼›
			include_recent_events=self.include_recent_events,
			# ç¤ºä¾‹å›¾ç‰‡ï¼ˆç”¨äºè§†è§‰ä»»åŠ¡çš„å‚è€ƒï¼‰
			sample_images=self.sample_images,
			# ä¼ ç»™ LLM çš„æˆªå›¾å°ºå¯¸ï¼ˆå¹³è¡¡å›¾ç‰‡è´¨é‡å’Œä¼ è¾“æ•ˆç‡ï¼‰ã€‚
			llm_screenshot_size=llm_screenshot_size,
		)
		# æ•æ„Ÿæ•°æ®ï¼ˆsensitive_dataï¼‰çš„å®‰å…¨æ ¡éªŒé€»è¾‘ï¼šå½“æ™ºèƒ½ä½“é…ç½®äº†æ•æ„Ÿæ•°æ®ï¼ˆå¦‚è´¦å·å¯†ç ï¼‰æ—¶ï¼Œé€šè¿‡æ£€æŸ¥æµè§ˆå™¨çš„å…è®¸åŸŸåï¼ˆallowed_domainsï¼‰é…ç½®ï¼Œé˜²èŒƒæ•æ„Ÿæ•°æ®å› æ¶æ„ç½‘ç«™ã€åŸŸåé…ç½®ä¸å½“å¯¼è‡´çš„æ³„éœ²é£é™©ï¼ŒåŒæ—¶å¯¹åŸŸåç‰¹å®šçš„å‡­è¯åšç²¾å‡†çš„åŸŸååŒ¹é…æ ¡éªŒã€‚
		if self.sensitive_data:
			# Check if sensitive_data has domain-specific credentials
			has_domain_specific_credentials = any(isinstance(v, dict) for v in self.sensitive_data.values())

			# If no allowed_domains are configured, show a security warning
			if not self.browser_profile.allowed_domains:
				self.logger.warning(
					'âš ï¸ Agent(sensitive_data=â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢) was provided but Browser(allowed_domains=[...]) is not locked down! âš ï¸\n'
					'          â˜ ï¸ If the agent visits a malicious website and encounters a prompt-injection attack, your sensitive_data may be exposed!\n\n'
					'   \n'
				)

			# If we're using domain-specific credentials, validate domain patterns
			elif has_domain_specific_credentials:
				# For domain-specific format, ensure all domain patterns are included in allowed_domains
				domain_patterns = [k for k, v in self.sensitive_data.items() if isinstance(v, dict)]

				# Validate each domain pattern against allowed_domains
				for domain_pattern in domain_patterns:
					is_allowed = False
					for allowed_domain in self.browser_profile.allowed_domains:
						# Special cases that don't require URL matching
						if domain_pattern == allowed_domain or allowed_domain == '*':
							is_allowed = True
							break

						# Need to create example URLs to compare the patterns
						# Extract the domain parts, ignoring scheme
						pattern_domain = domain_pattern.split('://')[-1] if '://' in domain_pattern else domain_pattern
						allowed_domain_part = allowed_domain.split('://')[-1] if '://' in allowed_domain else allowed_domain

						# Check if pattern is covered by an allowed domain
						# Example: "google.com" is covered by "*.google.com"
						if pattern_domain == allowed_domain_part or (
							allowed_domain_part.startswith('*.')
							and (
								pattern_domain == allowed_domain_part[2:]
								or pattern_domain.endswith('.' + allowed_domain_part[2:])
							)
						):
							is_allowed = True
							break

					if not is_allowed:
						self.logger.warning(
							f'âš ï¸ Domain pattern "{domain_pattern}" in sensitive_data is not covered by any pattern in allowed_domains={self.browser_profile.allowed_domains}\n'
							f'   This may be a security risk as credentials could be used on unintended domains.'
						)

		# Callbacks
		# æ³¨å†Œå›è°ƒå‡½æ•°ï¼šå°†å¤–éƒ¨ä¼ å…¥çš„å„ç±»å›è°ƒå‡½æ•°ç»‘å®šä¸ºå½“å‰å®ä¾‹çš„å±æ€§ï¼Œè®©æ™ºèƒ½ä½“åœ¨æ‰§è¡Œè¿‡ç¨‹ä¸­ï¼ˆå¦‚å¼€å§‹æ–°æ­¥éª¤ã€ä»»åŠ¡å®Œæˆã€éœ€è¦åœæ­¢ç­‰å…³é”®èŠ‚ç‚¹ï¼‰èƒ½è§¦å‘å¯¹åº”çš„è‡ªå®šä¹‰é€»è¾‘
		self.register_new_step_callback = register_new_step_callback
		self.register_done_callback = register_done_callback
		self.register_should_stop_callback = register_should_stop_callback
		self.register_external_agent_status_raise_error_callback = register_external_agent_status_raise_error_callback

		# Telemetry
		# åˆå§‹åŒ–äº§å“é¥æµ‹ï¼ˆTelemetryï¼‰å®ä¾‹ï¼Œå°†é¥æµ‹åŠŸèƒ½ç»‘å®šåˆ°å½“å‰æ™ºèƒ½ä½“ / ç±»å®ä¾‹ä¸­ï¼Œç”¨äºæ”¶é›†äº§å“ä½¿ç”¨è¿‡ç¨‹ä¸­çš„å…³é”®æ•°æ®ï¼ˆå¦‚åŠŸèƒ½è°ƒç”¨ã€æ€§èƒ½æŒ‡æ ‡ã€é”™è¯¯ä¿¡æ¯ç­‰ï¼‰ï¼Œå¸®åŠ©å¼€å‘è€…åˆ†æäº§å“ä½¿ç”¨æƒ…å†µã€å®šä½é—®é¢˜ã€ä¼˜åŒ–ä½“éªŒ
		self.telemetry = ProductTelemetry()

		# Event bus with WAL persistence
		# Default to ~/.config/browseruse/events/{agent_session_id}.jsonl
		# wal_path = CONFIG.BROWSER_USE_CONFIG_DIR / 'events' / f'{self.session_id}.jsonl'
		# åˆå§‹åŒ–å¸¦ WALï¼ˆWrite-Ahead Logï¼Œé¢„å†™å¼æ—¥å¿—ï¼‰æŒä¹…åŒ–çš„äº‹ä»¶æ€»çº¿ï¼ˆEventBusï¼‰å®ä¾‹ï¼Œä¸ºæ™ºèƒ½ä½“çš„äº‹ä»¶ç®¡ç†æä¾› â€œå¯é å­˜å‚¨ + äº‹ä»¶åˆ†å‘â€ èƒ½åŠ› â€”â€” æ—¢ä¿è¯äº‹ä»¶ä¸ä¼šä¸¢å¤±ï¼ˆWAL æŒä¹…åŒ–ï¼‰ï¼Œåˆèƒ½è®©æ™ºèƒ½ä½“å†…éƒ¨æ¨¡å— / å¤–éƒ¨ç»„ä»¶é€šè¿‡äº‹ä»¶æ€»çº¿è§£è€¦é€šä¿¡ï¼ŒåŒæ—¶æ³¨é‡Šè¿˜æ˜ç¡®äº†æŒä¹…åŒ–æ—¥å¿—çš„é»˜è®¤å­˜å‚¨è·¯å¾„
		self.eventbus = EventBus(name=f'Agent_{str(self.id)[-4:]}')

		# å¤„ç†å¹¶éªŒè¯å¯¹è¯ä¿å­˜è·¯å¾„ï¼šå½“é…ç½®äº† save_conversation_pathï¼ˆå¯¹è¯ä¿å­˜è·¯å¾„ï¼‰æ—¶ï¼Œå…ˆå°†è·¯å¾„æ ‡å‡†åŒ–ï¼ˆè§£æç”¨æˆ·ä¸»ç›®å½•ã€è½¬æ¢ä¸ºç»å¯¹è·¯å¾„ï¼‰ï¼Œå†è¾“å‡ºæ—¥å¿—å‘ŠçŸ¥ç”¨æˆ·å¯¹è¯å°†ä¿å­˜åˆ°è¯¥è·¯å¾„ï¼Œä¿è¯è·¯å¾„åœ¨ä¸åŒç¯å¢ƒä¸‹çš„æ­£ç¡®æ€§å’Œå¯è¿½æº¯æ€§
		if self.settings.save_conversation_path:
			self.settings.save_conversation_path = Path(self.settings.save_conversation_path).expanduser().resolve()
			self.logger.info(f'ğŸ’¬ Saving conversation to {_log_pretty_path(self.settings.save_conversation_path)}')

		# Initialize download tracking
		# åˆå§‹åŒ–æ™ºèƒ½ä½“çš„ä¸‹è½½æ–‡ä»¶è·Ÿè¸ªåŠŸèƒ½ï¼šå…ˆæ ¡éªŒæµè§ˆå™¨ä¼šè¯æ˜¯å¦å°±ç»ªï¼Œå†åˆ¤æ–­æ˜¯å¦é…ç½®äº†ä¸‹è½½è·¯å¾„ï¼Œè‹¥é…ç½®åˆ™åˆå§‹åŒ–ä¸‹è½½æ–‡ä»¶è·Ÿè¸ªçš„å˜é‡å¹¶è®°å½•è°ƒè¯•æ—¥å¿—ï¼Œä¸ºåç»­ç›‘æ§æµè§ˆå™¨ä¸‹è½½æ–‡ä»¶çš„å˜åŒ–ï¼ˆå¦‚æ–°å¢ä¸‹è½½ã€æ ¡éªŒä¸‹è½½ç»“æœï¼‰æ‰“ä¸‹åŸºç¡€
		assert self.browser_session is not None, 'BrowserSession is not set up'
		self.has_downloads_path = self.browser_session.browser_profile.downloads_path is not None
		if self.has_downloads_path:
			self._last_known_downloads: list[str] = []
			self.logger.debug('ğŸ“ Initialized download tracking for agent')

		# Event-based pause control (kept out of AgentState for serialization)
		# åˆå§‹åŒ–åŸºäºå¼‚æ­¥äº‹ä»¶ï¼ˆasyncio.Eventï¼‰çš„å¤–éƒ¨æš‚åœæ§åˆ¶æœºåˆ¶ï¼Œå¹¶ä¸”ç‰¹æ„å°†è¿™ä¸ªæ§åˆ¶äº‹ä»¶æ”¾åœ¨ AgentState ä¹‹å¤–ï¼Œ
		# ç”¨äºå®ç°å¯¹æ™ºèƒ½ä½“æ‰§è¡Œæµç¨‹çš„ â€œæ— ä¾µå…¥å¼æš‚åœ / æ¢å¤â€ æ§åˆ¶ â€”â€” æ¯”å¦‚å¤–éƒ¨ç³»ç»Ÿå¯é€šè¿‡è§¦å‘è¿™ä¸ªäº‹ä»¶ï¼Œè®©æ™ºèƒ½ä½“æš‚åœæ‰§è¡Œæˆ–æ¢å¤æ‰§è¡Œï¼Œä¸”ä¸å½±å“çŠ¶æ€åºåˆ—åŒ–
		self._external_pause_event = asyncio.Event()
		self._external_pause_event.set()

	def _enhance_task_with_schema(self, task: str, output_model_schema: type[AgentStructuredOutput] | None) -> str:
		"""Enhance task description with output schema information if provided."""
		if output_model_schema is None:
			return task

		try:
			schema = output_model_schema.model_json_schema()
			import json

			schema_json = json.dumps(schema, indent=2)

			enhancement = f'\nExpected output format: {output_model_schema.__name__}\n{schema_json}'
			return task + enhancement
		except Exception as e:
			self.logger.debug(f'Could not parse output schema: {e}')

		return task

	@property
	def logger(self) -> logging.Logger:
		"""
		è·å–ç‰¹å®šäºå®ä¾‹çš„æ—¥å¿—è®°å½•å™¨ï¼Œåç§°ä¸­åŒ…å«ä»»åŠ¡ ID
		
		ä½¿ç”¨å±æ€§è£…é¥°å™¨ï¼Œå¯ä»¥åƒè®¿é—®å±æ€§ä¸€æ ·è°ƒç”¨ï¼šself.logger
		æ—¥å¿—åç§°æ ¼å¼ï¼šAgentğŸ…° {ä»»åŠ¡ID} â‡¢ ğŸ…‘ {æµè§ˆå™¨ä¼šè¯ID} ğŸ…£ {å½“å‰ç›®æ ‡ID}
		
		Returns:
		    logging.Logger: å¸¦æœ‰ä»»åŠ¡æ ‡è¯†çš„æ—¥å¿—è®°å½•å™¨
		"""
		# å¯èƒ½åœ¨ __init__ ä¸­è°ƒç”¨ loggerï¼Œæ‰€ä»¥ä¸å‡è®¾ self.* å±æ€§å·²ç»åˆå§‹åŒ–
		# ä½¿ç”¨æµ·è±¡è¿ç®—ç¬¦ (:=) åœ¨åŒä¸€è¡Œè¿›è¡Œèµ‹å€¼å’Œåˆ¤æ–­
		_task_id = task_id[-4:] if (task_id := getattr(self, 'task_id', None)) else '----'
		_browser_session_id = browser_session.id[-4:] if (browser_session := getattr(self, 'browser_session', None)) else '----'
		_current_target_id = (
			browser_session.agent_focus_target_id[-2:]
			if (browser_session := getattr(self, 'browser_session', None)) and browser_session.agent_focus_target_id
			else '--'
		)
		return logging.getLogger(f'browser_use.AgentğŸ…° {_task_id} â‡¢ ğŸ…‘ {_browser_session_id} ğŸ…£ {_current_target_id}')

	@property
	def browser_profile(self) -> BrowserProfile:
		assert self.browser_session is not None, 'BrowserSession is not set up'
		return self.browser_session.browser_profile

	@property
	def is_using_fallback_llm(self) -> bool:
		"""Check if the agent is currently using the fallback LLM."""
		return self._using_fallback_llm

	@property
	def current_llm_model(self) -> str:
		"""Get the model name of the currently active LLM."""
		return self.llm.model if hasattr(self.llm, 'model') else 'unknown'

	async def _check_and_update_downloads(self, context: str = '') -> None:
		"""
		æ£€æŸ¥æ–°ä¸‹è½½å¹¶æ›´æ–°å¯ç”¨æ–‡ä»¶è·¯å¾„
		
		è¯¥æ–¹æ³•ä¼šï¼š
		1. æ¯”è¾ƒå½“å‰ä¸‹è½½æ–‡ä»¶ä¸ä¸Šæ¬¡å·²çŸ¥çš„ä¸‹è½½æ–‡ä»¶
		2. å¦‚æœæœ‰æ–°æ–‡ä»¶ï¼Œæ›´æ–° available_file_paths
		3. è®°å½•æ–°ä¸‹è½½çš„æ–‡ä»¶
		
		Args:
		    context: ä¸Šä¸‹æ–‡æè¿°ï¼Œç”¨äºæ—¥å¿—è®°å½•ï¼ˆå¦‚ "after executing actions"ï¼‰
		"""
		if not self.has_downloads_path:
			return

		assert self.browser_session is not None, 'BrowserSession is not set up'

		try:
			current_downloads = self.browser_session.downloaded_files
			if current_downloads != self._last_known_downloads:
				self._update_available_file_paths(current_downloads)
				self._last_known_downloads = current_downloads
				if context:
					self.logger.debug(f'ğŸ“ {context}: Updated available files')
		except Exception as e:
			error_context = f' {context}' if context else ''
			self.logger.debug(f'ğŸ“ Failed to check for downloads{error_context}: {type(e).__name__}: {e}')

	def _update_available_file_paths(self, downloads: list[str]) -> None:
		"""æ›´æ–° available_file_pathsï¼ŒåŠ å…¥å·²ä¸‹è½½çš„æ–‡ä»¶"""
		if not self.has_downloads_path:
			return

		current_files = set(self.available_file_paths or [])
		new_files = set(downloads) - current_files

		if new_files:
			self.available_file_paths = list(current_files | new_files)

			self.logger.info(
				f'ğŸ“ Added {len(new_files)} downloaded files to available_file_paths (total: {len(self.available_file_paths)} files)'
			)
			for file_path in new_files:
				self.logger.info(f'ğŸ“„ New file available: {file_path}')
		else:
			self.logger.debug(f'ğŸ“ No new downloads detected (tracking {len(current_files)} files)')

	def _set_file_system(self, file_system_path: str | None = None) -> None:
		"""åˆå§‹åŒ–æˆ–æ¢å¤æ–‡ä»¶ç³»ç»Ÿ"""
		# Check for conflicting parameters
		if self.state.file_system_state and file_system_path:
			raise ValueError(
				'Cannot provide both file_system_state (from agent state) and file_system_path. '
				'Either restore from existing state or create new file system at specified path, not both.'
			)

		# Check if we should restore from existing state first
		if self.state.file_system_state:
			try:
				# Restore file system from state at the exact same location
				self.file_system = FileSystem.from_state(self.state.file_system_state)
				# The parent directory of base_dir is the original file_system_path
				self.file_system_path = str(self.file_system.base_dir)
				self.logger.debug(f'ğŸ’¾ File system restored from state to: {self.file_system_path}')
				return
			except Exception as e:
				self.logger.error(f'ğŸ’¾ Failed to restore file system from state: {e}')
				raise e

		# Initialize new file system
		try:
			if file_system_path:
				self.file_system = FileSystem(file_system_path)
				self.file_system_path = file_system_path
			else:
				# Use the agent directory for file system
				self.file_system = FileSystem(self.agent_directory)
				self.file_system_path = str(self.agent_directory)
		except Exception as e:
			self.logger.error(f'ğŸ’¾ Failed to initialize file system: {e}.')
			raise e

		# Save file system state to agent state
		self.state.file_system_state = self.file_system.get_state()

		self.logger.debug(f'ğŸ’¾ File system path: {self.file_system_path}')

	def _set_screenshot_service(self) -> None:
		"""ä½¿ç”¨ä»£ç†ç›®å½•åˆå§‹åŒ–æˆªå›¾æœåŠ¡"""
		try:
			from browser_use.screenshots.service import ScreenshotService

			self.screenshot_service = ScreenshotService(self.agent_directory)
			self.logger.debug(f'ğŸ“¸ Screenshot service initialized in: {self.agent_directory}/screenshots')
		except Exception as e:
			self.logger.error(f'ğŸ“¸ Failed to initialize screenshot service: {e}.')
			raise e

	def save_file_system_state(self) -> None:
		"""å°†å½“å‰æ–‡ä»¶ç³»ç»ŸçŠ¶æ€ä¿å­˜åˆ° Agent çŠ¶æ€ä¸­"""
		if self.file_system:
			self.state.file_system_state = self.file_system.get_state()
		else:
			self.logger.error('ğŸ’¾ File system is not set up. Cannot save state.')
			raise ValueError('File system is not set up. Cannot save state.')

	def _set_browser_use_version_and_source(self, source_override: str | None = None) -> None:
		"""è·å– browser-use ç‰ˆæœ¬å¹¶ç¡®å®šåŒ…æ¥æºï¼ˆgit æˆ– pipï¼‰"""
		# Use the helper function for version detection
		version = get_browser_use_version()

		# Determine source
		try:
			package_root = Path(__file__).parent.parent.parent
			repo_files = ['.git', 'README.md', 'docs', 'examples']
			if all(Path(package_root / file).exists() for file in repo_files):
				source = 'git'
			else:
				source = 'pip'
		except Exception as e:
			self.logger.debug(f'Error determining source: {e}')
			source = 'unknown'

		if source_override is not None:
			source = source_override
		# self.logger.debug(f'Version: {version}, Source: {source}')  # moved later to _log_agent_run so that people are more likely to include it in copy-pasted support ticket logs
		self.version = version
		self.source = source

	def _setup_action_models(self) -> None:
		"""ä»å·¥å…·æ³¨å†Œè¡¨ä¸­è®¾ç½®åŠ¨æ€åŠ¨ä½œæ¨¡å‹----åˆå§‹åŒ–self.ActionModelå€¼
		
		æ ¹æ®ä¸åŒçš„é…ç½®ï¼ˆflash_modeã€use_thinkingï¼‰ï¼Œä»å·¥å…·æ³¨å†Œè¡¨ä¸­åŠ¨æ€åˆ›å»ºåŠ¨ä½œæ¨¡å‹ï¼Œå¹¶ä¸ºæ™ºèƒ½ä½“ï¼ˆAgentï¼‰è®¾ç½®å¯¹åº”çš„è¾“å‡ºæ¨¡å‹ï¼ŒåŒæ—¶è¿˜å•ç‹¬åˆ›å»ºäº†ç”¨äºè§¦å‘ç»“æŸåŠ¨ä½œçš„ Done ç›¸å…³æ¨¡å‹
		"""
		# Initially only include actions with no filters
		self.ActionModel = self.tools.registry.create_action_model()
		# Create output model with the dynamic actions
		if self.settings.flash_mode:
			self.AgentOutput = AgentOutput.type_with_custom_actions_flash_mode(self.ActionModel)
		elif self.settings.use_thinking:
			self.AgentOutput = AgentOutput.type_with_custom_actions(self.ActionModel)
		else:
			self.AgentOutput = AgentOutput.type_with_custom_actions_no_thinking(self.ActionModel)

		# used to force the done action when max_steps is reached
		self.DoneActionModel = self.tools.registry.create_action_model(include_actions=['done'])
		if self.settings.flash_mode:
			self.DoneAgentOutput = AgentOutput.type_with_custom_actions_flash_mode(self.DoneActionModel)
		elif self.settings.use_thinking:
			self.DoneAgentOutput = AgentOutput.type_with_custom_actions(self.DoneActionModel)
		else:
			self.DoneAgentOutput = AgentOutput.type_with_custom_actions_no_thinking(self.DoneActionModel)

	def _get_skill_slug(self, skill: 'Skill', all_skills: list['Skill']) -> str:
		"""
		ä»æŠ€èƒ½æ ‡é¢˜ç”Ÿæˆæ¸…æ™°çš„ slug ç”¨ä½œåŠ¨ä½œåç§°
		
		å°†æ ‡é¢˜è½¬æ¢ä¸ºå°å†™ï¼Œç§»é™¤éå­—æ¯æ•°å­—å­—ç¬¦ï¼Œç”¨ä¸‹åˆ’çº¿æ›¿æ¢ç©ºæ ¼ã€‚
		å¦‚æœæœ‰é‡å¤ slugï¼Œåˆ™æ·»åŠ  UUID åç¼€ã€‚

		Args:
			skill: The skill to get slug for
			all_skills: List of all skills to check for duplicates

		Returns:
			Slug like "cloned_github_stars_tracker" or "get_weather_data_a1b2" if duplicate

		Examples:
			"[Cloned] Github Stars Tracker" -> "cloned_github_stars_tracker"
			"Get Weather Data" -> "get_weather_data"
		"""
		import re

		# Remove special characters and convert to lowercase
		slug = re.sub(r'[^\w\s]', '', skill.title.lower())
		# Replace whitespace and hyphens with underscores
		slug = re.sub(r'[\s\-]+', '_', slug)
		# Remove leading/trailing underscores
		slug = slug.strip('_')

		# Check for duplicates and add UUID suffix if needed
		same_slug_count = sum(
			1 for s in all_skills if re.sub(r'[\s\-]+', '_', re.sub(r'[^\w\s]', '', s.title.lower()).strip('_')) == slug
		)
		if same_slug_count > 1:
			return f'{slug}_{skill.id[:4]}'
		else:
			return slug

	async def _register_skills_as_actions(self) -> None:
		"""å°†æ¯ä¸ªæŠ€èƒ½æ³¨å†Œä¸ºå•ç‹¬çš„åŠ¨ä½œï¼Œä½¿ç”¨ slug ä½œä¸ºåŠ¨ä½œåç§°"""
		if not self.skill_service or self._skills_registered:
			return

		self.logger.info('ğŸ”§ Registering skill actions...')

		# Fetch all skills (auto-initializes if needed)
		skills = await self.skill_service.get_all_skills()

		if not skills:
			self.logger.warning('No skills loaded from SkillService')
			return

		# Register each skill as its own action
		for skill in skills:
			slug = self._get_skill_slug(skill, skills)
			param_model = skill.parameters_pydantic(exclude_cookies=True)

			# Create description with skill title in quotes
			description = f'{skill.description} (Skill: "{skill.title}")'

			# Create handler for this specific skill
			def make_skill_handler(skill_id: str):
				async def skill_handler(params: BaseModel) -> ActionResult:
					"""Execute a specific skill"""
					assert self.skill_service is not None, 'SkillService not initialized'

					# Convert parameters to dict
					if isinstance(params, BaseModel):
						skill_params = params.model_dump()
					elif isinstance(params, dict):
						skill_params = params
					else:
						return ActionResult(extracted_content=None, error=f'Invalid parameters type: {type(params)}')

					# Get cookies from browser
					_cookies = await self.browser_session.cookies()

					try:
						result = await self.skill_service.execute_skill(
							skill_id=skill_id, parameters=skill_params, cookies=_cookies
						)

						if result.success:
							return ActionResult(
								extracted_content=str(result.result) if result.result else None,
								error=None,
							)
						else:
							return ActionResult(extracted_content=None, error=result.error or 'Skill execution failed')
					except Exception as e:
						# Check if it's a MissingCookieException
						if type(e).__name__ == 'MissingCookieException':
							# Format: "Missing cookies (name): description"
							cookie_name = getattr(e, 'cookie_name', 'unknown')
							cookie_description = getattr(e, 'cookie_description', str(e))
							error_msg = f'Missing cookies ({cookie_name}): {cookie_description}'
							return ActionResult(extracted_content=None, error=error_msg)
						return ActionResult(extracted_content=None, error=f'Skill execution error: {type(e).__name__}: {e}')

				return skill_handler

			# Create the handler for this skill
			handler = make_skill_handler(skill.id)
			handler.__name__ = slug

			# Register the action with the slug as the action name
			self.tools.registry.action(description=description, param_model=param_model)(handler)

		# Mark as registered
		self._skills_registered = True

		# Rebuild action models to include the new skill actions
		self._setup_action_models()

		# Reconvert initial actions with the new ActionModel type if they exist
		if self.initial_actions:
			# Convert back to dict form first
			initial_actions_dict = []
			for action in self.initial_actions:
				action_dump = action.model_dump(exclude_unset=True)
				initial_actions_dict.append(action_dump)
			# Reconvert using new ActionModel
			self.initial_actions = self._convert_initial_actions(initial_actions_dict)

		self.logger.info(f'âœ“ Registered {len(skills)} skill actions')

	async def _get_unavailable_skills_info(self) -> str:
		"""
		è·å–å› ç¼ºå°‘ cookie è€Œä¸å¯ç”¨çš„æŠ€èƒ½ä¿¡æ¯
		
		Returns:
			str: æè¿°ä¸å¯ç”¨æŠ€èƒ½åŠå¦‚ä½•ä½¿å…¶å¯ç”¨çš„æ ¼å¼åŒ–å­—ç¬¦ä¸²
		"""
		if not self.skill_service:
			return ''

		try:
			# Get all skills
			skills = await self.skill_service.get_all_skills()
			if not skills:
				return ''

			# Get current cookies
			current_cookies = await self.browser_session.cookies()
			cookie_dict = {cookie['name']: cookie['value'] for cookie in current_cookies}

			# Check each skill for missing required cookies
			unavailable_skills: list[dict[str, Any]] = []

			for skill in skills:
				# Get cookie parameters for this skill
				cookie_params = [p for p in skill.parameters if p.type == 'cookie']

				if not cookie_params:
					# No cookies needed, skip
					continue

				# Check for missing required cookies
				missing_cookies: list[dict[str, str]] = []
				for cookie_param in cookie_params:
					is_required = cookie_param.required if cookie_param.required is not None else True

					if is_required and cookie_param.name not in cookie_dict:
						missing_cookies.append(
							{'name': cookie_param.name, 'description': cookie_param.description or 'No description provided'}
						)

				if missing_cookies:
					unavailable_skills.append(
						{
							'id': skill.id,
							'title': skill.title,
							'description': skill.description,
							'missing_cookies': missing_cookies,
						}
					)

			if not unavailable_skills:
				return ''

			# Format the unavailable skills info with slugs
			lines = ['Unavailable Skills (missing required cookies):']
			for skill_info in unavailable_skills:
				# Get the full skill object to use the slug helper
				skill_obj = next((s for s in skills if s.id == skill_info['id']), None)
				slug = self._get_skill_slug(skill_obj, skills) if skill_obj else skill_info['title']
				title = skill_info['title']

				lines.append(f'\n  â€¢ {slug} ("{title}")')
				lines.append(f'    Description: {skill_info["description"]}')
				lines.append('    Missing cookies:')
				for cookie in skill_info['missing_cookies']:
					lines.append(f'      - {cookie["name"]}: {cookie["description"]}')

			return '\n'.join(lines)

		except Exception as e:
			self.logger.error(f'Error getting unavailable skills info: {type(e).__name__}: {e}')
			return ''

	def add_new_task(self, new_task: str) -> None:
		"""Add a new task to the agent, keeping the same task_id as tasks are continuous"""
		# Simply delegate to message manager - no need for new task_id or events
		# The task continues with new instructions, it doesn't end and start a new one
		self.task = new_task
		self._message_manager.add_new_task(new_task)
		# Mark as follow-up task and recreate eventbus (gets shut down after each run)
		self.state.follow_up_task = True
		# Reset control flags so agent can continue
		self.state.stopped = False
		self.state.paused = False
		agent_id_suffix = str(self.id)[-4:].replace('-', '_')
		if agent_id_suffix and agent_id_suffix[0].isdigit():
			agent_id_suffix = 'a' + agent_id_suffix
		self.eventbus = EventBus(name=f'Agent_{agent_id_suffix}')

	async def _check_stop_or_pause(self) -> None:
		"""
		ç»Ÿä¸€æ ¡éªŒæ‰€æœ‰ â€œåœæ­¢ / æš‚åœâ€ è§¦å‘æ¡ä»¶ï¼ˆå¤–éƒ¨å›è°ƒ + å†…éƒ¨çŠ¶æ€ï¼‰ï¼Œä¸€æ—¦æ»¡è¶³æ¡ä»¶å°±æŠ›å‡º InterruptedErrorï¼Œè®©ä¸Šå±‚æµç¨‹ï¼ˆå¦‚ step()/_execute_step()ï¼‰æ•è·å¹¶ä¼˜é›…ç»ˆæ­¢å½“å‰æ­¥éª¤ / ä»»åŠ¡
		"""

		# Check new should_stop_callback - sets stopped state cleanly without raising
		if self.register_should_stop_callback:
			if await self.register_should_stop_callback():
				self.logger.info('External callback requested stop')
				self.state.stopped = True
				raise InterruptedError

		if self.register_external_agent_status_raise_error_callback:
			if await self.register_external_agent_status_raise_error_callback():
				raise InterruptedError

		if self.state.stopped:
			raise InterruptedError

		if self.state.paused:
			raise InterruptedError

	@observe(name='agent.step', ignore_output=True, ignore_input=True)
	@time_execution_async('--step')
	async def step(self, step_info: AgentStepInfo | None = None) -> None:
		"""
		æ‰§è¡Œå•æ­¥ä»»åŠ¡ - Agent çš„æ ¸å¿ƒæ‰§è¡Œå•å…ƒ

		å®Œæˆæ™ºèƒ½ä½“å•æ­¥æ‰§è¡Œçš„å…¨æµç¨‹ï¼ˆä¸Šä¸‹æ–‡å‡†å¤‡â†’LLM å†³ç­–â†’åŠ¨ä½œæ‰§è¡Œâ†’åå¤„ç†ï¼‰ï¼Œæ·»åŠ ç›‘æ§ / è®¡æ—¶èƒ½åŠ›ï¼Œç»Ÿä¸€å¤„ç†å¼‚å¸¸ï¼Œä¿è¯æ— è®ºæ˜¯å¦å‡ºé”™éƒ½èƒ½å®Œæˆæ¸…ç†å’Œè®°å½•
		
		æ¯ä¸€æ­¥åŒ…å«ä¸‰ä¸ªé˜¶æ®µï¼š
		1. å‡†å¤‡ä¸Šä¸‹æ–‡ - è·å–æµè§ˆå™¨çŠ¶æ€ã€æ›´æ–°åŠ¨ä½œæ¨¡å‹
		2. è·å–å¹¶æ‰§è¡ŒåŠ¨ä½œ - è°ƒç”¨ LLM è·å–å†³ç­–ï¼Œæ‰§è¡Œæµè§ˆå™¨æ“ä½œ
		3. åå¤„ç† - æ£€æŸ¥ä¸‹è½½ã€è®°å½•ç»“æœ
		
		Args:
		    step_info: æ­¥éª¤ä¿¡æ¯ï¼ŒåŒ…å«å½“å‰æ­¥æ•°å’Œæœ€å¤§æ­¥æ•°
		"""
		# é¦–å…ˆåˆå§‹åŒ–è®¡æ—¶ï¼Œåœ¨ä»»ä½•å¼‚å¸¸å‘ç”Ÿä¹‹å‰
		self.step_start_time = time.time()
		# åˆå§‹åŒ–æµè§ˆå™¨çŠ¶æ€æ‘˜è¦ï¼ˆåç»­èµ‹å€¼ï¼‰
		browser_state_summary = None 

		try:
			# é˜¶æ®µ 1: å‡†å¤‡ä¸Šä¸‹æ–‡å’Œè®¡æ—¶
			browser_state_summary = await self._prepare_context(step_info)

			# é˜¶æ®µ 2: è·å–æ¨¡å‹è¾“å‡ºå¹¶æ‰§è¡ŒåŠ¨ä½œï¼ˆæ ¸å¿ƒï¼šLLMå†³ç­– + æµè§ˆå™¨æ“ä½œï¼‰
			await self._get_next_action(browser_state_summary)
			# æ‰§è¡ŒåŠ¨ä½œï¼ˆå¦‚ç‚¹å‡»ã€è¾“å…¥ã€å¯¼èˆªï¼‰
			await self._execute_actions()

			# é˜¶æ®µ 3: åå¤„ç†ï¼ˆæ£€æŸ¥ä¸‹è½½ã€è®°å½•ç»“æœã€æ›´æ–°çŠ¶æ€ï¼‰
			await self._post_process()

		except Exception as e:
			# åœ¨ä¸€ä¸ªåœ°æ–¹å¤„ç†æ‰€æœ‰å¼‚å¸¸
			await self._handle_step_error(e)

		finally:
			# æ— è®ºæ˜¯å¦å¼‚å¸¸ï¼Œéƒ½è¦æ‰§è¡Œæ¸…ç†å’Œè®°å½•
			await self._finalize(browser_state_summary)

	async def _prepare_context(self, step_info: AgentStepInfo | None = None) -> BrowserStateSummary:
		"""
		å‡†å¤‡æ­¥éª¤çš„ä¸Šä¸‹æ–‡ï¼šæµè§ˆå™¨çŠ¶æ€ã€åŠ¨ä½œæ¨¡å‹ã€é¡µé¢åŠ¨ä½œ
		
		è¿™æ˜¯æ¯æ­¥æ‰§è¡Œçš„ç¬¬ä¸€é˜¶æ®µï¼Œè´Ÿè´£ï¼š
		1. è·å–å½“å‰æµè§ˆå™¨çŠ¶æ€ï¼ˆåŒ…æ‹¬æˆªå›¾ï¼‰
		2. æ£€æŸ¥æ–°ä¸‹è½½çš„æ–‡ä»¶
		3. æ›´æ–°åŠ¨ä½œæ¨¡å‹ï¼ˆæ ¹æ®å½“å‰é¡µé¢è¿‡æ»¤å¯ç”¨åŠ¨ä½œï¼‰
		4. åˆ›å»ºçŠ¶æ€æ¶ˆæ¯ä¾› LLM ä½¿ç”¨
		
		Args:
		    step_info: æ­¥éª¤ä¿¡æ¯
		    
		Returns:
		    BrowserStateSummary: æµè§ˆå™¨çŠ¶æ€æ‘˜è¦ï¼ŒåŒ…å« URLã€æ ‡é¢˜ã€DOM çŠ¶æ€ã€æˆªå›¾ç­‰
		"""
		# step_start_time ç°åœ¨åœ¨ step() æ–¹æ³•ä¸­è®¾ç½®

		assert self.browser_session is not None, 'BrowserSession is not set up'

		self.logger.debug(f'ğŸŒ Step {self.state.n_steps}: Getting browser state...')
		# å§‹ç»ˆä¸ºæ‰€æœ‰æ­¥éª¤æˆªå›¾
		self.logger.debug('ğŸ“¸ Requesting browser state with include_screenshot=True')
		browser_state_summary = await self.browser_session.get_browser_state_summary(
			include_screenshot=True,  # å§‹ç»ˆæ•è·æˆªå›¾ï¼Œå³ä½¿ use_vision=Falseï¼Œä»¥ä¾¿äº‘åŒæ­¥æœ‰ç”¨ï¼ˆç°åœ¨å¾ˆå¿«ï¼‰
			include_recent_events=self.include_recent_events,
		)
		if browser_state_summary.screenshot:
			self.logger.debug(f'ğŸ“¸ Got browser state WITH screenshot, length: {len(browser_state_summary.screenshot)}')
		else:
			self.logger.debug('ğŸ“¸ Got browser state WITHOUT screenshot')

		# Check for new downloads after getting browser state (catches PDF auto-downloads and previous step downloads)
		await self._check_and_update_downloads(f'Step {self.state.n_steps}: after getting browser state')

		self._log_step_context(browser_state_summary)
		await self._check_stop_or_pause()

		# Update action models with page-specific actions
		self.logger.debug(f'ğŸ“ Step {self.state.n_steps}: Updating action models...')
		# æ›´æ–°åŠ¨ä½œæ¨¡å‹ä»¥åæ˜ å½“å‰é¡µé¢çš„å¯ç”¨åŠ¨ä½œå’Œè¾“å‡ºæ¨¡å‹
		await self._update_action_models_for_page(browser_state_summary.url)

		# Get page-specific filtered actions
		page_filtered_actions = self.tools.registry.get_prompt_description(browser_state_summary.url)

		# Page-specific actions will be included directly in the browser_state message
		self.logger.debug(f'ğŸ’¬ Step {self.state.n_steps}: Creating state messages for context...')

		# Get unavailable skills info if skills service is enabled
		unavailable_skills_info = None
		if self.skill_service is not None:
			unavailable_skills_info = await self._get_unavailable_skills_info()

		self._message_manager.create_state_messages(
			browser_state_summary=browser_state_summary,
			model_output=self.state.last_model_output,
			result=self.state.last_result,
			step_info=step_info,
			use_vision=self.settings.use_vision,
			page_filtered_actions=page_filtered_actions if page_filtered_actions else None,
			sensitive_data=self.sensitive_data,
			available_file_paths=self.available_file_paths,  # Always pass current available_file_paths
			unavailable_skills_info=unavailable_skills_info,
		)

		await self._force_done_after_last_step(step_info)
		await self._force_done_after_failure()
		return browser_state_summary

	@observe_debug(ignore_input=True, name='get_next_action')
	async def _get_next_action(self, browser_state_summary: BrowserStateSummary) -> None:
		"""
		æ‰§è¡Œ LLM äº¤äº’ï¼Œè·å–ä¸‹ä¸€ä¸ªåŠ¨ä½œå†³ç­–

		(ç»„è£… æ¶ˆæ¯ç®¡ç†å™¨ä¸­çš„LLM è¾“å…¥æ¶ˆæ¯ã€å¸¦è¶…æ—¶ / é‡è¯•è°ƒç”¨ LLM è·å–åŠ¨ä½œå†³ç­–ã€æ ¡éªŒæ™ºèƒ½ä½“çŠ¶æ€ï¼ˆæš‚åœ / ç»ˆæ­¢ï¼‰ã€å¤„ç†åç»­å›è°ƒå’Œå¯¹è¯ä¿å­˜ï¼Œæœ€ç»ˆæŠŠ LLM è¾“å‡ºå­˜å…¥æ™ºèƒ½ä½“çŠ¶æ€ï¼Œä¸ºåç»­æ‰§è¡ŒåŠ¨ä½œåšå‡†å¤‡)
		
		è¿™æ˜¯æ¯æ­¥æ‰§è¡Œçš„ç¬¬äºŒé˜¶æ®µï¼Œè´Ÿè´£ï¼š
		1. ä»æ¶ˆæ¯ç®¡ç†å™¨è·å–è¾“å…¥æ¶ˆæ¯
		2. è°ƒç”¨ LLM è·å–æ¨¡å‹è¾“å‡ºï¼ˆå¸¦é‡è¯•é€»è¾‘ï¼‰
		3. å¤„ç†å›è°ƒå’Œä¿å­˜å¯¹è¯
		
		Args:
		    browser_state_summary: æµè§ˆå™¨çŠ¶æ€æ‘˜è¦
		"""
		# 1ã€ä»æ¶ˆæ¯ç®¡ç†å™¨è·å–ç»„è£…å¥½çš„è¾“å…¥æ¶ˆæ¯ï¼ˆä¸Šä¸‹æ–‡+ä»»åŠ¡+æµè§ˆå™¨çŠ¶æ€ï¼‰
		input_messages = self._message_manager.get_messages()
		self.logger.debug(
			f'ğŸ¤– Step {self.state.n_steps}: Calling LLM with {len(input_messages)} messages (model: {self.llm.model})...'
		)

		# è¾“å…¥æ¶ˆæ¯å°±æ˜¯ç”¨æˆ·ç±»å‹çš„æç¤ºè¯ç»“æ„å¤§æ¦‚å¦‚ä¸‹ï¼š
		# 1. å›é¡¾å†å²ï¼ˆagent_historyï¼‰
		# agent_history = input_messages[-1].content
		# 2. ç†è§£å½“å‰ä»»åŠ¡ï¼ˆagent_stateï¼‰
		# agent_state = self.state
		# 3. æ„ŸçŸ¥ç¯å¢ƒï¼ˆbrowser_stateï¼‰
		# browser_state = browser_state_summary
		# 4. å†³å®šä¸‹ä¸€æ­¥åŠ¨ä½œï¼ˆå·¥å…·è°ƒç”¨ã€é¡µé¢æ“ä½œç­‰ï¼‰

		try:
			# 2ã€è°ƒç”¨ LLMï¼Œå¸¦è¶…æ—¶æ§åˆ¶
			model_output = await asyncio.wait_for(
				self._get_model_output_with_retry(input_messages), timeout=self.settings.llm_timeout
			)
		except TimeoutError:

			@observe(name='_llm_call_timed_out_with_input')
			async def _log_model_input_to_lmnr(input_messages: list[BaseMessage]) -> None:
				"""Log the model input"""
				pass

			await _log_model_input_to_lmnr(input_messages)

			raise TimeoutError(
				f'LLM call timed out after {self.settings.llm_timeout} seconds. Keep your thinking and output short.'
			)
		# æŠŠLLMè¾“å‡ºå­˜å…¥æ™ºèƒ½ä½“çŠ¶æ€ï¼Œä¾›åç»­æ‰§è¡ŒåŠ¨ä½œä½¿ç”¨
		self.state.last_model_output = model_output

		# # ç¬¬ä¸€æ¬¡æ ¡éªŒï¼šè·å–LLMè¾“å‡ºåï¼Œæ£€æŸ¥æ˜¯å¦è¢«æš‚åœ/ç»ˆæ­¢
		await self._check_stop_or_pause()

		# å¤„ç†LLMè°ƒç”¨åçš„å›è°ƒï¼ˆå¦‚è®°å½•tokenæ¶ˆè€—ã€æ›´æ–°å¯¹è¯å†å²ï¼‰+ ä¿å­˜å¯¹è¯
		await self._handle_post_llm_processing(browser_state_summary, input_messages)

		# ç¬¬äºŒæ¬¡æ ¡éªŒï¼šå­˜å…¥å†å²å‰å†æ¬¡æ£€æŸ¥æš‚åœ/ç»ˆæ­¢ï¼ˆé˜²æ­¢å¤„ç†å›è°ƒè¿‡ç¨‹ä¸­è§¦å‘åœæ­¢ï¼‰
		await self._check_stop_or_pause()

	async def _execute_actions(self) -> None:
		"""
		æ‰§è¡Œæ¨¡å‹è¾“å‡ºçš„åŠ¨ä½œï¼šæ ¡éªŒ LLM è¾“å‡ºæ˜¯å¦å­˜åœ¨ â†’ è°ƒç”¨å¤šåŠ¨ä½œæ‰§è¡Œå™¨æ‰§è¡ŒåŠ¨ä½œ â†’ ä¿å­˜æ‰§è¡Œç»“æœåˆ°æ™ºèƒ½ä½“çŠ¶æ€
		
		è¿™æ˜¯æ¯æ­¥æ‰§è¡Œçš„ç¬¬äºŒé˜¶æ®µï¼Œè´Ÿè´£ï¼š
		1. ä»æ¨¡å‹è¾“å‡ºä¸­æå–åŠ¨ä½œåˆ—è¡¨
		2. è°ƒç”¨ multi_act æ‰§è¡Œå¤šä¸ªåŠ¨ä½œ
		3. ä¿å­˜æ‰§è¡Œç»“æœåˆ°çŠ¶æ€
		
		Raises:
		    ValueError: å¦‚æœæ²¡æœ‰æ¨¡å‹è¾“å‡º
		"""
		if self.state.last_model_output is None:
			raise ValueError('No model output to execute actions from')

		# æ‰§è¡Œå¤šä¸ªåŠ¨ä½œï¼ˆæœ€å¤š max_actions_per_step ä¸ªï¼‰
		result = await self.multi_act(self.state.last_model_output.action)
		self.state.last_result = result

	async def _post_process(self) -> None:
		"""
		åŠ¨ä½œæ‰§è¡Œåçš„åå¤„ç†
		
		è´Ÿè´£ï¼š
		1. æ£€æŸ¥æ–°ä¸‹è½½çš„æ–‡ä»¶
		2. æ›´æ–°è¿ç»­å¤±è´¥è®¡æ•°
		3. è®°å½•æœ€ç»ˆç»“æœï¼ˆå¦‚æœä»»åŠ¡å®Œæˆï¼‰
		
		Raises:
		    AssertionError: å¦‚æœæµè§ˆå™¨ä¼šè¯æœªè®¾ç½®
		"""
		assert self.browser_session is not None, 'BrowserSession is not set up'

		# æ‰§è¡ŒåŠ¨ä½œåæ£€æŸ¥æ–°ä¸‹è½½
		await self._check_and_update_downloads('after executing actions')

		# check for action errors  and len more than 1
		# self.state.last_result[-1].error æœ€åä¸€ä¸ªåŠ¨ä½œæ‰§è¡Œå‡ºé”™
		if self.state.last_result and len(self.state.last_result) == 1 and self.state.last_result[-1].error:
			self.state.consecutive_failures += 1
			self.logger.debug(f'ğŸ”„ Step {self.state.n_steps}: Consecutive failures: {self.state.consecutive_failures}')
			return

		if self.state.consecutive_failures > 0:
			self.state.consecutive_failures = 0
			self.logger.debug(f'ğŸ”„ Step {self.state.n_steps}: Consecutive failures reset to: {self.state.consecutive_failures}')

		# Log completion results
		if self.state.last_result and len(self.state.last_result) > 0 and self.state.last_result[-1].is_done:
			success = self.state.last_result[-1].success
			if success:
				# Green color for success
				self.logger.info(f'\nğŸ“„ \033[32m Final Result:\033[0m \n{self.state.last_result[-1].extracted_content}\n\n')
			else:
				# Red color for failure
				self.logger.info(f'\nğŸ“„ \033[31m Final Result:\033[0m \n{self.state.last_result[-1].extracted_content}\n\n')
			if self.state.last_result[-1].attachments:
				total_attachments = len(self.state.last_result[-1].attachments)
				for i, file_path in enumerate(self.state.last_result[-1].attachments):
					self.logger.info(f'ğŸ‘‰ Attachment {i + 1 if total_attachments > 1 else ""}: {file_path}')

	async def _handle_step_error(self, error: Exception) -> None:
		"""
		å¤„ç†æ­¥éª¤æ‰§è¡Œä¸­å‘ç”Ÿçš„æ‰€æœ‰å¼‚å¸¸
		
		è¯¥æ–¹æ³•ä¼šï¼š
		1. ç‰¹æ®Šå¤„ç† InterruptedErrorï¼ˆç”¨æˆ·ä¸­æ–­ï¼‰
		2. è®°å½•é”™è¯¯æ—¥å¿—ï¼ˆåŒ…æ‹¬æ˜¯å¦éœ€è¦è°ƒè¯•å †æ ˆï¼‰
		3. æ›´æ–°è¿ç»­å¤±è´¥è®¡æ•°
		4. å°†é”™è¯¯ä½œä¸º ActionResult ä¿å­˜ï¼Œä»¥ä¾¿åç»­å¤„ç†
		
		Args:
		    error: æ•è·åˆ°çš„å¼‚å¸¸å¯¹è±¡
		"""

		# Handle InterruptedError specially
		if isinstance(error, InterruptedError):
			error_msg = 'The agent was interrupted mid-step' + (f' - {str(error)}' if str(error) else '')
			# NOTE: This is not an error, it's a normal part of the execution when the user interrupts the agent
			self.logger.warning(f'{error_msg}')
			return

		# Handle all other exceptions
		include_trace = self.logger.isEnabledFor(logging.DEBUG)
		error_msg = AgentError.format_error(error, include_trace=include_trace)
		max_total_failures = self.settings.max_failures + int(self.settings.final_response_after_failure)
		prefix = f'âŒ Result failed {self.state.consecutive_failures + 1}/{max_total_failures} times: '
		self.state.consecutive_failures += 1

		# Use WARNING for partial failures, ERROR only when max failures reached
		is_final_failure = self.state.consecutive_failures >= max_total_failures
		log_level = logging.ERROR if is_final_failure else logging.WARNING

		if 'Could not parse response' in error_msg or 'tool_use_failed' in error_msg:
			# give model a hint how output should look like
			self.logger.log(log_level, f'Model: {self.llm.model} failed')
			self.logger.log(log_level, f'{prefix}{error_msg}')
		else:
			self.logger.log(log_level, f'{prefix}{error_msg}')

		await self._demo_mode_log(f'Step error: {error_msg}', 'error', {'step': self.state.n_steps})
		self.state.last_result = [ActionResult(error=error_msg)]
		return None

	async def _finalize(self, browser_state_summary: BrowserStateSummary | None) -> None:
		"""
		æ­¥éª¤çš„æœ€ç»ˆåŒ–å¤„ç†ï¼š

		å•ä¸ªæ­¥éª¤å®Œæˆåçš„æœ€ç»ˆæ”¶å°¾é€»è¾‘ï¼Œæ ¸å¿ƒè´Ÿè´£æ•´åˆæ­¥éª¤å…¨é‡ä¿¡æ¯ï¼ˆæ‰§è¡Œæ—¶é—´ã€æµè§ˆå™¨çŠ¶æ€ã€åŠ¨ä½œç»“æœç­‰ï¼‰ã€æŒä¹…åŒ–æ•°æ®ã€å‘é€äº‹ä»¶å¹¶æ¨è¿›æ­¥éª¤è®¡æ•°
		
		è´Ÿè´£ï¼š
		1. è®¡ç®—æ­¥éª¤æ‰§è¡Œæ—¶é—´
		2. åˆ›å»ºå†å²è®°å½•é¡¹
		3. è®°å½•æ­¥éª¤å®Œæˆæ‘˜è¦
		4. ä¿å­˜æ–‡ä»¶ç³»ç»ŸçŠ¶æ€
		5. å‘é€äº‹ä»¶
		6. å¢åŠ æ­¥éª¤è®¡æ•°å™¨
		
		Args:
		    browser_state_summary: æµè§ˆå™¨çŠ¶æ€æ‘˜è¦
		"""
		step_end_time = time.time()
		if not self.state.last_result:
			return
		# é‡åŒ–æ­¥éª¤æ‰§è¡Œè€—æ—¶ï¼ˆå¼€å§‹ / ç»“æŸæ—¶é—´ã€ä¸ä¸Šä¸€æ­¥çš„é—´éš”ï¼‰ï¼›
		if browser_state_summary:
			step_interval = None
			if len(self.history.history) > 0:
				last_history_item = self.history.history[-1]

				if last_history_item.metadata:
					previous_end_time = last_history_item.metadata.step_end_time
					previous_start_time = last_history_item.metadata.step_start_time
					step_interval = max(0, previous_end_time - previous_start_time)
			metadata = StepMetadata(
				step_number=self.state.n_steps,
				step_start_time=self.step_start_time,
				step_end_time=step_end_time,
				step_interval=step_interval,
			)

			# Use _make_history_item like main branch
			# ç”Ÿæˆç»“æ„åŒ–çš„å†å²è®°å½•ï¼ˆä¾¿äºå›æº¯æ­¥éª¤æ‰§è¡Œè¿‡ç¨‹ï¼‰ï¼›
			# å°†æ­¥éª¤çš„ â€œè¾“å…¥ï¼ˆæ¨¡å‹æŒ‡ä»¤ï¼‰- è¿‡ç¨‹ï¼ˆæµè§ˆå™¨çŠ¶æ€ï¼‰- è¾“å‡ºï¼ˆæ‰§è¡Œç»“æœï¼‰- å…ƒæ•°æ®ï¼ˆæ—¶é—´ï¼‰â€ å®Œæ•´è®°å½•ï¼Œå½¢æˆå¯å›æº¯çš„æ“ä½œæ—¥å¿—
			await self._make_history_item(
				self.state.last_model_output,
				browser_state_summary,
				self.state.last_result,
				metadata,
				state_message=self._message_manager.last_state_message_text,
			)

		# Log step completion summary
		# è®°å½•æ­¥éª¤å®Œæˆæ‘˜è¦æ—¥å¿—ï¼ˆå¯è§†åŒ–æ‰§è¡Œç»“æœï¼‰ï¼›æ¯”å¦‚ â€œæ­¥éª¤ 1 æ‰§è¡Œå®Œæˆï¼Œè€—æ—¶ 2.5 ç§’ï¼ŒæˆåŠŸæ‰§è¡Œ click åŠ¨ä½œ
		summary_message = self._log_step_completion_summary(self.step_start_time, self.state.last_result)
		if summary_message:
			await self._demo_mode_log(summary_message, 'info', {'step': self.state.n_steps})

		# Save file system state after step completion
		# æŒä¹…åŒ–æ–‡ä»¶ç³»ç»ŸçŠ¶æ€ï¼ˆé¿å…ä¸‹è½½æ–‡ä»¶ / æ“ä½œè®°å½•ä¸¢å¤±ï¼‰ï¼›
		# ä½œç”¨ï¼šé¿å…æ­¥éª¤æ‰§è¡Œä¸­ä¿®æ”¹çš„æ–‡ä»¶çŠ¶æ€ä¸¢å¤±ï¼Œä¿è¯åç»­æ­¥éª¤èƒ½è·å–æœ€æ–°çš„æ–‡ä»¶ä¿¡æ¯ï¼ˆæ¯”å¦‚ä¸‹ä¸€ä¸ªæ­¥éª¤éœ€è¦è¯»å–æœ¬æ¬¡ä¸‹è½½çš„æ–‡ä»¶ï¼‰ã€‚
		self.save_file_system_state()

		# Emit both step created and executed events
		# å‘é€äº‹ä»¶ï¼ˆä¾›å¤–éƒ¨ç³»ç»Ÿç›‘æ§ / æ¶ˆè´¹æ­¥éª¤æ‰§è¡Œæ•°æ®ï¼‰ï¼›
		if browser_state_summary and self.state.last_model_output:
			# Extract key step data for the event
			actions_data = []
			if self.state.last_model_output.action:
				for action in self.state.last_model_output.action:
					action_dict = action.model_dump() if hasattr(action, 'model_dump') else {}
					actions_data.append(action_dict)

			# Emit CreateAgentStepEvent
			step_event = CreateAgentStepEvent.from_agent_step(
				self,
				self.state.last_model_output,
				self.state.last_result,
				actions_data,
				browser_state_summary,
			)
			self.eventbus.dispatch(step_event)

		# Increment step counter after step is fully completed
		# æ¨è¿›æ­¥éª¤è®¡æ•°å™¨ï¼ˆå‡†å¤‡æ‰§è¡Œä¸‹ä¸€ä¸ªæ­¥éª¤ï¼‰ã€‚
		# æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨ â€œæ­¥éª¤å®Œå…¨å®Œæˆåå†å¢åŠ è®¡æ•°å™¨â€ï¼Œé¿å…æ­¥éª¤æœªå®Œæˆå°±æ¨è¿›ç¼–å·å¯¼è‡´æ··ä¹±ï¼›
		self.state.n_steps += 1

	async def _force_done_after_last_step(self, step_info: AgentStepInfo | None = None) -> None:
		"""
		å¤„ç†æœ€åä¸€æ­¥çš„ç‰¹æ®Šé€»è¾‘
		
		å¦‚æœè¾¾åˆ°æœ€å¤§æ­¥æ•°ï¼š
		1. æç¤ºæ¨¡å‹è¿™æ˜¯æœ€åä¸€æ­¥
		2. å¼ºåˆ¶æ¨¡å‹åªèƒ½ä½¿ç”¨ done å·¥å…·
		"""
		if step_info and step_info.is_last_step():
			# Add last step warning if needed
			msg = 'You reached max_steps - this is your last step. Your only tool available is the "done" tool. No other tool is available. All other tools which you see in history or examples are not available.'
			msg += '\nIf the task is not yet fully finished as requested by the user, set success in "done" to false! E.g. if not all steps are fully completed. Else success to true.'
			msg += '\nInclude everything you found out for the ultimate task in the done text.'
			self.logger.debug('Last step finishing up')
			self._message_manager._add_context_message(UserMessage(content=msg))
			self.AgentOutput = self.DoneAgentOutput

	async def _force_done_after_failure(self) -> None:
		"""
		åœ¨å¤šæ¬¡å¤±è´¥åå¼ºåˆ¶ç»“æŸ
		
		å¦‚æœè¿ç»­å¤±è´¥æ¬¡æ•°è¾¾åˆ°ä¸Šé™ï¼š
		1. æç¤ºæ¨¡å‹ç”±äºå¤±è´¥è¿‡å¤šå³å°†ç»ˆæ­¢
		2. å¼ºåˆ¶æ¨¡å‹åªèƒ½ä½¿ç”¨ done å·¥å…·
		"""
		# Create recovery message
		if self.state.consecutive_failures >= self.settings.max_failures and self.settings.final_response_after_failure:
			msg = f'You failed {self.settings.max_failures} times. Therefore we terminate the agent.'
			msg += '\nYour only tool available is the "done" tool. No other tool is available. All other tools which you see in history or examples are not available.'
			msg += '\nIf the task is not yet fully finished as requested by the user, set success in "done" to false! E.g. if not all steps are fully completed. Else success to true.'
			msg += '\nInclude everything you found out for the ultimate task in the done text.'

			self.logger.debug('Force done action, because we reached max_failures.')
			self._message_manager._add_context_message(UserMessage(content=msg))
			self.AgentOutput = self.DoneAgentOutput

	@observe(ignore_input=True, ignore_output=False)
	async def _judge_trace(self) -> JudgementResult | None:
		"""
		è¯„ä¼° Agent çš„æ‰§è¡Œè½¨è¿¹
		
		ä½¿ç”¨ judge_llm å¯¹ä»»åŠ¡å®Œæˆæƒ…å†µè¿›è¡Œè¯„ä¼°
		
		Returns:
		    JudgementResult | None: è¯„ä¼°ç»“æœï¼Œå¦‚æœå¤±è´¥åˆ™è¿”å› None
		"""
		task = self.task
		final_result = self.history.final_result() or ''
		agent_steps = self.history.agent_steps()
		screenshot_paths = [p for p in self.history.screenshot_paths() if p is not None]

		# Construct input messages for judge evaluation
		input_messages = construct_judge_messages(
			task=task,
			final_result=final_result,
			agent_steps=agent_steps,
			screenshot_paths=screenshot_paths,
			max_images=10,
			ground_truth=self.settings.ground_truth,
		)

		# Call LLM with JudgementResult as output format
		kwargs: dict = {'output_format': JudgementResult}

		# Only pass request_type for ChatBrowserUse (other providers don't support it)
		if self.judge_llm.provider == 'browser-use':
			kwargs['request_type'] = 'judge'

		try:
			response = await self.judge_llm.ainvoke(input_messages, **kwargs)
			judgement: JudgementResult = response.completion  # type: ignore[assignment]
			return judgement
		except Exception as e:
			self.logger.error(f'Judge trace failed: {e}')
			# Return a default judgement on failure
			return None

	async def _judge_and_log(self) -> None:
		"""è¿è¡Œè¯„ä¼°å¹¶è®°å½•ç»“è®º"""
		judgement = await self._judge_trace()

		# Attach judgement to last action result
		if self.history.history[-1].result[-1].is_done:
			last_result = self.history.history[-1].result[-1]
			last_result.judgement = judgement

			# Get self-reported success
			self_reported_success = last_result.success

			# Log the verdict based on self-reported success and judge verdict
			if judgement:
				# If both self-reported and judge agree on success, don't log
				if self_reported_success is True and judgement.verdict is True:
					return

				judge_log = '\n'
				# If agent reported success but judge thinks it failed, show warning
				if self_reported_success is True and judgement.verdict is False:
					judge_log += 'âš ï¸  \033[33mAgent reported success but judge thinks task failed\033[0m\n'

				# Otherwise, show full judge result
				verdict_color = '\033[32m' if judgement.verdict else '\033[31m'
				verdict_text = 'âœ… PASS' if judgement.verdict else 'âŒ FAIL'
				judge_log += f'âš–ï¸  {verdict_color}Judge Verdict: {verdict_text}\033[0m\n'
				if judgement.failure_reason:
					judge_log += f'   Failure Reason: {judgement.failure_reason}\n'
				if judgement.reached_captcha:
					judge_log += '   ğŸ¤– Captcha Detected: Agent encountered captcha challenges\n'
					judge_log += '   ğŸ‘‰ ğŸ¥· Use Browser Use Cloud for the most stealth browser infra: https://docs.browser-use.com/customize/browser/remote\n'
				judge_log += f'   {judgement.reasoning}\n'
				self.logger.info(judge_log)

	async def _get_model_output_with_retry(self, input_messages: list[BaseMessage]) -> AgentOutput:
		"""
		è·å–æ¨¡å‹è¾“å‡ºï¼Œå¸¦é‡è¯•é€»è¾‘ï¼ˆé’ˆå¯¹ç©ºåŠ¨ä½œï¼‰
		
		å¦‚æœæ¨¡å‹è¿”å›ç©ºåŠ¨ä½œï¼Œä¼šè¿›è¡Œé‡è¯•ï¼š
		1. ç¬¬ä¸€æ¬¡ï¼šå‘é€æ¾„æ¸…æ¶ˆæ¯è¦æ±‚è¿”å›æœ‰æ•ˆåŠ¨ä½œ
		2. ç¬¬äºŒæ¬¡ï¼šå¦‚æœä»ç„¶ä¸ºç©ºï¼Œæ’å…¥å®‰å…¨çš„ noop åŠ¨ä½œ
		
		Args:
		    input_messages: è¾“å…¥æ¶ˆæ¯åˆ—è¡¨
			
		Returns:
		    AgentOutput: æ¨¡å‹è¾“å‡º
		"""
		# ç¬¬ä¸€æ­¥ï¼šè°ƒç”¨æ ¸å¿ƒæ–¹æ³•è·å–æ¨¡å‹åŸå§‹è¾“å‡º
		model_output = await self.get_model_output(input_messages)
		self.logger.debug(
			f'âœ… Step {self.state.n_steps}: Got LLM response with {len(model_output.action) if model_output.action else 0} actions'
		)
		# æ ¸å¿ƒåˆ¤æ–­ï¼šæ£€æŸ¥åŠ¨ä½œæ˜¯å¦ä¸ºç©º/æ— æ•ˆï¼ˆä¸‰ç§æƒ…å†µï¼‰
		if (
			not model_output.action# åŠ¨ä½œå­—æ®µä¸ºç©º
			or not isinstance(model_output.action, list)# åŠ¨ä½œä¸æ˜¯åˆ—è¡¨ç±»å‹
			or all(action.model_dump() == {} for action in model_output.action)# åŠ¨ä½œåˆ—è¡¨é‡Œå…¨æ˜¯ç©ºå­—å…¸
		):
			self.logger.warning('Model returned empty action. Retrying...')
			# æ„é€ æ¾„æ¸…æ¶ˆæ¯ï¼šæé†’æ¨¡å‹è¿”å›ç¬¦åˆæ ¼å¼çš„æœ‰æ•ˆåŠ¨ä½œ
			clarification_message = UserMessage(
				content='You forgot to return an action. Please respond with a valid JSON action according to the expected schema with your assessment and next actions.'
			)
			# é‡è¯•æ¶ˆæ¯åˆ—è¡¨ = åŸå§‹æ¶ˆæ¯ + æ¾„æ¸…æ¶ˆæ¯
			retry_messages = input_messages + [clarification_message]
			# ç¬¬äºŒæ¬¡è°ƒç”¨æ¨¡å‹ï¼ˆé‡è¯•ï¼‰
			model_output = await self.get_model_output(retry_messages)
			# äºŒæ¬¡æ£€æŸ¥ï¼šå¦‚æœé‡è¯•ååŠ¨ä½œä»ç„¶æ— æ•ˆ
			if not model_output.action or all(action.model_dump() == {} for action in model_output.action):
				self.logger.warning('Model still returned empty after retry. Inserting safe noop action.')
				# åˆ›å»ºä¸€ä¸ªç©ºåŠ¨ä½œå®ä¾‹ï¼ˆActionModelæ˜¯è‡ªå®šä¹‰çš„åŠ¨ä½œæ¨¡å‹ç±»ï¼‰
				action_instance = self.ActionModel()
				# ç»™ç©ºåŠ¨ä½œè®¾ç½®ã€Œdoneã€å±æ€§ï¼šæ ‡è®°ä»»åŠ¡å¤±è´¥ï¼Œè¯´æ˜åŸå› 
				setattr(
					action_instance,
					'done',
					{
						'success': False,
						'text': 'No next action returned by LLM!',
					},
				)
				# å°†è¿™ä¸ªå®‰å…¨çš„ç©ºåŠ¨ä½œèµ‹å€¼ç»™æ¨¡å‹è¾“å‡ºï¼Œé¿å…ç¨‹åºä¸­æ–­
				model_output.action = [action_instance]
		# è¿”å›æœ€ç»ˆçš„æ¨¡å‹è¾“å‡ºï¼ˆè¦ä¹ˆæ˜¯æœ‰æ•ˆåŠ¨ä½œï¼Œè¦ä¹ˆæ˜¯é‡è¯•åçš„åŠ¨ä½œï¼Œè¦ä¹ˆæ˜¯å®‰å…¨ç©ºåŠ¨ä½œï¼‰
		return model_output

	async def _handle_post_llm_processing(
		self,
		browser_state_summary: BrowserStateSummary,
		input_messages: list[BaseMessage],
	) -> None:
		"""å¤„ç† LLM äº¤äº’åçš„å›è°ƒå’Œå¯¹è¯ä¿å­˜
		
		åœ¨ LLM è¿”å›åŠ¨ä½œå†³ç­–åï¼Œå®Œæˆä¸¤ä»¶äº‹ â€”â€” è§¦å‘å¤–éƒ¨è‡ªå®šä¹‰çš„æ­¥éª¤å›è°ƒï¼ˆé€šçŸ¥ä¸Šå±‚ç³»ç»Ÿè¿›åº¦ï¼‰ã€å°† LLM çš„è¾“å…¥è¾“å‡ºä¿å­˜ä¸ºå¯¹è¯æ–‡ä»¶ï¼ˆä¾¿äºå¤ç›˜å’Œè°ƒè¯•ï¼‰
		"""
		if self.register_new_step_callback and self.state.last_model_output:
			if inspect.iscoroutinefunction(self.register_new_step_callback):
				await self.register_new_step_callback(
					browser_state_summary,
					self.state.last_model_output,
					self.state.n_steps,
				)
			else:
				self.register_new_step_callback(
					browser_state_summary,
					self.state.last_model_output,
					self.state.n_steps,
				)

		if self.settings.save_conversation_path and self.state.last_model_output:
			# Treat save_conversation_path as a directory (consistent with other recording paths)
			conversation_dir = Path(self.settings.save_conversation_path)
			conversation_filename = f'conversation_{self.id}_{self.state.n_steps}.txt'
			target = conversation_dir / conversation_filename
			await save_conversation(
				input_messages,
				self.state.last_model_output,
				target,
				self.settings.save_conversation_path_encoding,
			)

	async def _make_history_item(
		self,
		model_output: AgentOutput | None,
		browser_state_summary: BrowserStateSummary,
		result: list[ActionResult],
		metadata: StepMetadata | None = None,
		state_message: str | None = None,
	) -> None:
		"""
		åˆ›å»ºå¹¶å­˜å‚¨å†å²è®°å½•é¡¹
		
		Args:
		    model_output: æ¨¡å‹è¾“å‡º
		    browser_state_summary: æµè§ˆå™¨çŠ¶æ€æ‘˜è¦
		    result: åŠ¨ä½œæ‰§è¡Œç»“æœåˆ—è¡¨
		    metadata: æ­¥éª¤å…ƒæ•°æ®
		    state_message: çŠ¶æ€æ¶ˆæ¯
		"""

		if model_output:
			interacted_elements = AgentHistory.get_interacted_element(model_output, browser_state_summary.dom_state.selector_map)
		else:
			interacted_elements = [None]

		# Store screenshot and get path
		screenshot_path = None
		if browser_state_summary.screenshot:
			self.logger.debug(
				f'ğŸ“¸ Storing screenshot for step {self.state.n_steps}, screenshot length: {len(browser_state_summary.screenshot)}'
			)
			screenshot_path = await self.screenshot_service.store_screenshot(browser_state_summary.screenshot, self.state.n_steps)
			self.logger.debug(f'ğŸ“¸ Screenshot stored at: {screenshot_path}')
		else:
			self.logger.debug(f'ğŸ“¸ No screenshot in browser_state_summary for step {self.state.n_steps}')

		state_history = BrowserStateHistory(
			url=browser_state_summary.url,
			title=browser_state_summary.title,
			tabs=browser_state_summary.tabs,
			interacted_element=interacted_elements,
			screenshot_path=screenshot_path,
		)

		history_item = AgentHistory(
			model_output=model_output,
			result=result,
			state=state_history,
			metadata=metadata,
			state_message=state_message,
		)

		self.history.add_item(history_item)

	def _remove_think_tags(self, text: str) -> str:
		THINK_TAGS = re.compile(r'<think>.*?</think>', re.DOTALL)
		STRAY_CLOSE_TAG = re.compile(r'.*?</think>', re.DOTALL)
		# Step 1: Remove well-formed <think>...</think>
		text = re.sub(THINK_TAGS, '', text)
		# Step 2: If there's an unmatched closing tag </think>,
		#         remove everything up to and including that.
		text = re.sub(STRAY_CLOSE_TAG, '', text)
		return text.strip()

	# region - URL replacement
	def _replace_urls_in_text(self, text: str) -> tuple[str, dict[str, str]]:
		"""Replace URLs in a text string"""

		replaced_urls: dict[str, str] = {}

		def replace_url(match: re.Match) -> str:
			"""Url can only have 1 query and 1 fragment"""
			import hashlib

			original_url = match.group(0)

			# Find where the query/fragment starts
			query_start = original_url.find('?')
			fragment_start = original_url.find('#')

			# Find the earliest position of query or fragment
			after_path_start = len(original_url)  # Default: no query/fragment
			if query_start != -1:
				after_path_start = min(after_path_start, query_start)
			if fragment_start != -1:
				after_path_start = min(after_path_start, fragment_start)

			# Split URL into base (up to path) and after_path (query + fragment)
			base_url = original_url[:after_path_start]
			after_path = original_url[after_path_start:]

			# If after_path is within the limit, don't shorten
			if len(after_path) <= self._url_shortening_limit:
				return original_url

			# If after_path is too long, truncate and add hash
			if after_path:
				truncated_after_path = after_path[: self._url_shortening_limit]
				# Create a short hash of the full after_path content
				hash_obj = hashlib.md5(after_path.encode('utf-8'))
				short_hash = hash_obj.hexdigest()[:7]
				# Create shortened URL
				shortened = f'{base_url}{truncated_after_path}...{short_hash}'
				# Only use shortened URL if it's actually shorter than the original
				if len(shortened) < len(original_url):
					replaced_urls[shortened] = original_url
					return shortened

			return original_url

		return URL_PATTERN.sub(replace_url, text), replaced_urls

	def _process_messsages_and_replace_long_urls_shorter_ones(self, input_messages: list[BaseMessage]) -> dict[str, str]:
		"""
		å°†é•¿ URL æ›¿æ¢ä¸ºçŸ­ URLï¼ˆåŸåœ°ä¿®æ”¹ input_messagesï¼‰
		
		Args:
		    input_messages: è¾“å…¥æ¶ˆæ¯åˆ—è¡¨
			
		Returns:
		    dict[str, str]: URL æ›¿æ¢æ˜ å°„ {çŸ­URL: åŸURL}
		"""
		from browser_use.llm.messages import AssistantMessage, UserMessage

		urls_replaced: dict[str, str] = {}

		# Process each message, in place
		for message in input_messages:
			# no need to process SystemMessage, we have control over that anyway
			if isinstance(message, (UserMessage, AssistantMessage)):
				if isinstance(message.content, str):
					# Simple string content
					message.content, replaced_urls = self._replace_urls_in_text(message.content)
					urls_replaced.update(replaced_urls)

				elif isinstance(message.content, list):
					# List of content parts
					for part in message.content:
						if isinstance(part, ContentPartTextParam):
							part.text, replaced_urls = self._replace_urls_in_text(part.text)
							urls_replaced.update(replaced_urls)

		return urls_replaced

	@staticmethod
	def _recursive_process_all_strings_inside_pydantic_model(model: BaseModel, url_replacements: dict[str, str]) -> None:
		"""
		é€’å½’å¤„ç† Pydantic æ¨¡å‹ä¸­çš„æ‰€æœ‰å­—ç¬¦ä¸²ï¼Œå°†çŸ­ URL æ›¿æ¢ä¸ºåŸ URLï¼ˆåŸåœ°ä¿®æ”¹ï¼‰
		
		Args:
		    model: Pydantic æ¨¡å‹å®ä¾‹
		    url_replacements: URL æ›¿æ¢æ˜ å°„
		"""
		for field_name, field_value in model.__dict__.items():
			if isinstance(field_value, str):
				# Replace shortened URLs with original URLs in string
				processed_string = Agent._replace_shortened_urls_in_string(field_value, url_replacements)
				setattr(model, field_name, processed_string)
			elif isinstance(field_value, BaseModel):
				# Recursively process nested Pydantic models
				Agent._recursive_process_all_strings_inside_pydantic_model(field_value, url_replacements)
			elif isinstance(field_value, dict):
				# Process dictionary values in place
				Agent._recursive_process_dict(field_value, url_replacements)
			elif isinstance(field_value, (list, tuple)):
				processed_value = Agent._recursive_process_list_or_tuple(field_value, url_replacements)
				setattr(model, field_name, processed_value)

	@staticmethod
	def _recursive_process_dict(dictionary: dict, url_replacements: dict[str, str]) -> None:
		"""
		é€’å½’å¤„ç†å­—å…¸ä¸­çš„æ‰€æœ‰å­—ç¬¦ä¸²ï¼Œå°†çŸ­ URL æ›¿æ¢ä¸ºåŸ URLï¼ˆåŸåœ°ä¿®æ”¹ï¼‰
		
		Args:
		    dictionary: å­—å…¸å¯¹è±¡
		    url_replacements: URL æ›¿æ¢æ˜ å°„
		"""
		for k, v in dictionary.items():
			if isinstance(v, str):
				dictionary[k] = Agent._replace_shortened_urls_in_string(v, url_replacements)
			elif isinstance(v, BaseModel):
				Agent._recursive_process_all_strings_inside_pydantic_model(v, url_replacements)
			elif isinstance(v, dict):
				Agent._recursive_process_dict(v, url_replacements)
			elif isinstance(v, (list, tuple)):
				dictionary[k] = Agent._recursive_process_list_or_tuple(v, url_replacements)

	@staticmethod
	def _recursive_process_list_or_tuple(container: list | tuple, url_replacements: dict[str, str]) -> list | tuple:
		"""
		é€’å½’å¤„ç†åˆ—è¡¨æˆ–å…ƒç»„ä¸­çš„æ‰€æœ‰å­—ç¬¦ä¸²ï¼Œå°†çŸ­ URL æ›¿æ¢ä¸ºåŸ URL
		
		Args:
		    container: åˆ—è¡¨æˆ–å…ƒç»„
		    url_replacements: URL æ›¿æ¢æ˜ å°„
			
		Returns:
		    list | tuple: å¤„ç†åçš„åˆ—è¡¨æˆ–å…ƒç»„
		"""
		if isinstance(container, tuple):
			# For tuples, create a new tuple with processed items
			processed_items = []
			for item in container:
				if isinstance(item, str):
					processed_items.append(Agent._replace_shortened_urls_in_string(item, url_replacements))
				elif isinstance(item, BaseModel):
					Agent._recursive_process_all_strings_inside_pydantic_model(item, url_replacements)
					processed_items.append(item)
				elif isinstance(item, dict):
					Agent._recursive_process_dict(item, url_replacements)
					processed_items.append(item)
				elif isinstance(item, (list, tuple)):
					processed_items.append(Agent._recursive_process_list_or_tuple(item, url_replacements))
				else:
					processed_items.append(item)
			return tuple(processed_items)
		else:
			# For lists, modify in place
			for i, item in enumerate(container):
				if isinstance(item, str):
					container[i] = Agent._replace_shortened_urls_in_string(item, url_replacements)
				elif isinstance(item, BaseModel):
					Agent._recursive_process_all_strings_inside_pydantic_model(item, url_replacements)
				elif isinstance(item, dict):
					Agent._recursive_process_dict(item, url_replacements)
				elif isinstance(item, (list, tuple)):
					container[i] = Agent._recursive_process_list_or_tuple(item, url_replacements)
			return container

	@staticmethod
	def _replace_shortened_urls_in_string(text: str, url_replacements: dict[str, str]) -> str:
		"""
		å°†å­—ç¬¦ä¸²ä¸­çš„æ‰€æœ‰çŸ­ URL æ›¿æ¢ä¸ºåŸ URL
		
		Args:
		    text: åŒ…å«çŸ­ URL çš„æ–‡æœ¬
		    url_replacements: URL æ›¿æ¢æ˜ å°„
			
		Returns:
		    str: æ›¿æ¢åçš„æ–‡æœ¬
		"""
		result = text
		for shortened_url, original_url in url_replacements.items():
			result = result.replace(shortened_url, original_url)
		return result

	# endregion - URL replacement

	@time_execution_async('--get_next_action')
	@observe_debug(ignore_input=True, ignore_output=True, name='get_model_output')
	async def get_model_output(self, input_messages: list[BaseMessage]) -> AgentOutput:
		"""
		ä» LLM è·å–ä¸‹ä¸€ä¸ªåŠ¨ä½œå†³ç­–
		
		è¿™æ˜¯ Agent å†³ç­–çš„æ ¸å¿ƒæ–¹æ³•ï¼Œè´Ÿè´£ï¼š
		1. å¤„ç†è¾“å…¥æ¶ˆæ¯ï¼ˆåŒ…æ‹¬ URL ç¼©çŸ­ï¼‰
		2. è°ƒç”¨ LLM è·å–å“åº”
		3. è§£æå’ŒéªŒè¯æ¨¡å‹è¾“å‡º
		4. å¤„ç†é€Ÿç‡é™åˆ¶å’Œå›é€€é€»è¾‘
		
		Args:
		    input_messages: å‘é€ç»™ LLM çš„æ¶ˆæ¯åˆ—è¡¨
			
		Returns:
		    AgentOutput: æ¨¡å‹è¾“å‡ºï¼ŒåŒ…å«åŠ¨ä½œå†³ç­–å’ŒçŠ¶æ€ä¿¡æ¯
		"""

		urls_replaced = self._process_messsages_and_replace_long_urls_shorter_ones(input_messages)

		# Build kwargs for ainvoke
		# Note: ChatBrowserUse will automatically generate action descriptions from output_format schema
		kwargs: dict = {'output_format': self.AgentOutput, 'session_id': self.session_id}

		try:
			response = await self.llm.ainvoke(input_messages, **kwargs)
			parsed: AgentOutput = response.completion  # type: ignore[assignment]

			# è¿˜åŸè¾“å‡ºä¸­çš„çŸ­URLä¸ºåŸå§‹URLï¼ˆä¿è¯åŠ¨ä½œæ‰§è¡Œæ—¶URLæœ‰æ•ˆ
			if urls_replaced:
				self._recursive_process_all_strings_inside_pydantic_model(parsed, urls_replaced)

			# cut the number of actions to max_actions_per_step if needed
			# è£å‰ªåŠ¨ä½œæ•°é‡ï¼šé¿å…LLMè¿”å›è¿‡å¤šåŠ¨ä½œï¼ˆè¶…è¿‡æ¯æ­¥æœ€å¤§é™åˆ¶ï¼‰
			if len(parsed.action) > self.settings.max_actions_per_step:
				parsed.action = parsed.action[: self.settings.max_actions_per_step]
			# éæš‚åœ/åœæ­¢çŠ¶æ€æ—¶ï¼Œè®°å½•å“åº”æ—¥å¿—+å¹¿æ’­æ¨¡å‹çŠ¶æ€
			if not (hasattr(self.state, 'paused') and (self.state.paused or self.state.stopped)):
				log_response(parsed, self.tools.registry.registry, self.logger)
				await self._broadcast_model_state(parsed)
			# è®°å½•ä¸‹ä¸€æ­¥åŠ¨ä½œæ‘˜è¦ï¼ˆç®€åŒ–æ—¥å¿—ï¼Œä¾¿äºå¿«é€ŸæŸ¥çœ‹ï¼‰
			self._log_next_action_summary(parsed)
			return parsed
		except ValidationError:
			# Just re-raise - Pydantic's validation errors are already descriptive
			raise
		except (ModelRateLimitError, ModelProviderError) as e:
			# Check if we can switch to a fallback LLM
			if not self._try_switch_to_fallback_llm(e):
				# No fallback available, re-raise the original error
				raise
			# Retry with the fallback LLM
			return await self.get_model_output(input_messages)

	def _try_switch_to_fallback_llm(self, error: ModelRateLimitError | ModelProviderError) -> bool:
		"""
		å°è¯•åœ¨é€Ÿç‡é™åˆ¶æˆ–æä¾›è€…é”™è¯¯ååˆ‡æ¢åˆ°å¤‡ç”¨ LLM
		
		æ”¯æŒçš„é”™è¯¯ä»£ç ï¼š
		- 401: API å¯†é’¥æ— æ•ˆ/è¿‡æœŸ
		- 402: ä½™é¢ä¸è¶³/éœ€è¦ä»˜è´¹
		- 429: é€Ÿç‡é™åˆ¶
		- 500, 502, 503, 504: æœåŠ¡å™¨é”™è¯¯
		
		Args:
		    error: æ¨¡å‹é”™è¯¯ï¼ˆé€Ÿç‡é™åˆ¶æˆ–æä¾›è€…é”™è¯¯ï¼‰
			
		Returns:
		    bool: å¦‚æœæˆåŠŸåˆ‡æ¢åˆ°å¤‡ç”¨ LLM è¿”å› Trueï¼Œå¦åˆ™è¿”å› False
		    
		Note:
		    ä¸€æ—¦åˆ‡æ¢ï¼Œä»£ç†å°†åœ¨å‰©ä½™è¿è¡Œä¸­ä½¿ç”¨å¤‡ç”¨ LLM
		"""
		# Already using fallback - can't switch again
		if self._using_fallback_llm:
			self.logger.warning(
				f'âš ï¸ Fallback LLM also failed ({type(error).__name__}: {error.message}), no more fallbacks available'
			)
			return False

		# Check if error is retryable (rate limit, auth errors, or server errors)
		# 401: API key invalid/expired - fallback to different provider
		# 402: Insufficient credits/payment required - fallback to different provider
		# 429: Rate limit exceeded
		# 500, 502, 503, 504: Server errors
		retryable_status_codes = {401, 402, 429, 500, 502, 503, 504}
		is_retryable = isinstance(error, ModelRateLimitError) or (
			hasattr(error, 'status_code') and error.status_code in retryable_status_codes
		)

		if not is_retryable:
			return False

		# Check if we have a fallback LLM configured
		if self._fallback_llm is None:
			self.logger.warning(f'âš ï¸ LLM error ({type(error).__name__}: {error.message}) but no fallback_llm configured')
			return False

		self._log_fallback_switch(error, self._fallback_llm)

		# Switch to the fallback LLM
		self.llm = self._fallback_llm
		self._using_fallback_llm = True

		# Register the fallback LLM for token cost tracking
		self.token_cost_service.register_llm(self._fallback_llm)

		return True

	def _log_fallback_switch(self, error: ModelRateLimitError | ModelProviderError, fallback: BaseChatModel) -> None:
		"""Log when switching to a fallback LLM."""
		original_model = self._original_llm.model if hasattr(self._original_llm, 'model') else 'unknown'
		fallback_model = fallback.model if hasattr(fallback, 'model') else 'unknown'
		error_type = type(error).__name__
		status_code = getattr(error, 'status_code', 'N/A')

		self.logger.warning(
			f'âš ï¸ Primary LLM ({original_model}) failed with {error_type} (status={status_code}), '
			f'switching to fallback LLM ({fallback_model})'
		)

	async def _log_agent_run(self) -> None:
		"""Log the agent run"""
		# Blue color for task
		self.logger.info(f'\033[34mğŸ¯ Task: {self.task}\033[0m')

		self.logger.debug(f'ğŸ¤– Browser-Use Library Version {self.version} ({self.source})')

		# Check for latest version and log upgrade message if needed
		if CONFIG.BROWSER_USE_VERSION_CHECK:
			latest_version = await check_latest_browser_use_version()
			if latest_version and latest_version != self.version:
				self.logger.info(
					f'ğŸ“¦ Newer version available: {latest_version} (current: {self.version}). Upgrade with: uv add browser-use=={latest_version}'
				)

	def _log_first_step_startup(self) -> None:
		"""ä»…åœ¨ç¬¬ä¸€æ­¥æ—¶è®°å½•å¯åŠ¨æ¶ˆæ¯"""
		if len(self.history.history) == 0:
			self.logger.info(
				f'Starting a browser-use agent with version {self.version}, with provider={self.llm.provider} and model={self.llm.model}'
			)

	def _log_step_context(self, browser_state_summary: BrowserStateSummary) -> None:
		"""è®°å½•æ­¥éª¤ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ŒåŒ…æ‹¬URLå’Œäº¤äº’å…ƒç´ æ•°é‡"""
		url = browser_state_summary.url if browser_state_summary else ''
		url_short = url[:50] + '...' if len(url) > 50 else url
		interactive_count = len(browser_state_summary.dom_state.selector_map) if browser_state_summary else 0
		self.logger.info('\n')
		self.logger.info(f'ğŸ“ Step {self.state.n_steps}:')
		self.logger.debug(f'Evaluating page with {interactive_count} interactive elements on: {url_short}')

	def _log_next_action_summary(self, parsed: 'AgentOutput') -> None:
		"""è®°å½•ä¸‹ä¸€ä¸ªåŠ¨ä½œçš„è¯¦ç»†æ‘˜è¦"""
		if not (self.logger.isEnabledFor(logging.DEBUG) and parsed.action):
			return

		action_count = len(parsed.action)

		# Collect action details
		action_details = []
		for i, action in enumerate(parsed.action):
			action_data = action.model_dump(exclude_unset=True)
			action_name = next(iter(action_data.keys())) if action_data else 'unknown'
			action_params = action_data.get(action_name, {}) if action_data else {}

			# Format key parameters concisely
			param_summary = []
			if isinstance(action_params, dict):
				for key, value in action_params.items():
					if key == 'index':
						param_summary.append(f'#{value}')
					elif key == 'text' and isinstance(value, str):
						text_preview = value[:30] + '...' if len(value) > 30 else value
						param_summary.append(f'text="{text_preview}"')
					elif key == 'url':
						param_summary.append(f'url="{value}"')
					elif key == 'success':
						param_summary.append(f'success={value}')
					elif isinstance(value, (str, int, bool)):
						val_str = str(value)[:30] + '...' if len(str(value)) > 30 else str(value)
						param_summary.append(f'{key}={val_str}')

			param_str = f'({", ".join(param_summary)})' if param_summary else ''
			action_details.append(f'{action_name}{param_str}')

	def _prepare_demo_message(self, message: str, limit: int = 600) -> str:
		"""å‡†å¤‡æ¼”ç¤ºæ¨¡å¼æ¶ˆæ¯"""
		# ä¹‹å‰ä¼šæˆªæ–­é•¿æ¡ç›®ï¼›ç°åœ¨ä¿ç•™å®Œæ•´æ–‡æœ¬ä»¥åœ¨æ¼”ç¤ºé¢æ¿ä¸­æä¾›æ›´å¥½çš„ä¸Šä¸‹æ–‡
		return message.strip()

	async def _demo_mode_log(self, message: str, level: str = 'info', metadata: dict[str, Any] | None = None) -> None:
		"""å‘é€æ¼”ç¤ºæ¨¡å¼æ—¥å¿—æ¶ˆæ¯åˆ°æµè§ˆå™¨å åŠ å±‚"""
		if not self._demo_mode_enabled or not message or self.browser_session is None:
			return
		try:
			await self.browser_session.send_demo_mode_log(
				message=self._prepare_demo_message(message),
				level=level,
				metadata=metadata or {},
			)
		except Exception as exc:
			self.logger.debug(f'[DemoMode] Failed to send overlay log: {exc}')

	async def _broadcast_model_state(self, parsed: 'AgentOutput') -> None:
		"""å¹¿æ’­æ¨¡å‹çŠ¶æ€åˆ°æ¼”ç¤ºæ¨¡å¼æ—¥å¿—"""
		if not self._demo_mode_enabled:
			return

		state = parsed.current_state
		step_meta = {'step': self.state.n_steps}

		if state.thinking:
			await self._demo_mode_log(state.thinking, 'thought', step_meta)

		if state.evaluation_previous_goal:
			eval_text = state.evaluation_previous_goal
			level = 'success' if 'success' in eval_text.lower() else 'warning' if 'failure' in eval_text.lower() else 'info'
			await self._demo_mode_log(eval_text, level, step_meta)

		if state.memory:
			await self._demo_mode_log(f'Memory: {state.memory}', 'info', step_meta)

		if state.next_goal:
			await self._demo_mode_log(f'Next goal: {state.next_goal}', 'info', step_meta)

	def _log_step_completion_summary(self, step_start_time: float, result: list[ActionResult]) -> str | None:
		"""è®°å½•æ­¥éª¤å®Œæˆæ‘˜è¦ï¼ŒåŒ…æ‹¬åŠ¨ä½œè®¡æ•°ã€æ—¶é—´å’ŒæˆåŠŸ/å¤±è´¥ç»Ÿè®¡"""
		if not result:
			return None

		step_duration = time.time() - step_start_time
		action_count = len(result)

		# Count success and failures
		success_count = sum(1 for r in result if not r.error)
		failure_count = action_count - success_count

		# Format success/failure indicators
		success_indicator = f'âœ… {success_count}' if success_count > 0 else ''
		failure_indicator = f'âŒ {failure_count}' if failure_count > 0 else ''
		status_parts = [part for part in [success_indicator, failure_indicator] if part]
		status_str = ' | '.join(status_parts) if status_parts else 'âœ… 0'

		message = (
			f'ğŸ“ Step {self.state.n_steps}: Ran {action_count} action{"" if action_count == 1 else "s"} '
			f'in {step_duration:.2f}s: {status_str}'
		)
		self.logger.debug(message)
		return message

	def _log_final_outcome_messages(self) -> None:
		"""æ ¹æ®ä»£ç†è¿è¡Œç»“æœå‘ç”¨æˆ·è®°å½•æœ‰ç”¨çš„æ¶ˆæ¯"""
		# æ£€æŸ¥ä»£ç†æ˜¯å¦å¤±è´¥
		is_successful = self.history.is_successful()

		if is_successful is False or is_successful is None:
			# Get final result to check for specific failure reasons
			final_result = self.history.final_result()
			final_result_str = str(final_result).lower() if final_result else ''

			# Check for captcha/cloudflare related failures
			captcha_keywords = ['captcha', 'cloudflare', 'recaptcha', 'challenge', 'bot detection', 'access denied']
			has_captcha_issue = any(keyword in final_result_str for keyword in captcha_keywords)

			if has_captcha_issue:
				# Suggest use_cloud=True for captcha/cloudflare issues
				task_preview = self.task[:10] if len(self.task) > 10 else self.task
				self.logger.info('')
				self.logger.info('Failed because of CAPTCHA? For better browser stealth, try:')
				self.logger.info(f'   agent = Agent(task="{task_preview}...", browser=Browser(use_cloud=True))')

			# General failure message
			self.logger.info('')
			self.logger.info('Did the Agent not work as expected? Let us fix this!')
			self.logger.info('   Open a short issue on GitHub: https://github.com/browser-use/browser-use/issues')

	def _log_agent_event(self, max_steps: int, agent_run_error: str | None = None) -> None:
		"""å‘é€æ­¤æ¬¡è¿è¡Œçš„ä»£ç†äº‹ä»¶åˆ°é¥æµ‹ç³»ç»Ÿ"""

		token_summary = self.token_cost_service.get_usage_tokens_for_model(self.llm.model)

		# Prepare action_history data correctly
		action_history_data = []
		for item in self.history.history:
			if item.model_output and item.model_output.action:
				# Convert each ActionModel in the step to its dictionary representation
				step_actions = [
					action.model_dump(exclude_unset=True)
					for action in item.model_output.action
					if action  # Ensure action is not None if list allows it
				]
				action_history_data.append(step_actions)
			else:
				# Append None or [] if a step had no actions or no model output
				action_history_data.append(None)

		final_res = self.history.final_result()
		final_result_str = json.dumps(final_res) if final_res is not None else None

		# Extract judgement data if available
		judgement_data = self.history.judgement()
		judge_verdict = judgement_data.get('verdict') if judgement_data else None
		judge_reasoning = judgement_data.get('reasoning') if judgement_data else None
		judge_failure_reason = judgement_data.get('failure_reason') if judgement_data else None
		judge_reached_captcha = judgement_data.get('reached_captcha') if judgement_data else None
		judge_impossible_task = judgement_data.get('impossible_task') if judgement_data else None

		self.telemetry.capture(
			AgentTelemetryEvent(
				task=self.task,
				model=self.llm.model,
				model_provider=self.llm.provider,
				max_steps=max_steps,
				max_actions_per_step=self.settings.max_actions_per_step,
				use_vision=self.settings.use_vision,
				version=self.version,
				source=self.source,
				cdp_url=urlparse(self.browser_session.cdp_url).hostname
				if self.browser_session and self.browser_session.cdp_url
				else None,
				agent_type=None,  # Regular Agent (not code-use)
				action_errors=self.history.errors(),
				action_history=action_history_data,
				urls_visited=self.history.urls(),
				steps=self.state.n_steps,
				total_input_tokens=token_summary.prompt_tokens,
				total_output_tokens=token_summary.completion_tokens,
				prompt_cached_tokens=token_summary.prompt_cached_tokens,
				total_tokens=token_summary.total_tokens,
				total_duration_seconds=self.history.total_duration_seconds(),
				success=self.history.is_successful(),
				final_result_response=final_result_str,
				error_message=agent_run_error,
				judge_verdict=judge_verdict,
				judge_reasoning=judge_reasoning,
				judge_failure_reason=judge_failure_reason,
				judge_reached_captcha=judge_reached_captcha,
				judge_impossible_task=judge_impossible_task,
			)
		)

	async def take_step(self, step_info: AgentStepInfo | None = None) -> tuple[bool, bool]:
		"""æ‰§è¡Œä¸€ä¸ªæ­¥éª¤

		Returns:
		        Tuple[bool, bool]: (is_done, is_valid) - æ˜¯å¦å®Œæˆï¼Œæ˜¯å¦æœ‰æ•ˆ
		"""
		if step_info is not None and step_info.step_number == 0:
			# First step
			self._log_first_step_startup()
			# Normally there was no try catch here but the callback can raise an InterruptedError which we skip
			try:
				await self._execute_initial_actions()
			except InterruptedError:
				pass
			except Exception as e:
				raise e

		await self.step(step_info)

		if self.history.is_done():
			await self.log_completion()

			# Run judge before done callback if enabled
			if self.settings.use_judge:
				await self._judge_and_log()

			if self.register_done_callback:
				if inspect.iscoroutinefunction(self.register_done_callback):
					await self.register_done_callback(self.history)
				else:
					self.register_done_callback(self.history)
			return True, True

		return False, False

	def _extract_start_url(self, task: str) -> str | None:
		"""Extract URL from task string using naive pattern matching.
		
		ä¸€ä¸ªåŸºäºæ­£åˆ™åŒ¹é…çš„ URL æå–å‡½æ•°ï¼Œæ ¸å¿ƒç›®æ ‡æ˜¯ä»ç”¨æˆ·çš„ä»»åŠ¡å­—ç¬¦ä¸²ä¸­ï¼Œç­›é€‰å‡ºå”¯ä¸€ã€å¯å¯¼èˆªçš„èµ·å§‹ URLï¼ŒåŒæ—¶é€šè¿‡å¤šå±‚è¿‡æ»¤è§„åˆ™æ’é™¤æ— æ•ˆ / æ— å…³çš„ URLï¼Œé¿å…è¯¯è¯†åˆ«ï¼š
			å…ˆç§»é™¤ä»»åŠ¡ä¸­çš„é‚®ç®±åœ°å€ï¼ˆé¿å…è¢«è¯¯åˆ¤ä¸º URLï¼‰ï¼›
			ç”¨æ­£åˆ™åŒ¹é…è¯†åˆ«ä¸¤ç§å¸¸è§ URL æ ¼å¼ï¼›
			è¿‡æ»¤æ‰å¸¦ç‰¹å®šæ–‡ä»¶åç¼€ã€å«å¦å®šè¯­å¢ƒçš„ URLï¼›
			è‡ªåŠ¨è¡¥å…¨ HTTPS åè®®ï¼›
			è¿”å›å€¼ï¼šä»…è¿”å›å”¯ä¸€åŒ¹é…çš„ URLï¼ˆå¤šä¸ªåˆ™è¿”å› Noneï¼Œé¿å…æ­§ä¹‰ï¼Œä¸è‡ªåŠ¨å¯¼èˆªï¼‰ã€‚
		
		"""

		import re

		# Remove email addresses from task before looking for URLs
		task_without_emails = re.sub(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b', '', task)

		# Look for common URL patterns
		patterns = [
			r'https?://[^\s<>"\']+',  # Full URLs with http/https
			r'(?:www\.)?[a-zA-Z0-9-]+(?:\.[a-zA-Z0-9-]+)*\.[a-zA-Z]{2,}(?:/[^\s<>"\']*)?',  # Domain names with subdomains and optional paths
		]

		# File extensions that should be excluded from URL detection
		# These are likely files rather than web pages to navigate to
		excluded_extensions = {
			# Documents
			'pdf',
			'doc',
			'docx',
			'xls',
			'xlsx',
			'ppt',
			'pptx',
			'odt',
			'ods',
			'odp',
			# Text files
			'txt',
			'md',
			'csv',
			'json',
			'xml',
			'yaml',
			'yml',
			# Archives
			'zip',
			'rar',
			'7z',
			'tar',
			'gz',
			'bz2',
			'xz',
			# Images
			'jpg',
			'jpeg',
			'png',
			'gif',
			'bmp',
			'svg',
			'webp',
			'ico',
			# Audio/Video
			'mp3',
			'mp4',
			'avi',
			'mkv',
			'mov',
			'wav',
			'flac',
			'ogg',
			# Code/Data
			'py',
			'js',
			'css',
			'java',
			'cpp',
			# Academic/Research
			'bib',
			'bibtex',
			'tex',
			'latex',
			'cls',
			'sty',
			# Other common file types
			'exe',
			'msi',
			'dmg',
			'pkg',
			'deb',
			'rpm',
			'iso',
			# GitHub/Project paths
			'polynomial',
		}

		excluded_words = {
			'never',
			'dont',
			'not',
			"don't",
		}

		found_urls = []
		for pattern in patterns:
			matches = re.finditer(pattern, task_without_emails)
			for match in matches:
				url = match.group(0)
				original_position = match.start()  # Store original position before URL modification

				# Remove trailing punctuation that's not part of URLs
				url = re.sub(r'[.,;:!?()\[\]]+$', '', url)

				# Check if URL ends with a file extension that should be excluded
				url_lower = url.lower()
				should_exclude = False
				for ext in excluded_extensions:
					if f'.{ext}' in url_lower:
						should_exclude = True
						break

				if should_exclude:
					self.logger.debug(f'Excluding URL with file extension from auto-navigation: {url}')
					continue

				# If in the 20 characters before the url position is a word in excluded_words skip to avoid "Never go to this url"
				context_start = max(0, original_position - 20)
				context_text = task_without_emails[context_start:original_position]
				if any(word.lower() in context_text.lower() for word in excluded_words):
					self.logger.debug(
						f'Excluding URL with word in excluded words from auto-navigation: {url} (context: "{context_text.strip()}")'
					)
					continue

				# Add https:// if missing (after excluded words check to avoid position calculation issues)
				if not url.startswith(('http://', 'https://')):
					url = 'https://' + url

				found_urls.append(url)

		unique_urls = list(set(found_urls))
		# If multiple URLs found, skip directly_open_urling
		if len(unique_urls) > 1:
			self.logger.debug(f'Multiple URLs found ({len(found_urls)}), skipping directly_open_url to avoid ambiguity')
			return None

		# If exactly one URL found, return it
		if len(unique_urls) == 1:
			return unique_urls[0]

		return None

	async def _execute_step(
		self,
		step: int,
		max_steps: int,
		step_info: AgentStepInfo,
		on_step_start: AgentHookFunc | None = None,
		on_step_end: AgentHookFunc | None = None,
	) -> bool:
		"""
		æ‰§è¡Œæ™ºèƒ½ä½“çš„å•ä¸ªæ­¥éª¤ï¼Œæ·»åŠ è¶…æ—¶ä¿æŠ¤ï¼Œå¤„ç†æ­¥éª¤çº§å›è°ƒå’Œæ¼”ç¤ºæ—¥å¿—ï¼Œåˆ¤æ–­ä»»åŠ¡æ˜¯å¦å®Œæˆï¼Œè¿”å›å¸ƒå°”å€¼æ ‡è®°æ­¥éª¤ç»“æŸåä»»åŠ¡æ˜¯å¦å®Œæˆ

		Returns:
			bool: å¦‚æœä»»åŠ¡å®Œæˆè¿”å› Trueï¼Œå¦åˆ™è¿”å› False
		"""
		# 1. æ‰§è¡Œæ­¥éª¤å¼€å§‹å‰çš„å›è°ƒå‡½æ•°ï¼ˆå¤–éƒ¨ä¼ å…¥çš„é’©å­ï¼‰
		if on_step_start is not None:
			await on_step_start(self)
		# 2. æ¼”ç¤ºæ¨¡å¼ä¸‹è¾“å‡ºæ­¥éª¤å¼€å§‹æ—¥å¿—ï¼ˆå¸¦æ­¥æ•°/æ€»æ­¥æ•°å…ƒæ•°æ®ï¼‰
		await self._demo_mode_log(
			f'Starting step {step + 1}/{max_steps}',
			'info',
			{'step': step + 1, 'total_steps': max_steps},
		)

		self.logger.debug(f'ğŸš¶ Starting step {step + 1}/{max_steps}...')

		try:
			# æ‰§è¡Œæ ¸å¿ƒæ­¥éª¤é€»è¾‘ï¼Œæ·»åŠ è¶…æ—¶ä¿æŠ¤ï¼ˆè¶…æ—¶æ—¶é—´ç”±é…ç½®æŒ‡å®šï¼‰
			await asyncio.wait_for(
				# çœŸæ­£æ‰§è¡Œå•æ­¥çš„æ ¸å¿ƒé€»è¾‘ï¼ˆå¦‚è°ƒç”¨LLMã€æ“ä½œæµè§ˆå™¨ï¼‰
				self.step(step_info),
				# æ­¥éª¤è¶…æ—¶æ—¶é—´ï¼ˆæ¯”å¦‚30ç§’ï¼‰
				timeout=self.settings.step_timeout,
			)
			self.logger.debug(f'âœ… Completed step {step + 1}/{max_steps}')
		except TimeoutError:
			# å¤„ç†æ­¥éª¤è¶…æ—¶å¼‚å¸¸ï¼ˆä¼˜é›…å®¹é”™ï¼‰
			error_msg = f'Step {step + 1} timed out after {self.settings.step_timeout} seconds'
			self.logger.error(f'â° {error_msg}')
			await self._demo_mode_log(error_msg, 'error', {'step': step + 1})
			# æ›´æ–°çŠ¶æ€ï¼šè¿ç»­å¤±è´¥æ¬¡æ•°+1ï¼Œè®°å½•è¶…æ—¶é”™è¯¯ç»“æœ
			self.state.consecutive_failures += 1
			self.state.last_result = [ActionResult(error=error_msg)]

		if on_step_end is not None:
			await on_step_end(self)

		if self.history.is_done():
			await self.log_completion()

			# Run judge before done callback if enabled
			if self.settings.use_judge:
				await self._judge_and_log()

			if self.register_done_callback:
				if inspect.iscoroutinefunction(self.register_done_callback):
					await self.register_done_callback(self.history)
				else:
					self.register_done_callback(self.history)

			return True

		return False

	@observe(name='agent.run', ignore_input=True, ignore_output=True)
	@time_execution_async('--run')
	async def run(
		self,
		max_steps: int = 100,  # æœ€å¤§æ‰§è¡Œæ­¥æ•°ï¼Œé»˜è®¤100æ­¥
		on_step_start: AgentHookFunc | None = None,  # æ¯æ­¥å¼€å§‹å‰çš„å›è°ƒå‡½æ•°
		on_step_end: AgentHookFunc | None = None,  # æ¯æ­¥ç»“æŸåçš„å›è°ƒå‡½æ•°
	) -> AgentHistoryList[AgentStructuredOutput]:
		"""
		æ‰§è¡Œä»»åŠ¡çš„ä¸»è¦æ–¹æ³• - è¿è¡Œ Agent å®ŒæˆæŒ‡å®šä»»åŠ¡
		- ä½œç”¨ï¼šæŒ‰ç…§æŒ‡å®šçš„æœ€å¤§æ­¥æ•°è¿è¡Œæ™ºèƒ½ä½“å®Œæˆä»»åŠ¡ï¼ŒåŒæ—¶å¤„ç†æš‚åœ / ç»ˆæ­¢ä¿¡å·ã€è®°å½•é¥æµ‹æ•°æ®ã€åˆ†å‘äº‹ä»¶ã€æ¸…ç†èµ„æºï¼Œæœ€ç»ˆè¿”å›æ‰§è¡Œå†å²
		Args:
		    max_steps: æœ€å¤§æ‰§è¡Œæ­¥æ•°ï¼Œé˜²æ­¢æ— é™å¾ªç¯
		    on_step_start: æ¯æ­¥å¼€å§‹å‰çš„å›è°ƒå‡½æ•°
		    on_step_end: æ¯æ­¥ç»“æŸåçš„å›è°ƒå‡½æ•°
			
		Returns:
		    AgentHistoryList: æ‰§è¡Œå†å²è®°å½•åˆ—è¡¨ï¼ŒåŒ…å«æ¯ä¸€æ­¥çš„æ‰§è¡Œç»“æœ
		"""
		# è·å–å¼‚æ­¥å¾ªç¯ã€åˆå§‹åŒ–é”™è¯¯è¿½è¸ªã€å¼ºåˆ¶é€€å‡ºæ ‡è®°
		loop = asyncio.get_event_loop()
		agent_run_error: str | None = None  # Initialize error tracking variable
		self._force_exit_telemetry_logged = False  # ADDED: Flag for custom telemetry on force exit
		should_delay_close = False

		# Set up the  signal handler with callbacks specific to this agent
		# æ³¨å†Œä¿¡å·å¤„ç†å™¨ï¼ˆå¤„ç†Ctrl+Cç­‰é€€å‡ºä¿¡å·ï¼‰
		# æ ¸å¿ƒä½œç”¨ï¼šå¤„ç†ç”¨æˆ·æ‰‹åŠ¨ç»ˆæ­¢ï¼ˆCtrl+Cï¼‰ï¼Œä¿è¯å¼ºåˆ¶é€€å‡ºæ—¶ä¹Ÿèƒ½è®°å½•é¥æµ‹æ•°æ®ï¼Œé¿å…æ•°æ®ä¸¢å¤±ï¼›
		from browser_use.utils import SignalHandler

		# Define the custom exit callback function for second CTRL+C
		# å¼ºåˆ¶é€€å‡ºæ—¶è®°å½•é¥æµ‹ã€åˆ·ç›˜ã€æ ‡è®°å·²è®°å½•
		def on_force_exit_log_telemetry():
			self._log_agent_event(max_steps=max_steps, agent_run_error='SIGINT: Cancelled by user')
			# NEW: Call the flush method on the telemetry instance
			if hasattr(self, 'telemetry') and self.telemetry:
				self.telemetry.flush()
			self._force_exit_telemetry_logged = True  # Set the flag

		signal_handler = SignalHandler(
			loop=loop,
			pause_callback=self.pause,
			resume_callback=self.resume,
			custom_exit_callback=on_force_exit_log_telemetry,  # å¼ºåˆ¶é€€å‡ºå›è°ƒ
			exit_on_second_int=True, # ç¬¬ä¸€æ¬¡ Ctrl+C æš‚åœï¼Œç¬¬äºŒæ¬¡Ctrl+Cå¼ºåˆ¶é€€å‡º
		)
		signal_handler.register()

		try:
			# è®°å½•å¯åŠ¨æ—¥å¿—ã€åˆå§‹åŒ–è®¡æ—¶
			await self._log_agent_run()

			self.logger.debug(
				f'ğŸ”§ Agent setup: Agent Session ID {self.session_id[-4:]}, Task ID {self.task_id[-4:]}, Browser Session ID {self.browser_session.id[-4:] if self.browser_session else "None"} {"(connecting via CDP)" if (self.browser_session and self.browser_session.cdp_url) else "(launching local browser)"}'
			)

			# Initialize timing for session and task
			self._session_start_time = time.time()
			self._task_start_time = self._session_start_time  # Initialize task start time

			# Only dispatch session events if this is the first run
			# é¦–æ¬¡è¿è¡Œæ—¶åˆ†å‘ã€Œåˆ›å»ºä¼šè¯äº‹ä»¶ã€
			if not self.state.session_initialized:
				self.logger.debug('ğŸ“¡ Dispatching CreateAgentSessionEvent...')
				# Emit CreateAgentSessionEvent at the START of run()
				self.eventbus.dispatch(CreateAgentSessionEvent.from_agent(self))

				self.state.session_initialized = True

			self.logger.debug('ğŸ“¡ Dispatching CreateAgentTaskEvent...')
			# Emit CreateAgentTaskEvent at the START of run()
			# åˆ†å‘ã€Œåˆ›å»ºä»»åŠ¡äº‹ä»¶ã€
			self.eventbus.dispatch(CreateAgentTaskEvent.from_agent(self))

			# Log startup message on first step (only if we haven't already done steps)
			
			self._log_first_step_startup()
			# Start browser session and attach watchdogs
			# å¯åŠ¨æµè§ˆå™¨ä¼šè¯ ==> æ‰§è¡Œå®Œè¿™å¥è¯åï¼Œæµè§ˆå™¨æ‰çœŸæ­£å¯åŠ¨
			self.logger.debug('ğŸŒ --2516---Starting browser session...')
			await self.browser_session.start()
			# å½“å¯ç”¨æ¼”ç¤ºæ¨¡å¼æ—¶ï¼Œå‘ç”¨æˆ· / å‰ç«¯é¢æ¿è¾“å‡ºå‹å¥½çš„ä»»åŠ¡å¯åŠ¨æç¤ºå’Œæ¨¡å¼è¯´æ˜ï¼Œè®©ä½¿ç”¨è€…æ¸…æ™°æ„ŸçŸ¥ä»»åŠ¡çŠ¶æ€å’Œæ¼”ç¤ºæ¨¡å¼çš„äº¤äº’æ–¹å¼
			if self._demo_mode_enabled:
				await self._demo_mode_log(f'Started task: {self.task}', 'info', {'tag': 'task'})
				await self._demo_mode_log(
					'Demo mode active - follow the side panel for live thoughts and actions.',
					'info',
					{'tag': 'status'},
				)

			# æ³¨å†ŒæŠ€èƒ½ï¼šRegister skills as actions if SkillService is configured
			await self._register_skills_as_actions()

			# æ‰§è¡Œåˆå§‹åŠ¨ä½œï¼Œå¹¶åŒæ­¥åˆ°agentçŠ¶æ€ä¸­ä½œä¸ºç¬¬0æ­¥----å¦‚æœä¼ äº†initial_actionså‚æ•°ï¼šNormally there was no try catch here but the callback can raise an InterruptedErro
			try:
				await self._execute_initial_actions()
			except InterruptedError:
				pass
			except Exception as e:
				raise e

			self.logger.debug(
				f'ğŸ”„ Starting main execution loop with max {max_steps} steps (currently at step {self.state.n_steps})...'
			)

			# æ ¸å¿ƒæ‰§è¡Œå¾ªç¯ï¼ˆæ­¥éª¤æ§åˆ¶ï¼‰
			while self.state.n_steps <= max_steps:
				# è½¬ä¸º0ç´¢å¼•
				current_step = self.state.n_steps - 1  # Convert to 0-indexed for step_info

				# # æš‚åœé€»è¾‘ï¼šè‹¥æš‚åœåˆ™ç­‰å¾…å¤–éƒ¨æ¢å¤ä¿¡å· Use the consolidated pause state management
				if self.state.paused:
					self.logger.debug(f'â¸ï¸ Step {self.state.n_steps}: Agent paused, waiting to resume...')
					await self._external_pause_event.wait()
					signal_handler.reset()

				# # å¤±è´¥æ¬¡æ•°è¶…é™ï¼šç»ˆæ­¢å¾ªç¯ï¼šCheck if we should stop due to too many failures, if final_response_after_failure is True, we try one last time
				if (self.state.consecutive_failures) >= self.settings.max_failures + int(
					self.settings.final_response_after_failure
				):
					self.logger.error(f'âŒ Stopping due to {self.settings.max_failures} consecutive failures')
					agent_run_error = f'Stopped due to {self.settings.max_failures} consecutive failures'
					break

				# å¤–éƒ¨ç»ˆæ­¢ï¼šç»ˆæ­¢å¾ªç¯ï¼š Check control flags before each step
				if self.state.stopped:
					self.logger.info('ğŸ›‘ Agent stopped')
					agent_run_error = 'Agent stopped programmatically'
					break

				step_info = AgentStepInfo(step_number=current_step, max_steps=max_steps)
				# æ‰§è¡Œå•æ­¥åŠ¨ä½œï¼Œè¿”å›æ˜¯å¦å®Œæˆä»»åŠ¡
				is_done = await self._execute_step(current_step, max_steps, step_info, on_step_start, on_step_end)

				if is_done:
					# Agent has marked the task as done
					# æ³¨é‡Šï¼šAgentå·²æ ‡è®°ä»»åŠ¡ä¸ºå®Œæˆ
					if self._demo_mode_enabled and self.history.history:
						# è·å–æœ€ç»ˆç»“æœï¼ˆæ— ç»“æœåˆ™é»˜è®¤'Task completed'ï¼‰
						final_result_text = self.history.final_result() or 'Task completed'
						await self._demo_mode_log(f'Final Result: {final_result_text}', 'success', {'tag': 'task'})

					# æ ‡è®°éœ€è¦å»¶è¿Ÿå…³é—­èµ„æºï¼ˆæ¯”å¦‚æ¼”ç¤ºæ¨¡å¼ä¸‹ç»™ç”¨æˆ· 30 ç§’çœ‹ç»“æœï¼Œå†å…³é—­æµè§ˆå™¨ / äº‹ä»¶æ€»çº¿ï¼‰
					should_delay_close = True
					break
			# å¾ªç¯æ­£å¸¸ç»“æŸæ—¶çš„é€»è¾‘ï¼šbreakåä¸èµ°è¿™ä¸ªelse
			else:
				# æ­¥æ•°è¶…é™--å¯¼è‡´çš„---å¾ªç¯æ­£å¸¸ç»“æŸï¼ˆæœªbreakï¼‰
				agent_run_error = 'Failed to complete task in maximum steps'
				# è®°å½•æ­¥æ•°è¶…é™é”™è¯¯åˆ°å†å²
				self.history.add_item(
					AgentHistory(
						model_output=None,
						result=[ActionResult(error=agent_run_error, include_in_memory=True)],
						state=BrowserStateHistory(
							url='',
							title='',
							tabs=[],
							interacted_element=[],
							screenshot_path=None,
						),
						metadata=None,
					)
				)
				
				self.logger.info(f'âŒ {agent_run_error}')

			self.history.usage = await self.token_cost_service.get_usage_summary()

			# set the model output schema and call it on the fly
			if self.history._output_model_schema is None and self.output_model_schema is not None:
				self.history._output_model_schema = self.output_model_schema

			return self.history

		except KeyboardInterrupt:
			# Already handled by our signal handler, but catch any direct KeyboardInterrupt as well
			self.logger.debug('Got KeyboardInterrupt during execution, returning current history')
			agent_run_error = 'KeyboardInterrupt'

			self.history.usage = await self.token_cost_service.get_usage_summary()

			return self.history

		except Exception as e:
			self.logger.error(f'Agent run failed with exception: {e}', exc_info=True)
			agent_run_error = str(e)
			raise e

		finally:
			if should_delay_close and self._demo_mode_enabled and agent_run_error is None:
				await asyncio.sleep(30)
			if agent_run_error:
				await self._demo_mode_log(f'Agent stopped: {agent_run_error}', 'error', {'tag': 'run'})
			# Log token usage summary
			await self.token_cost_service.log_usage_summary()

			# Unregister signal handlers before cleanup
			signal_handler.unregister()

			if not self._force_exit_telemetry_logged:  # MODIFIED: Check the flag
				try:
					self._log_agent_event(max_steps=max_steps, agent_run_error=agent_run_error)
				except Exception as log_e:  # Catch potential errors during logging itself
					self.logger.error(f'Failed to log telemetry event: {log_e}', exc_info=True)
			else:
				# ADDED: Info message when custom telemetry for SIGINT was already logged
				self.logger.debug('Telemetry for force exit (SIGINT) was logged by custom exit callback.')

			# NOTE: CreateAgentSessionEvent and CreateAgentTaskEvent are now emitted at the START of run()
			# to match backend requirements for CREATE events to be fired when entities are created,
			# not when they are completed

			# Emit UpdateAgentTaskEvent at the END of run() with final task state
			self.eventbus.dispatch(UpdateAgentTaskEvent.from_agent(self))

			# Generate GIF if needed before stopping event bus
			if self.settings.generate_gif:
				output_path: str = 'agent_history.gif'
				if isinstance(self.settings.generate_gif, str):
					output_path = self.settings.generate_gif

				# Lazy import gif module to avoid heavy startup cost
				from browser_use.agent.gif import create_history_gif

				create_history_gif(task=self.task, history=self.history, output_path=output_path)

				# Only emit output file event if GIF was actually created
				if Path(output_path).exists():
					output_event = await CreateAgentOutputFileEvent.from_agent_and_file(self, output_path)
					self.eventbus.dispatch(output_event)

			# Log final messages to user based on outcome
			self._log_final_outcome_messages()

			# Stop the event bus gracefully, waiting for all events to be processed
			# Use longer timeout to avoid deadlocks in tests with multiple agents
			await self.eventbus.stop(timeout=3.0)

			await self.close()

	@observe_debug(ignore_input=True, ignore_output=True)
	@time_execution_async('--multi_act')
	async def multi_act(self, actions: list[ActionModel]) -> list[ActionResult]:
		"""
		æ‰§è¡Œå¤šä¸ªåŠ¨ä½œ

		- æŒ‰é¡ºåºæ‰§è¡ŒåŠ¨ä½œåˆ—è¡¨ï¼Œå¤„ç†åŠ¨ä½œé—´å»¶è¿Ÿã€done åŠ¨ä½œç‰¹æ®Šè§„åˆ™ã€æš‚åœ / åœæ­¢ä¿¡å·ï¼Œè®°å½•æ‰§è¡Œæ—¥å¿—å’Œè€—æ—¶ï¼Œé‡åˆ° done / é”™è¯¯ / æœ€åä¸€ä¸ªåŠ¨ä½œæ—¶ç»ˆæ­¢æ‰§è¡Œï¼Œæœ€ç»ˆè¿”å›æ‰€æœ‰å·²æ‰§è¡ŒåŠ¨ä½œçš„ç»“æœåˆ—è¡¨
		
		æŒ‰é¡ºåºæ‰§è¡ŒåŠ¨ä½œåˆ—è¡¨ï¼Œæ”¯æŒï¼š
		1. åŠ¨ä½œä¹‹é—´çš„å»¶è¿Ÿï¼ˆwait_between_actionsï¼‰
		2. åœ¨é‡åˆ° done åŠ¨ä½œæ—¶åœæ­¢
		3. åœ¨é‡åˆ°é”™è¯¯æ—¶åœæ­¢
		4. æš‚åœ/åœæ­¢æ£€æŸ¥
		
		Args:
		    actions: è¦æ‰§è¡Œçš„åŠ¨ä½œåˆ—è¡¨
			
		Returns:
		    list[ActionResult]: æ¯ä¸ªåŠ¨ä½œçš„æ‰§è¡Œç»“æœåˆ—è¡¨
		"""
		results: list[ActionResult] = []
		time_elapsed = 0
		total_actions = len(actions)
		# æ ¡éªŒæµè§ˆå™¨ä¼šè¯æ˜¯å¦å­˜åœ¨ï¼ˆå‰ç½®ä¿éšœï¼‰
		assert self.browser_session is not None, 'BrowserSession is not set up'
		# é¢„å¤„ç†æµè§ˆå™¨ç¼“å­˜çš„DOMé€‰æ‹©å™¨æ˜ å°„ï¼ˆç”¨äºå¿«é€Ÿå®šä½é¡µé¢å…ƒç´ ï¼Œæå‡åŠ¨ä½œæ‰§è¡Œæ•ˆç‡ï¼‰ï¼šåŠ è½½ç¼“å­˜çš„ DOM é€‰æ‹©å™¨æ˜ å°„ï¼ˆé¡µé¢å…ƒç´ çš„å“ˆå¸Œ / é€‰æ‹©å™¨å¯¹åº”å…³ç³»ï¼‰ï¼Œå‡å°‘åŠ¨ä½œæ‰§è¡Œæ—¶é‡æ–°æŸ¥è¯¢ DOM çš„è€—æ—¶ï¼Œæå‡æ‰§è¡Œæ•ˆç‡ï¼›
		try:
			if (
				self.browser_session._cached_browser_state_summary is not None
				and self.browser_session._cached_browser_state_summary.dom_state is not None
			):
				# 1. æ·±æ‹·è´ç¼“å­˜ä¸­çš„é€‰æ‹©å™¨æ˜ å°„ï¼ˆå“ˆå¸Œ->é€‰æ‹©å™¨ï¼‰ï¼Œé¿å…ä¿®æ”¹åŸç¼“å­˜
				cached_selector_map = dict(self.browser_session._cached_browser_state_summary.dom_state.selector_map)
				# 2. æå–æ‰€æœ‰ç¼“å­˜å…ƒç´ çš„çˆ¶åˆ†æ”¯å“ˆå¸Œï¼Œå­˜å…¥é›†åˆï¼ˆæ–¹ä¾¿å¿«é€Ÿåˆ¤æ–­å…ƒç´ æ˜¯å¦å·²ç¼“å­˜ï¼‰
				cached_element_hashes = {e.parent_branch_hash() for e in cached_selector_map.values()}
			else:
				# ç¼“å­˜ä¸å­˜åœ¨æ—¶ï¼Œåˆå§‹åŒ–ç©ºå­—å…¸å’Œç©ºé›†åˆ
				cached_selector_map = {}
				cached_element_hashes = set()
		except Exception as e:
			# å¼‚å¸¸æ•è·å…œåº•ï¼šå³ä½¿ç¼“å­˜è¯»å–å¤±è´¥ï¼Œä¹Ÿä¸ä¸­æ–­åŠ¨ä½œæ‰§è¡Œï¼Œä»…åˆå§‹åŒ–ç©ºç¼“å­˜ã€‚
			self.logger.error(f'Error getting cached selector map: {e}')
			cached_selector_map = {}
			cached_element_hashes = set()
		# éå†æ‰§è¡Œæ¯ä¸ªåŠ¨ä½œï¼ˆæ ¸å¿ƒå¾ªç¯ï¼‰ï¼šæŒ‰é¡ºåºæ‰§è¡Œä¸€ç³»åˆ—æµè§ˆå™¨è‡ªåŠ¨åŒ–åŠ¨ä½œï¼ˆå¦‚ click/type/done ç­‰ï¼‰ï¼Œå¹¶åŒ…å«äº† 4 æ¡æ ¸å¿ƒæ‰§è¡Œè§„åˆ™ã€å¼‚å¸¸å¤„ç†ã€æ—¥å¿—è®°å½•å’Œè€—æ—¶ç»Ÿè®¡ç­‰å®Œå–„çš„å·¥ç¨‹åŒ–é€»è¾‘
		for i, action in enumerate(actions):
			""" ä¸»è¦é€»è¾‘ï¼š
			1. éå†ä¸€ä¸ªåŠ¨ä½œåˆ—è¡¨ï¼ˆactionsï¼‰ï¼ŒæŒ‰é¡ºåºå¼‚æ­¥æ‰§è¡Œæ¯ä¸ªåŠ¨ä½œï¼›
			2. å†…ç½® 4 æ¡æ‰§è¡Œè§„åˆ™ï¼ˆdone åŠ¨ä½œé™åˆ¶ã€åŠ¨ä½œé—´å»¶è¿Ÿã€æš‚åœ / åœæ­¢æ£€æŸ¥ã€ç»ˆæ­¢æ¡ä»¶ï¼‰ï¼›
			3. è®°å½•æ¯ä¸ªåŠ¨ä½œçš„æ‰§è¡Œæ—¥å¿—ã€è€—æ—¶ã€ç»“æœï¼ˆæˆåŠŸ / å¤±è´¥ / å®Œæˆï¼‰ï¼›
			4. æ•è·æ‰§è¡Œå¼‚å¸¸å¹¶å‹å¥½å¤„ç†ï¼Œæœ€ç»ˆè¿”å›æ‰€æœ‰åŠ¨ä½œçš„æ‰§è¡Œç»“æœã€‚
			"""
			# è§„åˆ™1ï¼šdoneåŠ¨ä½œä»…å…è®¸ä½œä¸ºå•ä¸ªåŠ¨ä½œæ‰§è¡Œï¼ˆè‹¥doneå‡ºç°åœ¨éç¬¬ä¸€ä¸ªä½ç½®ï¼Œç›´æ¥ç»ˆæ­¢å¾ªç¯ï¼‰
			if i > 0:
				# é™åˆ¶doneåŠ¨ä½œåªèƒ½å•ç‹¬æ‰§è¡Œï¼ˆæ¯”å¦‚æ•´ä¸ªåŠ¨ä½œåˆ—è¡¨åªèƒ½æ˜¯[done]ï¼Œä¸èƒ½æ˜¯[click, done]ï¼‰ï¼Œé¿å…é€»è¾‘æ··ä¹±
				if action.model_dump(exclude_unset=True).get('done') is not None:
					msg = f'Done action is allowed only as a single action - stopped after action {i} / {total_actions}.'
					self.logger.debug(msg)
					break

			# è§„åˆ™2ï¼šéç¬¬ä¸€ä¸ªåŠ¨ä½œï¼Œæ‰§è¡ŒåŠ¨ä½œé—´å»¶è¿Ÿï¼ˆé¿å…æ“ä½œè¿‡å¿«å¯¼è‡´é¡µé¢æœªåŠ è½½ï¼‰
			if i > 0:
				# ç¬¬ 2 ä¸ªåŠä»¥åçš„åŠ¨ä½œæ‰§è¡Œå‰ï¼Œå…ˆç­‰å¾…æŒ‡å®šæ—¶é•¿
				self.logger.debug(f'Waiting {self.browser_profile.wait_between_actions} seconds between actions')
				# wait_between_actionsï¼Œæ¯”å¦‚ 1 ç§’ã€‚é¿å…æ“ä½œè¿‡å¿«å¯¼è‡´é¡µé¢å…ƒç´ æœªåŠ è½½å®Œæˆï¼Œå‡å°‘å…ƒç´ å®šä½å¤±è´¥çš„æ¦‚ç‡
				await asyncio.sleep(self.browser_profile.wait_between_actions)

			try:
				# è§„åˆ™3ï¼šæ‰§è¡Œå‰æ£€æŸ¥æš‚åœ/åœæ­¢ä¿¡å·ï¼ˆå“åº”å¤–éƒ¨æ§åˆ¶ï¼‰
				await self._check_stop_or_pause()
				# è§£æåŠ¨ä½œåç§°ï¼ˆå¦‚click/type/doneï¼‰
				# action_dataï¼šåŠ¨ä½œå¯¹è±¡è½¬ä¸ºçš„å­—å…¸ï¼ˆæ¯”å¦‚{'click': {'selector': '#login'}}ï¼‰ï¼›
				action_data = action.model_dump(exclude_unset=True)
				# å–å­—å…¸ç¬¬ä¸€ä¸ªé”®ä½œä¸ºåŠ¨ä½œåç§°ï¼ˆæ¯”å¦‚clickï¼‰
				action_name = next(iter(action_data.keys())) if action_data else 'unknown'

				# è®°å½•åŠ¨ä½œæ‰§è¡Œå‰æ—¥å¿—ï¼ˆä¾¿äºè°ƒè¯•ï¼‰
				await self._log_action(action, action_name, i + 1, total_actions)
				# ç»Ÿè®¡åŠ¨ä½œæ‰§è¡Œè€—æ—¶
				time_start = time.time()

				# æ ¸å¿ƒï¼šè°ƒç”¨å·¥å…·æ‰§è¡Œå•ä¸ªåŠ¨ä½œ
				result = await self.tools.act(
					action=action,  # å½“å‰è¦æ‰§è¡Œçš„åŠ¨ä½œå¯¹è±¡
					browser_session=self.browser_session,  # æµè§ˆå™¨ä¼šè¯ï¼ˆåŒ…å«ç¼“å­˜ã€é¡µé¢ç­‰ï¼‰
					# å…¶ä»–å‚æ•°ï¼šæ–‡ä»¶ç³»ç»Ÿã€LLM é…ç½®ã€æ•æ„Ÿæ•°æ®ã€å¯ç”¨æ–‡ä»¶è·¯å¾„ç­‰ï¼Œé€‚é…å¤æ‚ä¸šåŠ¡åœºæ™¯ï¼›
					file_system=self.file_system,
					page_extraction_llm=self.settings.page_extraction_llm,
					sensitive_data=self.sensitive_data,
					available_file_paths=self.available_file_paths,
				)
				# è¿”å›å€¼resultï¼šåŠ¨ä½œæ‰§è¡Œç»“æœå¯¹è±¡ï¼ŒåŒ…å«errorï¼ˆé”™è¯¯ä¿¡æ¯ï¼‰ã€is_doneï¼ˆæ˜¯å¦å®Œæˆï¼‰ã€successï¼ˆæ˜¯å¦æˆåŠŸï¼‰ç­‰å±æ€§

				time_end = time.time()
				time_elapsed = time_end - time_start
				# åŠ¨ä½œæ‰§è¡Œç»“æœå¤„ç†ï¼šé”™è¯¯/å®Œæˆæ—¥å¿—
				if result.error:
					# è®°å½•é”™è¯¯æ—¥å¿—ï¼ˆæ¯”å¦‚ â€œåŠ¨ä½œ click å¤±è´¥ï¼šå…ƒç´ æœªæ‰¾åˆ°â€ï¼‰ï¼›
					await self._demo_mode_log(
						f'Action "{action_name}" failed: {result.error}',
						'error',
						{'action': action_name, 'step': self.state.n_steps},
					)
				# è®°å½•å®Œæˆæ—¥å¿—ï¼ˆæˆåŠŸ / è­¦å‘Šçº§åˆ«ï¼‰ï¼›
				elif result.is_done:
					completion_text = result.long_term_memory or result.extracted_content or 'Task marked as done.'
					level = 'success' if result.success is not False else 'warning'
					await self._demo_mode_log(
						completion_text,
						level,
						{'action': action_name, 'step': self.state.n_steps},
					)
				# ä¿å­˜å½“å‰åŠ¨ä½œç»“æœ
				results.append(result)
				# è§„åˆ™4ï¼šé‡åˆ°done/é”™è¯¯/æœ€åä¸€ä¸ªåŠ¨ä½œï¼Œç»ˆæ­¢å¾ªç¯
				if results[-1].is_done or results[-1].error or i == total_actions - 1:
					break

			except Exception as e:
				# æ•è·åŠ¨ä½œæ‰§è¡Œä¸­çš„æ‰€æœ‰å¼‚å¸¸ï¼Œè®°å½•æ—¥å¿—å¹¶é‡æ–°æŠ›å‡º
				self.logger.error(f'âŒ Executing action {i + 1} failed -> {type(e).__name__}: {e}')
				await self._demo_mode_log(
					f'Action "{action_name}" raised {type(e).__name__}: {e}',
					'error',
					{'action': action_name, 'step': self.state.n_steps},
				)
				raise e

		return results

	async def _log_action(self, action, action_name: str, action_num: int, total_actions: int) -> None:
		"""åœ¨æ‰§è¡Œå‰è®°å½•åŠ¨ä½œï¼ˆå¸¦å½©è‰²æ ¼å¼åŒ–ï¼‰"""
		# é¢œè‰²å®šä¹‰
		blue = '\033[34m'  # åŠ¨ä½œåç§°
		magenta = '\033[35m'  # å‚æ•°åç§°
		reset = '\033[0m'

		# Format action number and name
		if total_actions > 1:
			action_header = f'â–¶ï¸  [{action_num}/{total_actions}] {blue}{action_name}{reset}:'
			plain_header = f'â–¶ï¸  [{action_num}/{total_actions}] {action_name}:'
		else:
			action_header = f'â–¶ï¸   {blue}{action_name}{reset}:'
			plain_header = f'â–¶ï¸  {action_name}:'

		# Get action parameters
		action_data = action.model_dump(exclude_unset=True)
		params = action_data.get(action_name, {})

		# Build parameter parts with colored formatting
		param_parts = []
		plain_param_parts = []

		if params and isinstance(params, dict):
			for param_name, value in params.items():
				# Truncate long values for readability
				if isinstance(value, str) and len(value) > 150:
					display_value = value[:150] + '...'
				elif isinstance(value, list) and len(str(value)) > 200:
					display_value = str(value)[:200] + '...'
				else:
					display_value = value

				param_parts.append(f'{magenta}{param_name}{reset}: {display_value}')
				plain_param_parts.append(f'{param_name}: {display_value}')

		# Join all parts
		if param_parts:
			params_string = ', '.join(param_parts)
			self.logger.info(f'  {action_header} {params_string}')
		else:
			self.logger.info(f'  {action_header}')

		if self._demo_mode_enabled:
			panel_message = plain_header
			if plain_param_parts:
				panel_message = f'{panel_message} {", ".join(plain_param_parts)}'
			await self._demo_mode_log(panel_message.strip(), 'action', {'action': action_name, 'step': self.state.n_steps})

	async def log_completion(self) -> None:
		"""è®°å½•ä»»åŠ¡å®ŒæˆçŠ¶æ€"""
		# self._task_end_time = time.time()
		# self._task_duration = self._task_end_time - self._task_start_time TODO: ä½¿ç”¨ take_step æ—¶ä¸å·¥ä½œ
		if self.history.is_successful():
			self.logger.info('âœ… Task completed successfully')
			await self._demo_mode_log('Task completed successfully', 'success', {'tag': 'task'})

	async def _generate_rerun_summary(
		self, original_task: str, results: list[ActionResult], summary_llm: BaseChatModel | None = None
	) -> ActionResult:
		"""ä½¿ç”¨æˆªå›¾å’Œæœ€åæ­¥éª¤ä¿¡æ¯ç”Ÿæˆé‡æ–°è¿è¡Œå®Œæˆçš„ AI æ‘˜è¦"""
		from browser_use.agent.views import RerunSummaryAction

		# Get current screenshot
		screenshot_b64 = None
		try:
			screenshot = await self.browser_session.take_screenshot(full_page=False)
			if screenshot:
				import base64

				screenshot_b64 = base64.b64encode(screenshot).decode('utf-8')
		except Exception as e:
			self.logger.warning(f'Failed to capture screenshot for rerun summary: {e}')

		# Build summary prompt and message
		error_count = sum(1 for r in results if r.error)
		success_count = len(results) - error_count

		from browser_use.agent.prompts import get_rerun_summary_message, get_rerun_summary_prompt

		prompt = get_rerun_summary_prompt(
			original_task=original_task,
			total_steps=len(results),
			success_count=success_count,
			error_count=error_count,
		)

		# Use provided LLM, agent's LLM, or fall back to OpenAI with structured output
		try:
			# Determine which LLM to use
			if summary_llm is None:
				# Try to use the agent's LLM first
				summary_llm = self.llm
				self.logger.debug('Using agent LLM for rerun summary')
			else:
				self.logger.debug(f'Using provided LLM for rerun summary: {summary_llm.model}')

			# Build message with prompt and optional screenshot
			from browser_use.llm.messages import BaseMessage

			message = get_rerun_summary_message(prompt, screenshot_b64)
			messages: list[BaseMessage] = [message]  # type: ignore[list-item]

			# Try calling with structured output first
			self.logger.debug(f'Calling LLM for rerun summary with {len(messages)} message(s)')
			try:
				kwargs: dict = {'output_format': RerunSummaryAction}
				response = await summary_llm.ainvoke(messages, **kwargs)
				summary: RerunSummaryAction = response.completion  # type: ignore[assignment]
				self.logger.debug(f'LLM response type: {type(summary)}')
				self.logger.debug(f'LLM response: {summary}')
			except Exception as structured_error:
				# If structured output fails (e.g., Browser-Use LLM doesn't support it for this type),
				# fall back to text response without parsing
				self.logger.debug(f'Structured output failed: {structured_error}, falling back to text response')

				response = await summary_llm.ainvoke(messages, None)
				response_text = response.completion
				self.logger.debug(f'LLM text response: {response_text}')

				# Use the text response directly as the summary
				summary = RerunSummaryAction(
					summary=response_text if isinstance(response_text, str) else str(response_text),
					success=error_count == 0,
					completion_status='complete' if error_count == 0 else ('partial' if success_count > 0 else 'failed'),
				)

			self.logger.info(f'ğŸ“Š Rerun Summary: {summary.summary}')
			self.logger.info(f'ğŸ“Š Status: {summary.completion_status} (success={summary.success})')

			return ActionResult(
				is_done=True,
				success=summary.success,
				extracted_content=summary.summary,
				long_term_memory=f'Rerun completed with status: {summary.completion_status}. {summary.summary[:100]}',
			)

		except Exception as e:
			self.logger.warning(f'Failed to generate AI summary: {e.__class__.__name__}: {e}')
			self.logger.debug('Full error traceback:', exc_info=True)
			# Fallback to simple summary
			return ActionResult(
				is_done=True,
				success=error_count == 0,
				extracted_content=f'Rerun completed: {success_count}/{len(results)} steps succeeded',
				long_term_memory=f'Rerun completed: {success_count} steps succeeded, {error_count} errors',
			)

	async def _execute_ai_step(
		self,
		query: str,
		include_screenshot: bool = False,
		extract_links: bool = False,
		ai_step_llm: BaseChatModel | None = None,
	) -> ActionResult:
		"""
		åœ¨é‡æ–°è¿è¡ŒæœŸé—´æ‰§è¡Œ AI æ­¥éª¤ä»¥é‡æ–°è¯„ä¼°æå–åŠ¨ä½œ
		åˆ†æå®Œæ•´çš„é¡µé¢ DOM/markdown + å¯é€‰çš„æˆªå›¾

		Args:
			query: è¦ä»å½“å‰é¡µé¢åˆ†ææˆ–æå–çš„å†…å®¹
			include_screenshot: æ˜¯å¦åœ¨åˆ†æä¸­åŒ…å«æˆªå›¾
			extract_links: æ˜¯å¦åœ¨ markdown æå–ä¸­åŒ…å«é“¾æ¥
			ai_step_llm: å¯é€‰çš„ LLMã€‚å¦‚æœæœªæä¾›ï¼Œä½¿ç”¨ä»£ç†çš„ LLM

		Returns:
			ActionResult åŒ…å«æå–çš„å†…å®¹
		"""
		from browser_use.agent.prompts import get_ai_step_system_prompt, get_ai_step_user_prompt, get_rerun_summary_message
		from browser_use.llm.messages import SystemMessage, UserMessage
		from browser_use.utils import sanitize_surrogates

		# Use provided LLM or agent's LLM
		llm = ai_step_llm or self.llm
		self.logger.debug(f'Using LLM for AI step: {llm.model}')

		# Extract clean markdown
		try:
			from browser_use.dom.markdown_extractor import extract_clean_markdown

			content, content_stats = await extract_clean_markdown(
				browser_session=self.browser_session, extract_links=extract_links
			)
		except Exception as e:
			return ActionResult(error=f'Could not extract clean markdown: {type(e).__name__}: {e}')

		# Get screenshot if requested
		screenshot_b64 = None
		if include_screenshot:
			try:
				screenshot = await self.browser_session.take_screenshot(full_page=False)
				if screenshot:
					import base64

					screenshot_b64 = base64.b64encode(screenshot).decode('utf-8')
			except Exception as e:
				self.logger.warning(f'Failed to capture screenshot for ai_step: {e}')

		# Build prompt with content stats
		original_html_length = content_stats['original_html_chars']
		initial_markdown_length = content_stats['initial_markdown_chars']
		final_filtered_length = content_stats['final_filtered_chars']
		chars_filtered = content_stats['filtered_chars_removed']

		stats_summary = f"""Content processed: {original_html_length:,} HTML chars â†’ {initial_markdown_length:,} initial markdown â†’ {final_filtered_length:,} filtered markdown"""
		if chars_filtered > 0:
			stats_summary += f' (filtered {chars_filtered:,} chars of noise)'

		# Sanitize content
		content = sanitize_surrogates(content)
		query = sanitize_surrogates(query)

		# Get prompts from prompts.py
		system_prompt = get_ai_step_system_prompt()
		prompt_text = get_ai_step_user_prompt(query, stats_summary, content)

		# Build user message with optional screenshot
		if screenshot_b64:
			user_message = get_rerun_summary_message(prompt_text, screenshot_b64)
		else:
			user_message = UserMessage(content=prompt_text)

		try:
			import asyncio

			response = await asyncio.wait_for(llm.ainvoke([SystemMessage(content=system_prompt), user_message]), timeout=120.0)

			current_url = await self.browser_session.get_current_page_url()
			extracted_content = (
				f'<url>\n{current_url}\n</url>\n<query>\n{query}\n</query>\n<result>\n{response.completion}\n</result>'
			)

			# Simple memory handling
			MAX_MEMORY_LENGTH = 1000
			if len(extracted_content) < MAX_MEMORY_LENGTH:
				memory = extracted_content
				include_extracted_content_only_once = False
			else:
				file_name = await self.file_system.save_extracted_content(extracted_content)
				memory = f'Query: {query}\nContent in {file_name} and once in <read_state>.'
				include_extracted_content_only_once = True

			self.logger.info(f'ğŸ¤– AI Step: {memory}')
			return ActionResult(
				extracted_content=extracted_content,
				include_extracted_content_only_once=include_extracted_content_only_once,
				long_term_memory=memory,
			)
		except Exception as e:
			self.logger.warning(f'Failed to execute AI step: {e.__class__.__name__}: {e}')
			self.logger.debug('Full error traceback:', exc_info=True)
			return ActionResult(error=f'AI step failed: {e}')

	async def rerun_history(
		self,
		history: AgentHistoryList,
		max_retries: int = 3,
		skip_failures: bool = False,
		delay_between_actions: float = 2.0,
		max_step_interval: float = 45.0,
		summary_llm: BaseChatModel | None = None,
		ai_step_llm: BaseChatModel | None = None,
		wait_for_elements: bool = False,
	) -> list[ActionResult]:
		"""
		é‡æ–°è¿è¡Œä¿å­˜çš„åŠ¨ä½œå†å²ï¼Œå¸¦æœ‰é”™è¯¯å¤„ç†å’Œé‡è¯•é€»è¾‘

		Args:
		                history: è¦é‡æ”¾çš„å†å²è®°å½•
		                max_retries: æ¯ä¸ªåŠ¨ä½œçš„æœ€å¤§é‡è¯•æ¬¡æ•°
		                skip_failures: æ˜¯å¦è·³è¿‡å¤±è´¥çš„åŠ¨ä½œæˆ–åœæ­¢æ‰§è¡Œã€‚å½“ä¸º True æ—¶ï¼Œä¹Ÿä¼šè·³è¿‡
		                               åŸå§‹è¿è¡Œä¸­æœ‰é”™è¯¯çš„æ­¥éª¤ï¼ˆä¾‹å¦‚è‡ªåŠ¨å…³é—­çš„æ¨¡æ€æ¡†å…³é—­æŒ‰é’®ï¼Œ
		                               æˆ–å˜å¾—ä¸å¯äº¤äº’çš„å…ƒç´ ï¼‰
		                delay_between_actions: åŠ¨ä½œä¹‹é—´çš„å»¶è¿Ÿï¼ˆç§’ï¼‰ï¼ˆå½“æ²¡æœ‰ä¿å­˜çš„é—´éš”æ—¶ä½¿ç”¨ï¼‰
		                max_step_interval: ä¿å­˜çš„ step_interval çš„æœ€å¤§å»¶è¿Ÿï¼ˆé™åˆ¶åŸå§‹è¿è¡Œçš„ LLM æ—¶é—´ï¼‰
		                summary_llm: å¯é€‰çš„ LLMï¼Œç”¨äºç”Ÿæˆæœ€ç»ˆæ‘˜è¦ã€‚å¦‚æœæœªæä¾›ï¼Œä½¿ç”¨ä»£ç†çš„ LLM
		                ai_step_llm: å¯é€‰çš„ LLMï¼Œç”¨äº AI æ­¥éª¤ï¼ˆæå–åŠ¨ä½œï¼‰ã€‚å¦‚æœæœªæä¾›ï¼Œä½¿ç”¨ä»£ç†çš„ LLM
		                wait_for_elements: å¦‚æœä¸º Trueï¼Œåœ¨å°è¯•å…ƒç´ åŒ¹é…ä¹‹å‰ç­‰å¾…æœ€å°æ•°é‡çš„å…ƒç´ ã€‚
		                               å¯¹äº shadow DOM å†…å®¹åŠ¨æ€åŠ è½½çš„ SPA é¡µé¢å¾ˆæœ‰ç”¨ã€‚
		                               é»˜è®¤ä¸º Falseã€‚

		Returns:
		                åŠ¨ä½œç»“æœåˆ—è¡¨ï¼ˆåŒ…æ‹¬ AI æ‘˜è¦ä½œä¸ºæœ€ç»ˆç»“æœï¼‰
		"""
		# Skip cloud sync session events for rerunning (we're replaying, not starting new)
		self.state.session_initialized = True

		# Initialize browser session
		await self.browser_session.start()

		results = []

		# Track previous step for redundant retry detection
		previous_item: AgentHistory | None = None
		previous_step_succeeded: bool = False

		try:
			for i, history_item in enumerate(history.history):
				goal = history_item.model_output.current_state.next_goal if history_item.model_output else ''
				step_num = history_item.metadata.step_number if history_item.metadata else i
				step_name = 'Initial actions' if step_num == 0 else f'Step {step_num}'

				# Determine step delay
				if history_item.metadata and history_item.metadata.step_interval is not None:
					# Cap the saved interval to max_step_interval (saved interval includes LLM time)
					step_delay = min(history_item.metadata.step_interval, max_step_interval)
					# Format delay nicely - show ms for values < 1s, otherwise show seconds
					if step_delay < 1.0:
						delay_str = f'{step_delay * 1000:.0f}ms'
					else:
						delay_str = f'{step_delay:.1f}s'
					if history_item.metadata.step_interval > max_step_interval:
						delay_source = f'capped to {delay_str} (saved was {history_item.metadata.step_interval:.1f}s)'
					else:
						delay_source = f'using saved step_interval={delay_str}'
				else:
					step_delay = delay_between_actions
					if step_delay < 1.0:
						delay_str = f'{step_delay * 1000:.0f}ms'
					else:
						delay_str = f'{step_delay:.1f}s'
					delay_source = f'using default delay={delay_str}'

				self.logger.info(f'Replaying {step_name} ({i + 1}/{len(history.history)}) [{delay_source}]: {goal}')

				if (
					not history_item.model_output
					or not history_item.model_output.action
					or history_item.model_output.action == [None]
				):
					self.logger.warning(f'{step_name}: No action to replay, skipping')
					results.append(ActionResult(error='No action to replay'))
					continue

				# Check if the original step had errors - skip if skip_failures is enabled
				original_had_error = any(r.error for r in history_item.result if r.error)
				if original_had_error and skip_failures:
					error_msgs = [r.error for r in history_item.result if r.error]
					self.logger.warning(
						f'{step_name}: Original step had error(s), skipping (skip_failures=True): {error_msgs[0][:100] if error_msgs else "unknown"}'
					)
					results.append(
						ActionResult(
							error=f'Skipped - original step had error: {error_msgs[0][:100] if error_msgs else "unknown"}'
						)
					)
					continue

				# Check if this step is a redundant retry of the previous step
				# This handles cases where original run needed to click same element multiple times
				# due to slow page response, but during replay the first click already worked
				if self._is_redundant_retry_step(history_item, previous_item, previous_step_succeeded):
					self.logger.info(f'{step_name}: Skipping redundant retry (previous step already succeeded with same element)')
					results.append(
						ActionResult(
							extracted_content='Skipped - redundant retry of previous step',
							include_in_memory=False,
						)
					)
					# Don't update previous_item/previous_step_succeeded - keep tracking the original step
					continue

				retry_count = 0
				step_succeeded = False
				# Exponential backoff: 5s base, doubling each retry, capped at 30s
				base_retry_delay = 5.0
				max_retry_delay = 30.0
				while retry_count < max_retries:
					try:
						result = await self._execute_history_step(history_item, step_delay, ai_step_llm, wait_for_elements)
						results.extend(result)
						step_succeeded = True
						break

					except Exception as e:
						retry_count += 1
						if retry_count == max_retries:
							error_msg = f'{step_name} failed after {max_retries} attempts: {str(e)}'
							self.logger.error(error_msg)
							# Always record the error in results so AI summary counts it correctly
							results.append(ActionResult(error=error_msg))
							if not skip_failures:
								raise RuntimeError(error_msg)
							# With skip_failures=True, continue to next step
						else:
							# Exponential backoff: 5s, 10s, 20s, ... capped at 30s
							retry_delay = min(base_retry_delay * (2 ** (retry_count - 1)), max_retry_delay)
							self.logger.warning(
								f'{step_name} failed (attempt {retry_count}/{max_retries}), retrying in {retry_delay}s...'
							)
							await asyncio.sleep(retry_delay)

				# Update tracking for redundant retry detection
				previous_item = history_item
				previous_step_succeeded = step_succeeded

			# Generate AI summary of rerun completion
			self.logger.info('ğŸ¤– Generating AI summary of rerun completion...')
			summary_result = await self._generate_rerun_summary(self.task, results, summary_llm)
			results.append(summary_result)

			return results
		finally:
			# Always close resources, even on failure
			await self.close()

	async def _execute_initial_actions(self) -> None:
		"""æ‰§è¡Œåˆå§‹åŠ¨ä½œï¼ˆå¦‚æœæä¾›ï¼‰
		
		self.initial_actionsï¼šé¢„è®¾çš„åˆå§‹åŠ¨ä½œåˆ—è¡¨ï¼ˆå¦‚ [{"action": "navigate", "url": "https://xxx.com"}]ï¼‰ï¼Œéç©ºæ—¶æ‰æ‰§è¡Œï¼›
		
		"""
		if self.initial_actions and not self.state.follow_up_task:
			self.logger.debug(f'âš¡ Executing {len(self.initial_actions)} initial actions...')
			result = await self.multi_act(self.initial_actions)
			# æ›´æ–°ç»“æœ 1 ä»¥æåŠå®ƒæ˜¯è‡ªåŠ¨åŠ è½½çš„
			if result and self.initial_url and result[0].long_term_memory:
				result[0].long_term_memory = f'Found initial url and automatically loaded it. {result[0].long_term_memory}'
			self.state.last_result = result

			# Save initial actions to history as step 0 for rerun capability
			# Skip browser state capture for initial actions (usually just URL navigation)
			if self.settings.flash_mode:
				model_output = self.AgentOutput(
					evaluation_previous_goal=None,
					memory='Initial navigation',
					next_goal=None,
					action=self.initial_actions,
				)
			else:
				model_output = self.AgentOutput(
					evaluation_previous_goal='Start',
					memory=None,
					next_goal='Initial navigation',
					action=self.initial_actions,
				)

			metadata = StepMetadata(step_number=0, step_start_time=time.time(), step_end_time=time.time(), step_interval=None)

			# Create minimal browser state history for initial actions
			state_history = BrowserStateHistory(
				url=self.initial_url or '',
				title='Initial Actions',
				tabs=[],
				interacted_element=[None] * len(self.initial_actions),  # No DOM elements needed
				screenshot_path=None,
			)

			history_item = AgentHistory(
				model_output=model_output,
				result=result,
				state=state_history,
				metadata=metadata,
			)

			self.history.add_item(history_item)
			self.logger.debug('ğŸ“ Saved initial actions to history as step 0')
			self.logger.debug('Initial actions completed')

	async def _wait_for_minimum_elements(
		self,
		min_elements: int,
		timeout: float = 30.0,
		poll_interval: float = 1.0,
	) -> BrowserStateSummary | None:
		"""ç­‰å¾…é¡µé¢è‡³å°‘æœ‰ min_elements ä¸ªäº¤äº’å…ƒç´ 

		è¿™æœ‰åŠ©äºå¤„ç† SPA é¡µé¢ï¼Œå…¶ä¸­ shadow DOM å’ŒåŠ¨æ€å†…å®¹
		å³ä½¿åœ¨ document.readyState ä¸º 'complete' æ—¶ä¹Ÿå¯èƒ½ç«‹å³å¯ç”¨

		Args:
			min_elements: è¦ç­‰å¾…çš„æœ€å°äº¤äº’å…ƒç´ æ•°é‡
			timeout: æœ€å¤§ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰
			poll_interval: è½®è¯¢å°è¯•ä¹‹é—´çš„æ—¶é—´ï¼ˆç§’ï¼‰

		Returns:
			å¦‚æœæ‰¾åˆ°æœ€å°å…ƒç´ åˆ™è¿”å› BrowserStateSummaryï¼Œè¶…æ—¶åˆ™è¿”å› None
		"""
		assert self.browser_session is not None, 'BrowserSession is not set up'

		start_time = time.time()
		last_count = 0

		while (time.time() - start_time) < timeout:
			state = await self.browser_session.get_browser_state_summary(include_screenshot=False)
			if state and state.dom_state.selector_map:
				current_count = len(state.dom_state.selector_map)
				if current_count >= min_elements:
					self.logger.debug(f'âœ… Page has {current_count} elements (needed {min_elements}), proceeding with action')
					return state
				if current_count != last_count:
					self.logger.debug(
						f'â³ Waiting for elements: {current_count}/{min_elements} '
						f'(timeout in {timeout - (time.time() - start_time):.1f}s)'
					)
					last_count = current_count
			await asyncio.sleep(poll_interval)

		# Return last state even if we didn't reach min_elements
		self.logger.warning(f'âš ï¸ Timeout waiting for {min_elements} elements, proceeding with {last_count} elements')
		return await self.browser_session.get_browser_state_summary(include_screenshot=False)

	def _count_expected_elements_from_history(self, history_item: AgentHistory) -> int:
		"""æ ¹æ®å†å²è®°å½•ä¼°è®¡é¢„æœŸçš„æœ€å°å…ƒç´ æ•°é‡

		ä½¿ç”¨å†å²è®°å½•ä¸­çš„åŠ¨ä½œç´¢å¼•æ¥ç¡®å®šé¡µé¢åº”è¯¥å…·æœ‰çš„æœ€å°
		å…ƒç´ æ•°é‡ã€‚å¦‚æœåŠ¨ä½œé’ˆå¯¹ç´¢å¼• Nï¼Œé¡µé¢éœ€è¦åœ¨ selector_map ä¸­è‡³å°‘æœ‰ N+1 ä¸ªå…ƒç´ 
		"""
		if not history_item.model_output or not history_item.model_output.action:
			return 0

		max_index = -1  # Use -1 to indicate no index found yet
		for action in history_item.model_output.action:
			# Get the element index this action targets
			index = action.get_index()
			if index is not None:
				max_index = max(max_index, index)

		# Need at least max_index + 1 elements (indices are 0-based)
		# Cap at 50 to avoid waiting forever for very high indices
		# max_index >= 0 means we found at least one action with an index
		return min(max_index + 1, 50) if max_index >= 0 else 0

	async def _execute_history_step(
		self,
		history_item: AgentHistory,
		delay: float,
		ai_step_llm: BaseChatModel | None = None,
		wait_for_elements: bool = False,
	) -> list[ActionResult]:
		"""æ‰§è¡Œå†å²è®°å½•ä¸­çš„å•ä¸ªæ­¥éª¤ï¼Œå¸¦æœ‰å…ƒç´ éªŒè¯

		å¯¹äºæå–åŠ¨ä½œï¼Œä½¿ç”¨ AI é‡æ–°è¯„ä¼°å†…å®¹ï¼Œå› ä¸ºé¡µé¢å†…å®¹å¯èƒ½å·²æ›´æ”¹

		Args:
			history_item: è¦æ‰§è¡Œçš„å†å²æ­¥éª¤
			delay: æ‰§è¡Œæ­¥éª¤å‰çš„å»¶è¿Ÿ
			ai_step_llm: å¯é€‰çš„ LLMï¼Œç”¨äº AI æ­¥éª¤
			wait_for_elements: å¦‚æœä¸º Trueï¼Œåœ¨å…ƒç´ åŒ¹é…ä¹‹å‰ç­‰å¾…æœ€å°å…ƒç´ 
		"""
		assert self.browser_session is not None, 'BrowserSession is not set up'

		await asyncio.sleep(delay)

		# Optionally wait for minimum elements before element matching (useful for SPAs)
		if wait_for_elements:
			# Determine if we need to wait for elements (actions that interact with DOM elements)
			needs_element_matching = False
			if history_item.model_output:
				for i, action in enumerate(history_item.model_output.action):
					action_data = action.model_dump(exclude_unset=True)
					action_name = next(iter(action_data.keys()), None)
					# Actions that need element matching
					if action_name in ('click', 'input', 'hover', 'select_option', 'drag_and_drop'):
						historical_elem = (
							history_item.state.interacted_element[i] if i < len(history_item.state.interacted_element) else None
						)
						if historical_elem is not None:
							needs_element_matching = True
							break

			# If we need element matching, wait for minimum elements before proceeding
			if needs_element_matching:
				min_elements = self._count_expected_elements_from_history(history_item)
				if min_elements > 0:
					state = await self._wait_for_minimum_elements(min_elements, timeout=15.0, poll_interval=1.0)
				else:
					state = await self.browser_session.get_browser_state_summary(include_screenshot=False)
			else:
				state = await self.browser_session.get_browser_state_summary(include_screenshot=False)
		else:
			state = await self.browser_session.get_browser_state_summary(include_screenshot=False)
		if not state or not history_item.model_output:
			raise ValueError('Invalid state or model output')

		results = []
		pending_actions = []

		for i, action in enumerate(history_item.model_output.action):
			# Check if this is an extract action - use AI step instead
			action_data = action.model_dump(exclude_unset=True)
			action_name = next(iter(action_data.keys()), None)

			if action_name == 'extract':
				# Execute any pending actions first to maintain correct order
				# (e.g., if step is [click, extract], click must happen before extract)
				if pending_actions:
					batch_results = await self.multi_act(pending_actions)
					results.extend(batch_results)
					pending_actions = []

				# Now execute AI step for extract action
				extract_params = action_data['extract']
				query = extract_params.get('query', '')
				extract_links = extract_params.get('extract_links', False)

				self.logger.info(f'ğŸ¤– Using AI step for extract action: {query[:50]}...')
				ai_result = await self._execute_ai_step(
					query=query,
					include_screenshot=False,  # Match original extract behavior
					extract_links=extract_links,
					ai_step_llm=ai_step_llm,
				)
				results.append(ai_result)
			else:
				# For non-extract actions, update indices and collect for batch execution
				historical_elem = history_item.state.interacted_element[i]
				updated_action = await self._update_action_indices(
					historical_elem,
					action,
					state,
				)
				if updated_action is None:
					# Build informative error message with diagnostic info
					elem_info = self._format_element_for_error(historical_elem)
					selector_map = state.dom_state.selector_map or {}
					selector_count = len(selector_map)

					# Find elements with same node_name for diagnostics
					hist_node = historical_elem.node_name.lower() if historical_elem else ''
					similar_elements = []
					if historical_elem and historical_elem.attributes:
						hist_aria = historical_elem.attributes.get('aria-label', '')
						for idx, elem in selector_map.items():
							if elem.node_name.lower() == hist_node and elem.attributes:
								elem_aria = elem.attributes.get('aria-label', '')
								if elem_aria:
									similar_elements.append(f'{idx}:{elem_aria[:30]}')
									if len(similar_elements) >= 5:
										break

					diagnostic = ''
					if similar_elements:
						diagnostic = f'\n  Available <{hist_node.upper()}> with aria-label: {similar_elements}'
					elif hist_node:
						same_node_count = sum(1 for e in selector_map.values() if e.node_name.lower() == hist_node)
						diagnostic = (
							f'\n  Found {same_node_count} <{hist_node.upper()}> elements (none with matching identifiers)'
						)

					raise ValueError(
						f'Could not find matching element for action {i} in current page.\n'
						f'  Looking for: {elem_info}\n'
						f'  Page has {selector_count} interactive elements.{diagnostic}\n'
						f'  Tried: EXACT hash â†’ STABLE hash â†’ XPATH â†’ ATTRIBUTE matching'
					)
				pending_actions.append(updated_action)

		# Execute any remaining pending actions
		if pending_actions:
			batch_results = await self.multi_act(pending_actions)
			results.extend(batch_results)

		return results

	async def _update_action_indices(
		self,
		historical_element: DOMInteractedElement | None,
		action: ActionModel,  # æ ¹æ®ä½ çš„åŠ¨ä½œæ¨¡å‹æ­£ç¡®è¾“å…¥ç±»å‹
		browser_state_summary: BrowserStateSummary,
	) -> ActionModel | None:
		"""
		æ ¹æ®å½“å‰é¡µé¢çŠ¶æ€æ›´æ–°åŠ¨ä½œç´¢å¼•
		è¿”å›æ›´æ–°çš„åŠ¨ä½œï¼Œå¦‚æœæ‰¾ä¸åˆ°å…ƒç´ åˆ™è¿”å› None

		çº§è”åŒ¹é…ç­–ç•¥ï¼ˆæŒ‰é¡ºåºå°è¯•æ¯ä¸ªçº§åˆ«ï¼‰ï¼š
		1. EXACT: å®Œæ•´çš„ element_hash åŒ¹é…ï¼ˆåŒ…æ‹¬æ‰€æœ‰å±æ€§ + ax_nameï¼‰
		2. STABLE: è¿‡æ»¤æ‰åŠ¨æ€ CSS ç±»çš„å“ˆå¸Œï¼ˆfocusã€hoverã€animation ç­‰ï¼‰
		3. XPATH: XPath å­—ç¬¦ä¸²åŒ¹é…ï¼ˆDOM ä¸­çš„ç»“æ„ä½ç½®ï¼‰
		4. ATTRIBUTE: å”¯ä¸€å±æ€§åŒ¹é…ï¼ˆnameã€idã€aria-labelï¼‰ï¼Œç”¨äºæ—§çš„å†å²æ–‡ä»¶
		"""
		if not historical_element or not browser_state_summary.dom_state.selector_map:
			return action

		selector_map = browser_state_summary.dom_state.selector_map
		highlight_index: int | None = None
		match_level: MatchLevel | None = None

		# Debug: log what we're looking for and what's available
		self.logger.info(
			f'ğŸ” Searching for element: <{historical_element.node_name}> '
			f'hash={historical_element.element_hash} stable_hash={historical_element.stable_hash}'
		)
		# Log what elements are in selector_map for debugging
		if historical_element.node_name:
			hist_name = historical_element.node_name.lower()
			matching_nodes = [
				(idx, elem.node_name, elem.attributes.get('name') if elem.attributes else None)
				for idx, elem in selector_map.items()
				if elem.node_name.lower() == hist_name
			]
			self.logger.info(
				f'ğŸ” Selector map has {len(selector_map)} elements, '
				f'{len(matching_nodes)} are <{hist_name.upper()}>: {matching_nodes}'
			)

		# Level 1: EXACT hash match
		for idx, elem in selector_map.items():
			if elem.element_hash == historical_element.element_hash:
				highlight_index = idx
				match_level = MatchLevel.EXACT
				break

		if highlight_index is None:
			self.logger.debug(f'EXACT hash match failed (checked {len(selector_map)} elements)')

		# Level 2: STABLE hash match (dynamic classes filtered)
		# Use stored stable_hash (computed at save time from EnhancedDOMTreeNode - single source of truth)
		if highlight_index is None and historical_element.stable_hash is not None:
			for idx, elem in selector_map.items():
				if elem.compute_stable_hash() == historical_element.stable_hash:
					highlight_index = idx
					match_level = MatchLevel.STABLE
					self.logger.info('Element matched at STABLE level (dynamic classes filtered)')
					break
			if highlight_index is None:
				self.logger.debug('STABLE hash match failed')
		elif highlight_index is None:
			self.logger.debug('STABLE hash match skipped (no stable_hash in history)')

		# Level 3: XPATH match
		if highlight_index is None and historical_element.x_path:
			for idx, elem in selector_map.items():
				if elem.xpath == historical_element.x_path:
					highlight_index = idx
					match_level = MatchLevel.XPATH
					self.logger.info(f'Element matched at XPATH level: {historical_element.x_path}')
					break
			if highlight_index is None:
				self.logger.debug(f'XPATH match failed for: {historical_element.x_path[-60:]}')

		# Level 4: Unique attribute fallback (for old history files without stable_hash)
		if highlight_index is None and historical_element.attributes:
			hist_attrs = historical_element.attributes
			hist_name = historical_element.node_name.lower()

			# Try matching by unique identifiers: name, id, or aria-label
			for attr_key in ['name', 'id', 'aria-label']:
				if attr_key in hist_attrs and hist_attrs[attr_key]:
					for idx, elem in selector_map.items():
						if (
							elem.node_name.lower() == hist_name
							and elem.attributes
							and elem.attributes.get(attr_key) == hist_attrs[attr_key]
						):
							highlight_index = idx
							match_level = MatchLevel.XPATH  # Reuse XPATH level for logging
							self.logger.info(f'Element matched via {attr_key} attribute: {hist_attrs[attr_key]}')
							break
					if highlight_index is not None:
						break

			if highlight_index is None:
				tried_attrs = [k for k in ['name', 'id', 'aria-label'] if k in hist_attrs and hist_attrs[k]]
				# Log what was tried and what's available on the page for debugging
				same_node_elements = [
					(idx, elem.attributes.get('aria-label') or elem.attributes.get('id') or elem.attributes.get('name'))
					for idx, elem in selector_map.items()
					if elem.node_name.lower() == hist_name and elem.attributes
				]
				self.logger.info(
					f'ğŸ” ATTRIBUTE match failed for <{hist_name.upper()}> '
					f'(tried: {tried_attrs}, looking for: {[hist_attrs.get(k) for k in tried_attrs]}). '
					f'Page has {len(same_node_elements)} <{hist_name.upper()}> elements with identifiers: '
					f'{same_node_elements[:5]}{"..." if len(same_node_elements) > 5 else ""}'
				)

		if highlight_index is None:
			return None

		old_index = action.get_index()
		if old_index != highlight_index:
			action.set_index(highlight_index)
			level_name = match_level.name if match_level else 'UNKNOWN'
			self.logger.info(f'Element index updated {old_index} â†’ {highlight_index} (matched at {level_name} level)')

		return action

	def _format_element_for_error(self, elem: DOMInteractedElement | None) -> str:
		"""ä¸ºå†å²é‡æ–°è¿è¡ŒæœŸé—´çš„é”™è¯¯æ¶ˆæ¯æ ¼å¼åŒ–å…ƒç´ ä¿¡æ¯"""
		if elem is None:
			return '<no element recorded>'

		parts = [f'<{elem.node_name}>']

		# Add key identifying attributes
		if elem.attributes:
			for key in ['name', 'id', 'aria-label', 'type']:
				if key in elem.attributes and elem.attributes[key]:
					parts.append(f'{key}="{elem.attributes[key]}"')

		# Add hash info
		parts.append(f'hash={elem.element_hash}')
		if elem.stable_hash:
			parts.append(f'stable_hash={elem.stable_hash}')

		# Add xpath (truncated)
		if elem.x_path:
			xpath_short = elem.x_path if len(elem.x_path) <= 60 else f'...{elem.x_path[-57:]}'
			parts.append(f'xpath="{xpath_short}"')

		return ' '.join(parts)

	def _is_redundant_retry_step(
		self,
		current_item: AgentHistory,
		previous_item: AgentHistory | None,
		previous_step_succeeded: bool,
	) -> bool:
		"""
		æ£€æµ‹å½“å‰æ­¥éª¤æ˜¯å¦æ˜¯å‰ä¸€æ­¥éª¤çš„å†—ä½™é‡è¯•

		è¿™å¤„ç†äº†åŸå§‹è¿è¡Œç”±äºé¡µé¢å“åº”æ…¢è€Œéœ€è¦å¤šæ¬¡å•å‡»åŒä¸€å…ƒç´ çš„æƒ…å†µï¼Œ
		ä½†åœ¨é‡æ”¾æœŸé—´ç¬¬ä¸€æ¬¡å•å‡»å·²ç»æˆåŠŸã€‚
		å½“é¡µé¢å·²ç»å¯¼èˆªæ—¶ï¼Œå¯¹åŒä¸€å…ƒç´ çš„åç»­é‡è¯•å•å‡»å°†å¤±è´¥ï¼Œå› ä¸ºè¯¥å…ƒç´ ä¸å†å­˜åœ¨

		å¦‚æœæ»¡è¶³ä»¥ä¸‹æ¡ä»¶åˆ™è¿”å› Trueï¼š
		- å‰ä¸€æ­¥éª¤æˆåŠŸ
		- ä¸¤ä¸ªæ­¥éª¤é’ˆå¯¹åŒä¸€å…ƒç´ ï¼ˆé€šè¿‡ element_hashã€stable_hash æˆ– xpathï¼‰
		- ä¸¤ä¸ªæ­¥éª¤æ‰§è¡Œç›¸åŒçš„åŠ¨ä½œç±»å‹ï¼ˆä¾‹å¦‚ï¼Œéƒ½æ˜¯å•å‡»ï¼‰
		"""
		if not previous_item or not previous_step_succeeded:
			return False

		# Get interacted elements from both steps (first action in each)
		curr_elements = current_item.state.interacted_element
		prev_elements = previous_item.state.interacted_element

		if not curr_elements or not prev_elements:
			return False

		curr_elem = curr_elements[0] if curr_elements else None
		prev_elem = prev_elements[0] if prev_elements else None

		if not curr_elem or not prev_elem:
			return False

		# Check if same element by various matching strategies
		same_by_hash = curr_elem.element_hash == prev_elem.element_hash
		same_by_stable_hash = (
			curr_elem.stable_hash is not None
			and prev_elem.stable_hash is not None
			and curr_elem.stable_hash == prev_elem.stable_hash
		)
		same_by_xpath = curr_elem.x_path == prev_elem.x_path

		if not (same_by_hash or same_by_stable_hash or same_by_xpath):
			return False

		# Check if same action type
		curr_actions = current_item.model_output.action if current_item.model_output else []
		prev_actions = previous_item.model_output.action if previous_item.model_output else []

		if not curr_actions or not prev_actions:
			return False

		# Get the action type (first key in the action dict)
		curr_action_data = curr_actions[0].model_dump(exclude_unset=True)
		prev_action_data = prev_actions[0].model_dump(exclude_unset=True)

		curr_action_type = next(iter(curr_action_data.keys()), None)
		prev_action_type = next(iter(prev_action_data.keys()), None)

		if curr_action_type != prev_action_type:
			return False

		self.logger.debug(
			f'ğŸ”„ Detected redundant retry: both steps target same element '
			f'<{curr_elem.node_name}> with action "{curr_action_type}"'
		)

		return True

	async def load_and_rerun(
		self,
		history_file: str | Path | None = None,
		variables: dict[str, str] | None = None,
		**kwargs,
	) -> list[ActionResult]:
		"""
		ä»æ–‡ä»¶åŠ è½½å†å²è®°å½•å¹¶é‡æ–°è¿è¡Œï¼Œå¯é€‰æ‹©æ›¿æ¢å˜é‡

		Args:
			history_file: å†å²æ–‡ä»¶çš„è·¯å¾„
			variables: å¯é€‰çš„å­—å…¸ï¼Œå°†å˜é‡åç§°æ˜ å°„åˆ°æ–°å€¼ï¼ˆä¾‹å¦‚ {'email': 'new@example.com'}ï¼‰
			**kwargs: ä¼ é€’ç»™ rerun_history çš„å…¶ä»–å‚æ•°ï¼š
				- max_retries: æ¯ä¸ªåŠ¨ä½œçš„æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆé»˜è®¤ï¼š3ï¼‰
				- skip_failures: å¤±è´¥æ—¶ç»§ç»­ï¼ˆé»˜è®¤ï¼šTrueï¼‰
				- delay_between_actions: æ²¡æœ‰ä¿å­˜é—´éš”æ—¶çš„å»¶è¿Ÿï¼ˆé»˜è®¤ï¼š2.0sï¼‰
				- max_step_interval: ä¿å­˜çš„ step_interval çš„ä¸Šé™ï¼ˆé»˜è®¤ï¼š45.0sï¼‰
				- summary_llm: ç”¨äºæœ€ç»ˆæ‘˜è¦çš„è‡ªå®šä¹‰ LLM
				- ai_step_llm: ç”¨äºæå–é‡æ–°è¯„ä¼°çš„è‡ªå®šä¹‰ LLM
		"""
		if not history_file:
			history_file = 'AgentHistory.json'
		history = AgentHistoryList.load_from_file(history_file, self.AgentOutput)

		# Substitute variables if provided
		if variables:
			history = self._substitute_variables_in_history(history, variables)

		return await self.rerun_history(history, **kwargs)

	def save_history(self, file_path: str | Path | None = None) -> None:
		"""å°†å†å²è®°å½•ä¿å­˜åˆ°æ–‡ä»¶ï¼Œå¸¦æœ‰æ•æ„Ÿæ•°æ®è¿‡æ»¤"""
		if not file_path:
			file_path = 'AgentHistory.json'
		self.history.save_to_file(file_path, sensitive_data=self.sensitive_data)

	def pause(self) -> None:
		"""åœ¨ä¸‹ä¸€æ­¥ä¹‹å‰æš‚åœä»£ç†"""
		print('\n\nâ¸ï¸ Paused the agent and left the browser open.\n\tPress [Enter] to resume or [Ctrl+C] again to quit.')
		self.state.paused = True
		self._external_pause_event.clear()

	def resume(self) -> None:
		"""æ¢å¤ä»£ç†æ‰§è¡Œ"""
		# TODO: æœ¬åœ°æµè§ˆå™¨å·²å…³é—­
		print('----------------------------------------------------------------------')
		print('â–¶ï¸  Resuming agent execution where it left off...\n')
		self.state.paused = False
		self._external_pause_event.set()

	def stop(self) -> None:
		"""åœæ­¢ä»£ç†"""
		self.logger.info('â¹ï¸ Agent stopping')
		self.state.stopped = True

		# å‘å‡ºæš‚åœäº‹ä»¶ä¿¡å·ä»¥è§£é™¤ä»»ä½•ç­‰å¾…ä»£ç çš„é˜»å¡ï¼Œä»¥ä¾¿å®ƒå¯ä»¥æ£€æŸ¥åœæ­¢çŠ¶æ€
		self._external_pause_event.set()

		# ä»»åŠ¡å·²åœæ­¢

	def _convert_initial_actions(self, actions: list[dict[str, dict[str, Any]]]) -> list[ActionModel]:
		"""å°†åŸºäºå­—å…¸çš„åŠ¨ä½œè½¬æ¢ä¸º ActionModel å®ä¾‹
		
		è¾“å…¥ç¤ºä¾‹ï¼š
		[{"click": {"x": 100, "y": 200}}, {"input_text": {"text": "hello"}}]

		è¿”å›ç¤ºä¾‹ï¼š
		[ActionModel(click=ClickParams(x=100, y=200)), ActionModel(input_text=InputTextParams(text="hello"))]
		"""
		converted_actions = []
		action_model = self.ActionModel
		for action_dict in actions:
			# Each action_dict should have a single key-value pair
			action_name = next(iter(action_dict))
			params = action_dict[action_name]

			# Get the parameter model for this action from registry
			action_info = self.tools.registry.registry.actions[action_name]
			param_model = action_info.param_model

			# Create validated parameters using the appropriate param model
			validated_params = param_model(**params)

			# Create ActionModel instance with the validated parameters
			action_model = self.ActionModel(**{action_name: validated_params})
			converted_actions.append(action_model)

		return converted_actions

	def _verify_and_setup_llm(self):
		"""
		éªŒè¯ LLM API å¯†é’¥æ˜¯å¦å·²è®¾ç½®ï¼Œå¹¶ä¸” LLM API æ­£ç¡®å“åº”
		å¦‚æœåœ¨è‡ªåŠ¨æ¨¡å¼ä¸‹ï¼Œè¿˜å¤„ç†å·¥å…·è°ƒç”¨æ–¹æ³•æ£€æµ‹
		"""

		# å¦‚æœå·²ç»å®ŒæˆéªŒè¯åˆ™è·³è¿‡
		if getattr(self.llm, '_verified_api_keys', None) is True or CONFIG.SKIP_LLM_API_KEY_VERIFICATION:
			setattr(self.llm, '_verified_api_keys', True)
			return True

	@property
	def message_manager(self) -> MessageManager:
		return self._message_manager

	async def close(self):
		"""å…³é—­æ‰€æœ‰èµ„æº"""
		try:
			# ä»…åœ¨ keep_alive ä¸º Falseï¼ˆæˆ–æœªè®¾ç½®ï¼‰æ—¶å…³é—­æµè§ˆå™¨
			if self.browser_session is not None:
				if not self.browser_session.browser_profile.keep_alive:
					# ç»ˆæ­¢æµè§ˆå™¨ä¼šè¯ - è¿™ä¼šåˆ†å‘ BrowserStopEventï¼Œ
					# ä½¿ç”¨ clear=True åœæ­¢ EventBusï¼Œå¹¶é‡æ–°åˆ›å»ºä¸€ä¸ªæ–°çš„ EventBus
					await self.browser_session.kill()

			# Close skill service if configured
			if self.skill_service is not None:
				await self.skill_service.close()

			# Force garbage collection
			gc.collect()

			# Debug: Log remaining threads and asyncio tasks
			import threading

			threads = threading.enumerate()
			self.logger.debug(f'ğŸ§µ Remaining threads ({len(threads)}): {[t.name for t in threads]}')

			# Get all asyncio tasks
			tasks = asyncio.all_tasks(asyncio.get_event_loop())
			# Filter out the current task (this close() coroutine)
			other_tasks = [t for t in tasks if t != asyncio.current_task()]
			if other_tasks:
				self.logger.debug(f'âš¡ Remaining asyncio tasks ({len(other_tasks)}):')
				for task in other_tasks[:10]:  # Limit to first 10 to avoid spam
					self.logger.debug(f'  - {task.get_name()}: {task}')

		except Exception as e:
			self.logger.error(f'Error during cleanup: {e}')

	async def _update_action_models_for_page(self, page_url: str) -> None:
		"""ä½¿ç”¨é¡µé¢ç‰¹å®šçš„åŠ¨ä½œæ›´æ–°åŠ¨ä½œæ¨¡å‹

		åŸºäºå½“å‰é¡µé¢ URL åŠ¨æ€æ›´æ–°æ™ºèƒ½ä½“çš„åŠ¨ä½œæ¨¡å‹å’Œè¾“å‡ºæ¨¡å‹ï¼Œè®© LLM ç”Ÿæˆçš„åŠ¨ä½œä¸¥æ ¼åŒ¹é…å½“å‰é¡µé¢çš„å¯æ“ä½œèŒƒå›´ï¼ŒåŒæ—¶é€‚é…ä¸åŒçš„æ‰§è¡Œæ¨¡å¼ã€‚

		- æ›´æ–°ActionModelï¼š é¦–å…ˆä¼šæ ¹æ®pageUrlè¿‡æ»¤å‡ºå½“å‰é¡µé¢ä»…æœ‰çš„å¯æ‰§è¡ŒåŠ¨ä½œï¼Œå¦‚å½“å‰urlé¡µé¢åªèƒ½ä½¿ç”¨clickï¼Œå’Œå¯¼èˆªåŠ¨ä½œï¼Œä¸èƒ½ä½¿ç”¨ä¸‹å•åŠ¨ä½œ
		- æ›´æ–°self.AgentOutput è¾“å‡ºæ ¼å¼è§„èŒƒçš„æ¨¡å‹
		"""
		# Create new action model with current page's filtered actions
		self.ActionModel = self.tools.registry.create_action_model(page_url=page_url)
		# Update output model with the new actions
		if self.settings.flash_mode:
			self.AgentOutput = AgentOutput.type_with_custom_actions_flash_mode(self.ActionModel)
		elif self.settings.use_thinking:
			self.AgentOutput = AgentOutput.type_with_custom_actions(self.ActionModel)
		else:
			self.AgentOutput = AgentOutput.type_with_custom_actions_no_thinking(self.ActionModel)

		# Update done action model too
		self.DoneActionModel = self.tools.registry.create_action_model(include_actions=['done'], page_url=page_url)
		if self.settings.flash_mode:
			self.DoneAgentOutput = AgentOutput.type_with_custom_actions_flash_mode(self.DoneActionModel)
		elif self.settings.use_thinking:
			self.DoneAgentOutput = AgentOutput.type_with_custom_actions(self.DoneActionModel)
		else:
			self.DoneAgentOutput = AgentOutput.type_with_custom_actions_no_thinking(self.DoneActionModel)

	async def authenticate_cloud_sync(self, show_instructions: bool = True) -> bool:
		"""
		ä¸äº‘æœåŠ¡è¿›è¡Œèº«ä»½éªŒè¯ä»¥ä¾›å°†æ¥è¿è¡Œ

		è¿™åœ¨ç”¨æˆ·æƒ³è¦åœ¨ä»»åŠ¡å®Œæˆåè¿›è¡Œèº«ä»½éªŒè¯æ—¶å¾ˆæœ‰ç”¨ï¼Œ
		ä»¥ä¾¿å°†æ¥çš„è¿è¡Œå°†åŒæ­¥åˆ°äº‘

		Args:
			show_instructions: æ˜¯å¦å‘ç”¨æˆ·æ˜¾ç¤ºèº«ä»½éªŒè¯è¯´æ˜

		Returns:
			bool: å¦‚æœèº«ä»½éªŒè¯æˆåŠŸåˆ™è¿”å› True
		"""
		self.logger.warning('Cloud sync has been removed and is no longer available')
		return False

	def run_sync(
		self,
		max_steps: int = 100,
		on_step_start: AgentHookFunc | None = None,
		on_step_end: AgentHookFunc | None = None,
	) -> AgentHistoryList[AgentStructuredOutput]:
		"""å¼‚æ­¥ run æ–¹æ³•çš„åŒæ­¥åŒ…è£…å™¨ï¼Œä»¥ä¾¿åœ¨æ²¡æœ‰ asyncio çš„æƒ…å†µä¸‹æ›´å®¹æ˜“ä½¿ç”¨"""
		import asyncio

		return asyncio.run(self.run(max_steps=max_steps, on_step_start=on_step_start, on_step_end=on_step_end))

	def detect_variables(self) -> dict[str, DetectedVariable]:
		"""æ£€æµ‹ä»£ç†å†å²è®°å½•ä¸­çš„å¯é‡ç”¨å˜é‡"""
		from browser_use.agent.variable_detector import detect_variables_in_history

		return detect_variables_in_history(self.history)

	def _substitute_variables_in_history(self, history: AgentHistoryList, variables: dict[str, str]) -> AgentHistoryList:
		"""ç”¨æ–°å€¼æ›¿æ¢å†å²è®°å½•ä¸­çš„å˜é‡ï¼Œä»¥ä¾¿ä½¿ç”¨ä¸åŒçš„æ•°æ®é‡æ–°è¿è¡Œ"""
		from browser_use.agent.variable_detector import detect_variables_in_history

		# Detect variables in the history
		detected_vars = detect_variables_in_history(history)

		# Build a mapping of original values to new values
		value_replacements: dict[str, str] = {}
		for var_name, new_value in variables.items():
			if var_name in detected_vars:
				old_value = detected_vars[var_name].original_value
				value_replacements[old_value] = new_value
			else:
				self.logger.warning(f'Variable "{var_name}" not found in history, skipping substitution')

		if not value_replacements:
			self.logger.info('No variables to substitute')
			return history

		# Create a deep copy of history to avoid modifying the original
		import copy

		modified_history = copy.deepcopy(history)

		# Substitute values in all actions
		substitution_count = 0
		for history_item in modified_history.history:
			if not history_item.model_output or not history_item.model_output.action:
				continue

			for action in history_item.model_output.action:
				# Handle both Pydantic models and dicts
				if hasattr(action, 'model_dump'):
					action_dict = action.model_dump()
				elif isinstance(action, dict):
					action_dict = action
				else:
					action_dict = vars(action) if hasattr(action, '__dict__') else {}

				# Substitute in all string fields
				substitution_count += self._substitute_in_dict(action_dict, value_replacements)

				# Update the action with modified values
				if hasattr(action, 'model_dump'):
					# For Pydantic RootModel, we need to recreate from the modified dict
					if hasattr(action, 'root'):
						# This is a RootModel - recreate it from the modified dict
						new_action = type(action).model_validate(action_dict)
						# Replace the root field in-place using object.__setattr__ to bypass Pydantic's immutability
						object.__setattr__(action, 'root', getattr(new_action, 'root'))
					else:
						# Regular Pydantic model - update fields in-place
						for key, val in action_dict.items():
							if hasattr(action, key):
								setattr(action, key, val)
				elif isinstance(action, dict):
					action.update(action_dict)

		self.logger.info(f'Substituted {substitution_count} value(s) in {len(value_replacements)} variable type(s) in history')
		return modified_history

	def _substitute_in_dict(self, data: dict, replacements: dict[str, str]) -> int:
		"""é€’å½’æ›¿æ¢å­—å…¸ä¸­çš„å€¼ï¼Œè¿”å›æ‰€åšçš„æ›¿æ¢è®¡æ•°"""
		count = 0
		for key, value in data.items():
			if isinstance(value, str):
				# Replace if exact match
				if value in replacements:
					data[key] = replacements[value]
					count += 1
			elif isinstance(value, dict):
				# Recurse into nested dicts
				count += self._substitute_in_dict(value, replacements)
			elif isinstance(value, list):
				# Handle lists
				for i, item in enumerate(value):
					if isinstance(item, str) and item in replacements:
						value[i] = replacements[item]
						count += 1
					elif isinstance(item, dict):
						count += self._substitute_in_dict(item, replacements)
		return count
